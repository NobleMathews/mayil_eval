{
    "id": "scikit-learn__scikit-learn-25370",
    "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
    "task_id": 8901150219564988315,
    "title": "sklearn.set_config(transform_output=\"pandas\") breaks TSNE embeddings",
    "body": "### Describe the bug\r\n\r\nTSNE doesn't work when the [global config is changed to pandas.](https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep018/proposal.html#global-configuration)\r\n\r\nI tracked down this bug in the sklearn codebase. The issue is here: https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/manifold/_t_sne.py#L996\r\n\r\nWhat's happening is that `X_embedded` returns a Pandas array under `set_output` API, with the columns being named \"pca0\" and \"pca1\". So when `X_embedded[:, 0]` is called, we get an IndexError, because you'd have to index with `X_embedded.iloc[:, 0]` in this situation. \r\n\r\nPossible fix could be changing line 996 to this:\r\n`X_embedded = X_embedded / np.std(np.array(X_embedded)[:, 0]) * 1e-4`\r\n\r\nwhich I am happy to make a PR to do unless somebody has a cleaner way.\r\n\r\nCheers!\r\n\r\n### Steps/Code to Reproduce\r\n\r\n```py\r\nimport sklearn\r\nimport numpy as np\r\nfrom sklearn.manifold import TSNE\r\n\r\nsklearn.set_config(transform_output=\"pandas\")\r\narr = np.arange(35*4).reshape(35, 4)\r\nTSNE(n_components=2).fit_transform(arr)\r\n```\r\n\r\n### Expected Results\r\n\r\nNo error is thrown, a 2-dimensional pandas array is returned\r\n\r\n### Actual Results\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803, in Index.get_loc(self, key, method, tolerance)\r\n   3802 try:\r\n-> 3803     return self._engine.get_loc(casted_key)\r\n   3804 except KeyError as err:\r\n\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/pandas/_libs/index.pyx:138, in pandas._libs.index.IndexEngine.get_loc()\r\n\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/pandas/_libs/index.pyx:144, in pandas._libs.index.IndexEngine.get_loc()\r\n\r\nTypeError: '(slice(None, None, None), 0)' is an invalid key\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidIndexError                         Traceback (most recent call last)\r\nCell In[14], line 7\r\n      5 sklearn.set_config(transform_output=\"pandas\")\r\n      6 arr = np.arange(35*4).reshape(35, 4)\r\n----> 7 TSNE(n_components=2).fit_transform(arr)\r\n\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1117, in TSNE.fit_transform(self, X, y)\r\n   1115 self._validate_params()\r\n   1116 self._check_params_vs_input(X)\r\n-> 1117 embedding = self._fit(X)\r\n   1118 self.embedding_ = embedding\r\n   1119 return self.embedding_\r\n\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:996, in TSNE._fit(self, X, skip_num_points)\r\n    993     X_embedded = pca.fit_transform(X).astype(np.float32, copy=False)\r\n    994     # PCA is rescaled so that PC1 has standard deviation 1e-4 which is\r\n    995     # the default value for random initialization. See issue #18018.\r\n--> 996     X_embedded = X_embedded / np.std(X_embedded[:, 0]) * 1e-4\r\n    997 elif self.init == \"random\":\r\n    998     # The embedding is initialized with iid samples from Gaussians with\r\n    999     # standard deviation 1e-4.\r\n   1000     X_embedded = 1e-4 * random_state.standard_normal(\r\n   1001         size=(n_samples, self.n_components)\r\n   1002     ).astype(np.float32)\r\n\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/pandas/core/frame.py:3805, in DataFrame.__getitem__(self, key)\r\n   3803 if self.columns.nlevels > 1:\r\n   3804     return self._getitem_multilevel(key)\r\n-> 3805 indexer = self.columns.get_loc(key)\r\n   3806 if is_integer(indexer):\r\n   3807     indexer = [indexer]\r\n\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810, in Index.get_loc(self, key, method, tolerance)\r\n   3805         raise KeyError(key) from err\r\n   3806     except TypeError:\r\n   3807         # If we have a listlike key, _check_indexing_error will raise\r\n   3808         #  InvalidIndexError. Otherwise we fall through and re-raise\r\n   3809         #  the TypeError.\r\n-> 3810         self._check_indexing_error(key)\r\n   3811         raise\r\n   3813 # GH#42269\r\n\r\nFile ~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/pandas/core/indexes/base.py:5968, in Index._check_indexing_error(self, key)\r\n   5964 def _check_indexing_error(self, key):\r\n   5965     if not is_scalar(key):\r\n   5966         # if key is not a scalar, directly raise an error (the code below\r\n   5967         # would convert to numpy arrays and raise later any way) - GH29926\r\n-> 5968         raise InvalidIndexError(key)\r\n\r\nInvalidIndexError: (slice(None, None, None), 0)\r\n```\r\n\r\n### Versions\r\n\r\n```shell\r\nSystem:\r\n    python: 3.10.9 (main, Dec 12 2022, 21:10:20) [GCC 9.4.0]\r\nexecutable: /home/aloftus/.pyenv/versions/3.10.9/bin/python3.10\r\n   machine: Linux-5.4.0-128-generic-x86_64-with-glibc2.31\r\n\r\nPython dependencies:\r\n      sklearn: 1.2.0\r\n          pip: 22.3.1\r\n   setuptools: 65.6.3\r\n        numpy: 1.23.5\r\n        scipy: 1.9.3\r\n       Cython: None\r\n       pandas: 1.5.2\r\n   matplotlib: 3.6.2\r\n       joblib: 1.2.0\r\nthreadpoolctl: 3.1.0\r\n\r\nBuilt with OpenMP: True\r\n\r\nthreadpoolctl info:\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /home/aloftus/.pyenv/versions/3.10.9/lib/python3.10/site-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so\r\n        version: 0.3.20\r\nthreading_layer: pthreads\r\n   architecture: SkylakeX\r\n    num_threads: 32\r\n\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /home/aloftus/.pyenv/versions/3.10.9/lib/python3.10/site-packages/scipy.libs/libopenblasp-r0-41284840.3.18.so\r\n        version: 0.3.18\r\nthreading_layer: pthreads\r\n   architecture: SkylakeX\r\n    num_threads: 32\r\n\r\n       user_api: openmp\r\n   internal_api: openmp\r\n         prefix: libgomp\r\n       filepath: /home/aloftus/.pyenv/versions/3.10.9/lib/python3.10/site-packages/scikit_learn.libs/libgomp-a34b3233.so.1.0.0\r\n        version: None\r\n    num_threads: 32\r\n\r\n       user_api: openmp\r\n   internal_api: openmp\r\n         prefix: libgomp\r\n       filepath: /home/aloftus/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/lib/libgomp-a34b3233.so.1\r\n        version: None\r\n    num_threads: 16\r\n```\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__1.3.git",
    "requested_commit": "",
    "mayil_response": "- Replace the line `X_embedded = X_embedded / np.std(X_embedded[:, 0]) * 1e-4` in the `TSNE._fit` method with the proposed fix `X_embedded = X_embedded / np.std(np.array(X_embedded)[:, 0]) * 1e-4` to ensure compatibility with the global `transform_output=\"pandas\"` configuration.\n- The change should be made in the file `_t_sne.py` at the line corresponding to the PCA initialization block within the `TSNE._fit` method.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn) \u2192 [manifold](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn/manifold)- [Lines 983 - 1087](https://github.com/testbed/scikit-learn__scikit-learn__1.3/blob//sklearn/manifold/_t_sne.py#L983-L1087)\n\n This snippet contains the exact line of code (line 996) where the IndexError occurs when indexing a pandas DataFrame with a numpy-style index, which is the root cause of the issue.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0003495,
        "snippet_processor": 0.04503,
        "issue_star_creation": 0.0381,
        "issue_star_solver": 0.06981000000000001,
        "bouncer": 0.02748
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711737893.275257,
        "relevant_snippets": [
            {
                "code": "\"\"\"\n================================\nIntroducing the `set_output` API\n================================\n\n.. currentmodule:: sklearn\n\nThis example will demonstrate the `set_output` API to configure transformers to\noutput pandas DataFrames. `set_output` can be configured per estimator by calling\nthe `set_output` method or globally by setting `set_config(transform_output=\"pandas\")`.\nFor details, see\n`SLEP018 <https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep018/proposal.html>`__.\n\"\"\"  # noqa\n\n# %%\n# First, we load the iris dataset as a DataFrame to demonstrate the `set_output` API.\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\nX, y = load_iris(as_frame=True, return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\nX_train.head()\n\n# %%\n# To configure an estimator such as :class:`preprocessing.StandardScaler` to return\n# DataFrames, call `set_output`. This feature requires pandas to be installed.\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().set_output(transform=\"pandas\")\n\nscaler.fit(X_train)\nX_test_scaled = scaler.transform(X_test)\nX_test_scaled.head()\n\n# %%\n# `set_output` can be called after `fit` to configure `transform` after the fact.\nscaler2 = StandardScaler()\n\nscaler2.fit(X_train)\nX_test_np = scaler2.transform(X_test)\nprint(f\"Default output type: {type(X_test_np).__name__}\")\n\nscaler2.set_output(transform=\"pandas\")\nX_test_df = scaler2.transform(X_test)\nprint(f\"Configured pandas output type: {type(X_test_df).__name__}\")\n\n# %%\n# In a :class:`pipeline.Pipeline`, `set_output` configures all steps to output\n# DataFrames.\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\nclf = make_pipeline(\n    StandardScaler(), SelectPercentile(percentile=75), LogisticRegression()\n)\nclf.set_output(transform=\"pandas\")\nclf.fit(X_train, y_train)\n\n# %%\n# Each transformer in the pipeline is configured to return DataFrames. This\n# means that the final logistic regression step contains the feature names of the input.\nclf[-1].feature_names_in_\n\n# %%\n# Next we load the titanic dataset to demonstrate `set_output` with\n# :class:`compose.ColumnTransformer` and heterogeneous data.\nfrom sklearn.datasets import fetch_openml\n\nX, y = fetch_openml(\n    \"titanic\", version=1, as_frame=True, return_X_y=True, parser=\"pandas\"\n)\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n\n# %%\n# The `set_output` API can be configured globally by using :func:`set_config` and\n# setting `transform_output` to `\"pandas\"`.\nfrom sklearn import set_config\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nset_config(transform_output=\"pandas\")\n\nnum_pipe = make_pipeline(SimpleImputer(), StandardScaler())\nnum_cols = [\"age\", \"fare\"]",
                "filename": "examples/miscellaneous/plot_set_output.py",
                "start_index": 0,
                "end_index": 2982,
                "start_line": 1,
                "end_line": 87,
                "max_line": 138,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.9
            },
            {
                "code": "def check_set_output_transform_pandas(name, transformer_orig):\n    # Check transformer.set_output configures the output of transform=\"pandas\".\n    try:\n        import pandas as pd\n    except ImportError:\n        raise SkipTest(\n            \"pandas is not installed: not checking column name consistency for pandas\"\n        )\n\n    tags = transformer_orig._get_tags()\n    if \"2darray\" not in tags[\"X_types\"] or tags[\"no_validation\"]:\n        return\n\n    rng = np.random.RandomState(0)\n    transformer = clone(transformer_orig)\n\n    X = rng.uniform(size=(20, 5))\n    X = _enforce_estimator_tags_X(transformer_orig, X)\n    y = rng.randint(0, 2, size=20)\n    y = _enforce_estimator_tags_y(transformer_orig, y)\n    set_random_state(transformer)\n\n    feature_names_in = [f\"col{i}\" for i in range(X.shape[1])]\n    index = [f\"index{i}\" for i in range(X.shape[0])]\n    df = pd.DataFrame(X, columns=feature_names_in, copy=False, index=index)\n\n    transformer_default = clone(transformer).set_output(transform=\"default\")\n    outputs_default = _output_from_fit_transform(transformer_default, name, X, df, y)\n    transformer_pandas = clone(transformer).set_output(transform=\"pandas\")\n    try:\n        outputs_pandas = _output_from_fit_transform(transformer_pandas, name, X, df, y)\n    except ValueError as e:\n        # transformer does not support sparse data\n        assert str(e) == \"Pandas output does not support sparse data.\", e\n        return\n\n    for case in outputs_default:\n        _check_generated_dataframe(\n            name, case, index, outputs_default[case], outputs_pandas[case]\n        )",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 161309,
                "end_index": 162898,
                "start_line": 4554,
                "end_line": 4639,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"\n=====================================\nApproximate nearest neighbors in TSNE\n=====================================\n\nThis example presents how to chain KNeighborsTransformer and TSNE in a pipeline.\nIt also shows how to wrap the packages `nmslib` and `pynndescent` to replace\nKNeighborsTransformer and perform approximate nearest neighbors. These packages\ncan be installed with `pip install nmslib pynndescent`.\n\nNote: In KNeighborsTransformer we use the definition which includes each\ntraining point as its own neighbor in the count of `n_neighbors`, and for\ncompatibility reasons, one extra neighbor is computed when `mode == 'distance'`.\nPlease note that we do the same in the proposed `nmslib` wrapper.\n\"\"\"\n\n# Author: Tom Dupre la Tour\n# License: BSD 3 clause\n\n# %%\n# First we try to import the packages and warn the user in case they are\n# missing.\nimport sys\n\ntry:\n    import nmslib\nexcept ImportError:\n    print(\"The package 'nmslib' is required to run this example.\")\n    sys.exit()\n\ntry:\n    from pynndescent import PyNNDescentTransformer\nexcept ImportError:\n    print(\"The package 'pynndescent' is required to run this example.\")\n    sys.exit()\n\n# %%\n# We define a wrapper class for implementing the scikit-learn API to the\n# `nmslib`, as well as a loading function.\nimport joblib\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.utils import shuffle",
                "filename": "examples/neighbors/approximate_nearest_neighbors.py",
                "start_index": 0,
                "end_index": 1480,
                "start_line": 1,
                "end_line": 46,
                "max_line": 314,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "transformers = [\n    (\"TSNE with internal NearestNeighbors\", TSNE(metric=metric, **tsne_params)),\n    (\n        \"TSNE with KNeighborsTransformer\",\n        make_pipeline(\n            KNeighborsTransformer(\n                n_neighbors=n_neighbors, mode=\"distance\", metric=metric\n            ),\n            TSNE(metric=\"precomputed\", **tsne_params),\n        ),\n    ),\n    (\n        \"TSNE with NMSlibTransformer\",\n        make_pipeline(\n            NMSlibTransformer(n_neighbors=n_neighbors, metric=metric),\n            TSNE(metric=\"precomputed\", **tsne_params),\n        ),\n    ),\n]\n\n# init the plot\nnrows = len(datasets)\nncols = np.sum([1 for name, model in transformers if \"TSNE\" in name])\nfig, axes = plt.subplots(\n    nrows=nrows, ncols=ncols, squeeze=False, figsize=(5 * ncols, 4 * nrows)\n)\naxes = axes.ravel()\ni_ax = 0\n\nfor dataset_name, (X, y) in datasets:\n    msg = f\"Benchmarking on {dataset_name}:\"\n    print(f\"\\n{msg}\\n\" + str(\"-\" * len(msg)))\n\n    for transformer_name, transformer in transformers:\n        longest = np.max([len(name) for name, model in transformers])\n        start = time.time()\n        Xt = transformer.fit_transform(X)\n        transform_duration = time.time() - start\n        print(\n            f\"{transformer_name:<{longest}} {transform_duration:.3f} sec\"\n            \" (fit_transform)\"\n        )\n\n        # plot TSNE embedding which should be very similar across methods\n        axes[i_ax].set_title(transformer_name + \"\\non \" + dataset_name)\n        axes[i_ax].scatter(\n            Xt[:, 0],\n            Xt[:, 1],\n            c=y.astype(np.int32),\n            alpha=0.2,\n            cmap=plt.cm.viridis,\n        )\n        axes[i_ax].xaxis.set_major_formatter(NullFormatter())\n        axes[i_ax].yaxis.set_major_formatter(NullFormatter())\n        axes[i_ax].axis(\"tight\")\n        i_ax += 1\n\nfig.tight_layout()\nplt.show()\n\n# %%\n# Sample output::\n#\n#     Benchmarking on MNIST_10000:\n#     ----------------------------\n#     TSNE with internal NearestNeighbors 24.828 sec (fit_transform)\n#     TSNE with KNeighborsTransformer     20.111 sec (fit_transform)\n#     TSNE with NMSlibTransformer         21.757 sec (fit_transform)\n#\n#     Benchmarking on MNIST_20000:\n#     ----------------------------\n#     TSNE with internal NearestNeighbors 51.955 sec (fit_transform)\n#     TSNE with KNeighborsTransformer     50.994 sec (fit_transform)\n#     TSNE with NMSlibTransformer         43.536 sec (fit_transform)\n#\n# We can observe that the default :class:`~sklearn.manifold.TSNE` estimator with\n# its internal :class:`~sklearn.neighbors.NearestNeighbors` implementation is\n# roughly equivalent to the pipeline with :class:`~sklearn.manifold.TSNE` and\n# :class:`~sklearn.neighbors.KNeighborsTransformer` in terms of performance.\n# This is expected because both pipelines rely internally on the same\n# :class:`~sklearn.neighbors.NearestNeighbors` implementation that performs\n# exacts neighbors search. The approximate `NMSlibTransformer` is already",
                "filename": "examples/neighbors/approximate_nearest_neighbors.py",
                "start_index": 7326,
                "end_index": 10294,
                "start_line": 141,
                "end_line": 297,
                "max_line": 314,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "if isinstance(self.init, np.ndarray):\n            X_embedded = self.init\n        elif self.init == \"pca\":\n            pca = PCA(\n                n_components=self.n_components,\n                svd_solver=\"randomized\",\n                random_state=random_state,\n            )\n            # Always output a numpy array, no matter what is configured globally\n            pca.set_output(transform=\"default\")\n            X_embedded = pca.fit_transform(X).astype(np.float32, copy=False)\n            # PCA is rescaled so that PC1 has standard deviation 1e-4 which is\n            # the default value for random initialization. See issue #18018.\n            X_embedded = X_embedded / np.std(X_embedded[:, 0]) * 1e-4\n        elif self.init == \"random\":\n            # The embedding is initialized with iid samples from Gaussians with\n            # standard deviation 1e-4.\n            X_embedded = 1e-4 * random_state.standard_normal(\n                size=(n_samples, self.n_components)\n            ).astype(np.float32)\n\n        # Degrees of freedom of the Student's t-distribution. The suggestion\n        # degrees_of_freedom = n_components - 1 comes from\n        # \"Learning a Parametric Embedding by Preserving Local Structure\"\n        # Laurens van der Maaten, 2009.\n        degrees_of_freedom = max(self.n_components - 1, 1)\n\n        return self._tsne(\n            P,\n            degrees_of_freedom,\n            n_samples,\n            X_embedded=X_embedded,\n            neighbors=neighbors_nn,\n            skip_num_points=skip_num_points,\n        )",
                "filename": "sklearn/manifold/_t_sne.py",
                "start_index": 36632,
                "end_index": 38174,
                "start_line": 983,
                "end_line": 1087,
                "max_line": 1158,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "def check_set_output_transform(name, transformer_orig):\n    # Check transformer.set_output with the default configuration does not\n    # change the transform output.\n    tags = transformer_orig._get_tags()\n    if \"2darray\" not in tags[\"X_types\"] or tags[\"no_validation\"]:\n        return\n\n    rng = np.random.RandomState(0)\n    transformer = clone(transformer_orig)\n\n    X = rng.uniform(size=(20, 5))\n    X = _enforce_estimator_tags_X(transformer_orig, X)\n    y = rng.randint(0, 2, size=20)\n    y = _enforce_estimator_tags_y(transformer_orig, y)\n    set_random_state(transformer)\n\n    def fit_then_transform(est):\n        if name in CROSS_DECOMPOSITION:\n            return est.fit(X, y).transform(X, y)\n        return est.fit(X, y).transform(X)\n\n    def fit_transform(est):\n        return est.fit_transform(X, y)\n\n    transform_methods = {\n        \"transform\": fit_then_transform,\n        \"fit_transform\": fit_transform,\n    }\n    for name, transform_method in transform_methods.items():\n        transformer = clone(transformer)\n        if not hasattr(transformer, name):\n            continue\n        X_trans_no_setting = transform_method(transformer)\n\n        # Auto wrapping only wraps the first array\n        if name in CROSS_DECOMPOSITION:\n            X_trans_no_setting = X_trans_no_setting[0]\n\n        transformer.set_output(transform=\"default\")\n        X_trans_default = transform_method(transformer)\n\n        if name in CROSS_DECOMPOSITION:\n            X_trans_default = X_trans_default[0]\n\n        # Default and no setting -> returns the same transformation\n        assert_allclose_dense_sparse(X_trans_no_setting, X_trans_default)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 157079,
                "end_index": 158718,
                "start_line": 4434,
                "end_line": 4479,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "# T-distributed Stochastic Neighbor Embedding\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n#\n# It converts similarities between data points to joint probabilities and\n# tries to minimize the Kullback-Leibler divergence between the joint probabilities\n# of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost\n# function that is not convex, i.e. with different initializations we can get\n# different results. Read more in the :ref:`User Guide <t_sne>`.\n\nt_sne = manifold.TSNE(\n    n_components=n_components,\n    perplexity=30,\n    init=\"random\",\n    n_iter=250,\n    random_state=0,\n)\nS_t_sne = t_sne.fit_transform(S_points)\n\nplot_2d(S_t_sne, S_color, \"T-distributed Stochastic  \\n Neighbor Embedding\")\n\n# %%",
                "filename": "examples/manifold/plot_compare_methods.py",
                "start_index": 6002,
                "end_index": 6734,
                "start_line": 192,
                "end_line": 212,
                "max_line": 212,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def check_transformer_get_feature_names_out_pandas(name, transformer_orig):\n    try:\n        import pandas as pd\n    except ImportError:\n        raise SkipTest(\n            \"pandas is not installed: not checking column name consistency for pandas\"\n        )\n\n    tags = transformer_orig._get_tags()\n    if \"2darray\" not in tags[\"X_types\"] or tags[\"no_validation\"]:\n        return\n\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n\n    transformer = clone(transformer_orig)\n    X = _enforce_estimator_tags_X(transformer, X)\n\n    n_features = X.shape[1]\n    set_random_state(transformer)\n\n    y_ = y\n    if name in CROSS_DECOMPOSITION:\n        y_ = np.c_[np.asarray(y), np.asarray(y)]\n        y_[::2, 1] *= 2\n\n    feature_names_in = [f\"col{i}\" for i in range(n_features)]\n    df = pd.DataFrame(X, columns=feature_names_in, copy=False)\n    X_transform = transformer.fit_transform(df, y=y_)\n\n    # error is raised when `input_features` do not match feature_names_in\n    invalid_feature_names = [f\"bad{i}\" for i in range(n_features)]\n    with raises(ValueError, match=\"input_features is not equal to feature_names_in_\"):\n        transformer.get_feature_names_out(invalid_feature_names)\n\n    feature_names_out_default = transformer.get_feature_names_out()\n    feature_names_in_explicit_names = transformer.get_feature_names_out(\n        feature_names_in\n    )\n    assert_array_equal(feature_names_out_default, feature_names_in_explicit_names)\n\n    if isinstance(X_transform, tuple):\n        n_features_out = X_transform[0].shape[1]\n    else:\n        n_features_out = X_transform.shape[1]\n\n    assert (\n        len(feature_names_out_default) == n_features_out\n    ), f\"Expected {n_features_out} feature names, got {len(feature_names_out_default)}\"",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 149921,
                "end_index": 151816,
                "start_line": 4258,
                "end_line": 4312,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "default=\"pca\"\n        Initialization of embedding.\n        PCA initialization cannot be used with precomputed distances and is\n        usually more globally stable than random initialization.\n\n        .. versionchanged:: 1.2\n           The default value changed to `\"pca\"`.\n\n    verbose : int, default=0\n        Verbosity level.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines the random number generator. Pass an int for reproducible\n        results across multiple function calls. Note that different\n        initializations might result in different local minima of the cost\n        function. See :term:`Glossary <random_state>`.\n\n    method : {'barnes_hut', 'exact'}, default='barnes_hut'\n        By default the gradient calculation algorithm uses Barnes-Hut\n        approximation running in O(NlogN) time. method='exact'\n        will run on the slower, but exact, algorithm in O(N^2) time. The\n        exact algorithm should be used when nearest-neighbor errors need\n        to be better than 3%. However, the exact method cannot scale to\n        millions of examples.\n\n        .. versionadded:: 0.17\n           Approximate optimization *method* via the Barnes-Hut.\n\n    angle : float, default=0.5\n        Only used if method='barnes_hut'\n        This is the trade-off between speed and accuracy for Barnes-Hut T-SNE.\n        'angle' is the angular size (referred to as theta in [3]) of a distant\n        node as measured from a point. If this size is below 'angle' then it is\n        used as a summary node of all points contained within it.\n        This method is not very sensitive to changes in this parameter\n        in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing\n        computation time and angle greater 0.8 has quickly increasing error.\n\n    n_jobs : int, default=None\n        The number of parallel jobs to run for neighbors search. This parameter\n        has no impact when ``metric=\"precomputed\"`` or\n        (``metric=\"euclidean\"`` and ``method=\"exact\"``).\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n        .. versionadded:: 0.22\n\n    Attributes\n    ----------\n    embedding_ : array-like of shape (n_samples, n_components)\n        Stores the embedding vectors.\n\n    kl_divergence_ : float\n        Kullback-Leibler divergence after optimization.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    learning_rate_ : float\n        Effective learning rate.\n\n        .. versionadded:: 1.2\n\n    n_iter_ : int\n        Number of iterations run.\n\n    See Also\n    --------\n    sklearn.decomposition.PCA : Principal component analysis that is a linear\n        dimensionality reduction method.\n    sklearn.decomposition.KernelPCA : Non-linear dimensionality reduction using\n        kernels and PCA.\n    MDS : Manifold learning using multidimensional scaling.\n    Isomap : Manifold learning based on Isometric Mapping.\n    LocallyLinearEmbedding : Manifold learning using Locally Linear Embedding.\n    SpectralEmbedding : Spectral embedding for non-linear dimensionality.\n\n    References\n    ----------\n\n    [1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data\n        Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.\n\n    [2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding\n        https://lvdmaaten.github.io/tsne/\n\n    [3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.\n        Journal of Machine Learning Research 15(Oct):3221-3245, 2014.\n        https://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf\n\n    [4] Belkina, A. C., Ciccolella, C. O., Anno, R., Halpert, R., Spidlen, J.,\n        & Snyder-Cappione, J. E. (2019). Automated optimized parameters for\n        T-distributed stochastic neighbor embedding improve visualization\n        and analysis of large datasets. Nature Communications, 10(1), 1-12.\n\n    [5] Kobak, D., & Berens, P. (2019). The art of using t-SNE for single-cell\n        transcriptomics. Nature Communications, 10(1), 1-14.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.manifold import TSNE\n    >>> X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n    >>> X_embedded = TSNE(n_components=2, learning_rate='auto',\n    ...                   init='random', perplexity=3).fit_transform(X)\n    >>> X_embedded.shape\n    (4, 2)\n    \"\"\"",
                "filename": "sklearn/manifold/_t_sne.py",
                "start_index": 23390,
                "end_index": 28158,
                "start_line": 645,
                "end_line": 1154,
                "max_line": 1158,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def check_global_output_transform_pandas(name, transformer_orig):\n    \"\"\"Check that setting globally the output of a transformer to pandas lead to the\n    right results.\"\"\"\n    try:\n        import pandas as pd\n    except ImportError:\n        raise SkipTest(\n            \"pandas is not installed: not checking column name consistency for pandas\"\n        )\n\n    tags = transformer_orig._get_tags()\n    if \"2darray\" not in tags[\"X_types\"] or tags[\"no_validation\"]:\n        return\n\n    rng = np.random.RandomState(0)\n    transformer = clone(transformer_orig)\n\n    X = rng.uniform(size=(20, 5))\n    X = _enforce_estimator_tags_X(transformer_orig, X)\n    y = rng.randint(0, 2, size=20)\n    y = _enforce_estimator_tags_y(transformer_orig, y)\n    set_random_state(transformer)\n\n    feature_names_in = [f\"col{i}\" for i in range(X.shape[1])]\n    index = [f\"index{i}\" for i in range(X.shape[0])]\n    df = pd.DataFrame(X, columns=feature_names_in, copy=False, index=index)\n\n    transformer_default = clone(transformer).set_output(transform=\"default\")\n    outputs_default = _output_from_fit_transform(transformer_default, name, X, df, y)\n    transformer_pandas = clone(transformer)\n    try:\n        with config_context(transform_output=\"pandas\"):\n            outputs_pandas = _output_from_fit_transform(\n                transformer_pandas, name, X, df, y\n            )\n    except ValueError as e:\n        # transformer does not support sparse data\n        assert str(e) == \"Pandas output does not support sparse data.\", e\n        return\n\n    for case in outputs_default:\n        _check_generated_dataframe(\n            name, case, index, outputs_default[case], outputs_pandas[case]\n        )",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 162901,
                "end_index": 164579,
                "start_line": 4596,
                "end_line": 4639,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sklearn/manifold/_t_sne.py": [
                {
                    "chunk": {
                        "code": "if isinstance(self.init, np.ndarray):\n            X_embedded = self.init\n        elif self.init == \"pca\":\n            pca = PCA(\n                n_components=self.n_components,\n                svd_solver=\"randomized\",\n                random_state=random_state,\n            )\n            # Always output a numpy array, no matter what is configured globally\n            pca.set_output(transform=\"default\")\n            X_embedded = pca.fit_transform(X).astype(np.float32, copy=False)\n            # PCA is rescaled so that PC1 has standard deviation 1e-4 which is\n            # the default value for random initialization. See issue #18018.\n            X_embedded = X_embedded / np.std(X_embedded[:, 0]) * 1e-4\n        elif self.init == \"random\":\n            # The embedding is initialized with iid samples from Gaussians with\n            # standard deviation 1e-4.\n            X_embedded = 1e-4 * random_state.standard_normal(\n                size=(n_samples, self.n_components)\n            ).astype(np.float32)\n\n        # Degrees of freedom of the Student's t-distribution. The suggestion\n        # degrees_of_freedom = n_components - 1 comes from\n        # \"Learning a Parametric Embedding by Preserving Local Structure\"\n        # Laurens van der Maaten, 2009.\n        degrees_of_freedom = max(self.n_components - 1, 1)\n\n        return self._tsne(\n            P,\n            degrees_of_freedom,\n            n_samples,\n            X_embedded=X_embedded,\n            neighbors=neighbors_nn,\n            skip_num_points=skip_num_points,\n        )",
                        "filename": "sklearn/manifold/_t_sne.py",
                        "start_index": 36632,
                        "end_index": 38174,
                        "start_line": 983,
                        "end_line": 1087,
                        "max_line": 1158,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the exact line of code (line 996) where the IndexError occurs when indexing a pandas DataFrame with a numpy-style index, which is the root cause of the issue."
                }
            ]
        },
        "solution_task": "- Replace the line `X_embedded = X_embedded / np.std(X_embedded[:, 0]) * 1e-4` in the `TSNE._fit` method with the proposed fix `X_embedded = X_embedded / np.std(np.array(X_embedded)[:, 0]) * 1e-4` to ensure compatibility with the global `transform_output=\"pandas\"` configuration.\n- The change should be made in the file `_t_sne.py` at the line corresponding to the PCA initialization block within the `TSNE._fit` method.",
        "bouncer_response": {
            "score": 7,
            "criteria": "RESPONSE that are highly relevant, offering clear and comprehensive guidance or solutions for the described bug, should score between 7 and 9.",
            "supporting_evidence": "The RESPONSE provides a specific and actionable solution to the bug described in the PROMPT. It suggests replacing the problematic line of code with a version that converts the Pandas DataFrame to a NumPy array before indexing, which would resolve the IndexError caused by the global configuration change to output Pandas DataFrames. The RESPONSE also correctly identifies the location of the change in the codebase and provides a link to the relevant section of the code. This advice is directly applicable to the issue at hand and would likely resolve the bug if implemented. However, the RESPONSE could be improved by explaining why the proposed solution works and by considering any potential side effects or the need for additional changes elsewhere in the code to fully support the global configuration change. Therefore, it does not score a perfect 10.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711738102.531106,
        "result": "- Replace the line `X_embedded = X_embedded / np.std(X_embedded[:, 0]) * 1e-4` in the `TSNE._fit` method with the proposed fix `X_embedded = X_embedded / np.std(np.array(X_embedded)[:, 0]) * 1e-4` to ensure compatibility with the global `transform_output=\"pandas\"` configuration.\n- The change should be made in the file `_t_sne.py` at the line corresponding to the PCA initialization block within the `TSNE._fit` method.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn) \u2192 [manifold](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn/manifold)- [Lines 983 - 1087](https://github.com/testbed/scikit-learn__scikit-learn__1.3/blob//sklearn/manifold/_t_sne.py#L983-L1087)\n\n This snippet contains the exact line of code (line 996) where the IndexError occurs when indexing a pandas DataFrame with a numpy-style index, which is the root cause of the issue.",
        "context_relevance": 0.35000000000000003,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers the PROMPT completely.\nSupporting Evidence: The RESPONSE directly addresses the bug described in the PROMPT by providing a specific solution to the IndexError caused by the `transform_output=\"pandas\"` configuration in the sklearn TSNE implementation. It identifies the exact line of code that needs to be changed and offers a proposed fix that is relevant to the issue. Additionally, the RESPONSE includes a link to the code snippet where the change should be made, which is directly related to the traceback error provided in the PROMPT. The RESPONSE fulfills all aspects of the PROMPT, making it highly relevant and deserving of the highest score."
        },
        "qa_relevance": 1.0
    }
}