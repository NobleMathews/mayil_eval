{
    "id": "scikit-learn__scikit-learn-25733",
    "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
    "task_id": 7346575176720661163,
    "title": "FutureWarning is not issued for deprecated class",
    "body": "FutureWarning is not issued when using `BaseNB` as a baseclass but its `__init__()` is not called in the subclass, here: https://github.com/astroML/astroML/blob/master/astroML/classification/gmm_bayes.py#L15\r\n\r\n```\r\nIn [1]: from astroML.classification import GMMBayes                                                                                                                                \r\n\r\nIn [2]: GMMBayes()                                                                                                                                                                 \r\nOut[2]: GMMBayes(n_components=array([1]))\r\n```\r\n\r\nAs the comment suggest in your `deprecated` decorator, overriding ``__new__`` in the class decorator indeed solves this issue.\r\n\r\n```\r\nIn [4]: from astroML.classification import GMMBayes                                                                                                                                \r\n\r\nIn [5]: GMMBayes()                                                                                                                                                                 \r\n/Users/bsipocz/munka/devel/scikit-learn/sklearn/utils/deprecation.py:73: FutureWarning: Class BaseNB is deprecated; BaseNB is deprecated in version 0.22 and will be removed in version 0.24.\r\n  warnings.warn(msg, category=FutureWarning)\r\nOut[5]: GMMBayes(n_components=array([1]))\r\n```\r\n\r\nI'm  happy to open a PR with the fix.\r\n\r\nAlso, relatedly, I wonder whether you would be interested in using a generic deprecation package instead. Basically we have the same functionality in astropy (I feel it's actually has more features e.g. this works there out of the box, it helps with arg renames/removals, etc.), there is also a deprecated decorator in matplotlib, and also a very basic one in numpy. I feel that having one for the wider ecosystem would be beneficial instead of the current system where we all roll our own. \r\nAt the numfocus summit I recall some interest from the mpl side, so I'm happy to get the ball rolling in this quoter if it's a thumb up from multiple projects.\r\n\r\n\r\n\r\nDarwin-17.7.0-x86_64-i386-64bit\r\nPython 3.7.5 (default, Nov  1 2019, 02:16:38) \r\n[Clang 10.0.0 (clang-1000.11.45.5)]\r\nNumPy 1.19.0.dev0+63ef78b\r\nSciPy 1.4.1\r\nScikit-Learn 0.23.dev0\r\n\r\n\r\n\r\n\r\n\r\n\r\n\nQuick fix for class deprecation decorator\nThis is a quick and dirty fix for my use case, but looking at the astropy decorator I suspect there may be some corner cases that still doesn't work.\r\n\r\n\r\n#### Reference Issues/PRs\r\n\r\ncloses #15994 \r\n\r\n\r\n\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__1.3.git",
    "requested_commit": "",
    "mayil_response": "- Apply the `deprecated` decorator to the `GMMBayes` class to issue a `FutureWarning` when the class is instantiated.\n- Ensure that the `__new__` method of the `GMMBayes` class is properly wrapped by the `deprecated` decorator to issue the warning.\n- Modify the `GMMBayes` class definition to use the `deprecated` decorator, passing in the appropriate version and reason for deprecation.\n\n```python\nfrom sklearn.utils.deprecation import deprecated\n\n@deprecated(extra=\"GMMBayes is deprecated in version X.X and will be removed in version Y.Y. Use ZZZ instead.\")\nclass GMMBayes(BaseNB):\n    def __init__(self, n_components=None):\n        # ... existing code ...\n```\n\n- Replace `X.X` with the version in which `GMMBayes` is deprecated and `Y.Y` with the version in which it will be removed.\n- Replace `ZZZ` with the alternative class or method that should be used instead of `GMMBayes`.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn/utils)- [Lines 1 - 104](https://github.com/testbed/scikit-learn__scikit-learn__1.3/blob//sklearn/utils/deprecation.py#L1-L104)\n\n This snippet contains the deprecated decorator which is directly related to the issue of the FutureWarning not being issued. The fix involves modifying the __new__ method within this decorator.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0003495,
        "snippet_processor": 0.04503,
        "issue_star_creation": 0.0381,
        "issue_star_solver": 0.06981000000000001,
        "bouncer": 0.02748
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711737893.140992,
        "relevant_snippets": [
            {
                "code": "import functools\nimport warnings\n\n__all__ = [\"deprecated\"]\n\n\nclass deprecated:\n    \"\"\"Decorator to mark a function or class as deprecated.\n\n    Issue a warning when the function is called/the class is instantiated and\n    adds a warning to the docstring.\n\n    The optional extra argument will be appended to the deprecation message\n    and the docstring. Note: to use this with the default value for extra, put\n    in an empty of parentheses:\n\n    >>> from sklearn.utils import deprecated\n    >>> deprecated()\n    <sklearn.utils.deprecation.deprecated object at ...>\n\n    >>> @deprecated()\n    ... def some_function(): pass\n\n    Parameters\n    ----------\n    extra : str, default=''\n          To be added to the deprecation messages.\n    \"\"\"\n\n    # Adapted from https://wiki.python.org/moin/PythonDecoratorLibrary,\n    # but with many changes.\n\n    def __init__(self, extra=\"\"):\n        self.extra = extra\n\n    def __call__(self, obj):\n        \"\"\"Call method\n\n        Parameters\n        ----------\n        obj : object\n        \"\"\"\n        if isinstance(obj, type):\n            return self._decorate_class(obj)\n        elif isinstance(obj, property):\n            # Note that this is only triggered properly if the `property`\n            # decorator comes before the `deprecated` decorator, like so:\n            #\n            # @deprecated(msg)\n            # @property\n            # def deprecated_attribute_(self):\n            #     ...\n            return self._decorate_property(obj)\n        else:\n            return self._decorate_fun(obj)\n\n    def _decorate_class(self, cls):\n        msg = \"Class %s is deprecated\" % cls.__name__\n        if self.extra:\n            msg += \"; %s\" % self.extra\n\n        new = cls.__new__\n\n        def wrapped(cls, *args, **kwargs):\n            warnings.warn(msg, category=FutureWarning)\n            if new is object.__new__:\n                return object.__new__(cls)\n            return new(cls, *args, **kwargs)\n\n        cls.__new__ = wrapped\n\n        wrapped.__name__ = \"__new__\"\n        wrapped.deprecated_original = new\n\n        return cls\n\n    def _decorate_fun(self, fun):\n        \"\"\"Decorate function fun\"\"\"\n\n        msg = \"Function %s is deprecated\" % fun.__name__\n        if self.extra:\n            msg += \"; %s\" % self.extra\n\n        @functools.wraps(fun)\n        def wrapped(*args, **kwargs):\n            warnings.warn(msg, category=FutureWarning)\n            return fun(*args, **kwargs)\n\n        # Add a reference to the wrapped function so that we can introspect\n        # on function arguments in Python 2 (already works in Python 3)\n        wrapped.__wrapped__ = fun\n\n        return wrapped\n\n    def _decorate_property(self, prop):\n        msg = self.extra\n\n        @property\n        @functools.wraps(prop)\n        def wrapped(*args, **kwargs):\n            warnings.warn(msg, category=FutureWarning)\n            return prop.fget(*args, **kwargs)\n\n        return wrapped",
                "filename": "sklearn/utils/deprecation.py",
                "start_index": 0,
                "end_index": 2917,
                "start_line": 1,
                "end_line": 104,
                "max_line": 115,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "\"\"\"Compatibility fixes for older version of python, numpy and scipy\n\nIf you add content to this file, please give the version of the package\nat which the fix is no longer needed.\n\"\"\"\n# Authors: Emmanuelle Gouillart <emmanuelle.gouillart@normalesup.org>\n#          Gael Varoquaux <gael.varoquaux@normalesup.org>\n#          Fabian Pedregosa <fpedregosa@acm.org>\n#          Lars Buitinck\n#\n# License: BSD 3 clause\n\nimport sys\nfrom importlib import resources\n\nimport numpy as np\nimport scipy\nimport scipy.stats\nimport threadpoolctl\n\nimport sklearn\n\nfrom ..externals._packaging.version import parse as parse_version\nfrom .deprecation import deprecated\n\nnp_version = parse_version(np.__version__)\nsp_version = parse_version(scipy.__version__)\nsp_base_version = parse_version(sp_version.base_version)\n\n\ntry:\n    from scipy.optimize._linesearch import line_search_wolfe1, line_search_wolfe2\nexcept ImportError:  # SciPy < 1.8\n    from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1  # type: ignore  # noqa\n\n\ndef _object_dtype_isnan(X):\n    return X != X\n\n\n# Rename the `method` kwarg to `interpolation` for NumPy < 1.22, because\n# `interpolation` kwarg was deprecated in favor of `method` in NumPy >= 1.22.\ndef _percentile(a, q, *, method=\"linear\", **kwargs):\n    return np.percentile(a, q, interpolation=method, **kwargs)\n\n\nif np_version < parse_version(\"1.22\"):\n    percentile = _percentile\nelse:  # >= 1.22\n    from numpy import percentile  # type: ignore  # noqa\n\n\n# compatibility fix for threadpoolctl >= 3.0.0\n# since version 3 it's possible to setup a global threadpool controller to avoid\n# looping through all loaded shared libraries each time.\n# the global controller is created during the first call to threadpoolctl.\ndef _get_threadpool_controller():\n    if not hasattr(threadpoolctl, \"ThreadpoolController\"):\n        return None\n\n    if not hasattr(sklearn, \"_sklearn_threadpool_controller\"):\n        sklearn._sklearn_threadpool_controller = threadpoolctl.ThreadpoolController()\n\n    return sklearn._sklearn_threadpool_controller\n\n\ndef threadpool_limits(limits=None, user_api=None):\n    controller = _get_threadpool_controller()\n    if controller is not None:\n        return controller.limit(limits=limits, user_api=user_api)\n    else:\n        return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n\n\nthreadpool_limits.__doc__ = threadpoolctl.threadpool_limits.__doc__\n\n\ndef threadpool_info():\n    controller = _get_threadpool_controller()\n    if controller is not None:\n        return controller.info()\n    else:\n        return threadpoolctl.threadpool_info()\n\n\nthreadpool_info.__doc__ = threadpoolctl.threadpool_info.__doc__\n\n\n@deprecated(\n    \"The function `delayed` has been moved from `sklearn.utils.fixes` to \"\n    \"`sklearn.utils.parallel`. This import path will be removed in 1.5.\"\n)\ndef delayed(function):\n    from sklearn.utils.parallel import delayed\n\n    return delayed(function)",
                "filename": "sklearn/utils/fixes.py",
                "start_index": 0,
                "end_index": 2939,
                "start_line": 1,
                "end_line": 96,
                "max_line": 160,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "class _BaseNB(ClassifierMixin, BaseEstimator, metaclass=ABCMeta):",
                "filename": "sklearn/naive_bayes.py",
                "start_index": 1227,
                "end_index": 1292,
                "start_line": 39,
                "end_line": 39,
                "max_line": 1528,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "- :class:`linear_model.LogisticRegression`\n# - :class:`linear_model.GammaRegressor`\n# - :class:`linear_model.PoissonRegressor`\n# - :class:`linear_model.TweedieRegressor`\n\n# %%\n# :class:`~decomposition.MiniBatchNMF`: an online version of NMF\n# --------------------------------------------------------------\n# The new class :class:`~decomposition.MiniBatchNMF` implements a faster but\n# less accurate version of non-negative matrix factorization\n# (:class:`~decomposition.NMF`). :class:`~decomposition.MiniBatchNMF` divides the\n# data into mini-batches and optimizes the NMF model in an online manner by\n# cycling over the mini-batches, making it better suited for large datasets. In\n# particular, it implements `partial_fit`, which can be used for online\n# learning when the data is not readily available from the start, or when the\n# data does not fit into memory.\nimport numpy as np\nfrom sklearn.decomposition import MiniBatchNMF\n\nrng = np.random.RandomState(0)\nn_samples, n_features, n_components = 10, 10, 5\ntrue_W = rng.uniform(size=(n_samples, n_components))\ntrue_H = rng.uniform(size=(n_components, n_features))\nX = true_W @ true_H\n\nnmf = MiniBatchNMF(n_components=n_components, random_state=0)\n\nfor _ in range(10):\n    nmf.partial_fit(X)\n\nW = nmf.transform(X)\nH = nmf.components_\nX_reconstructed = W @ H\n\nprint(\n    f\"relative reconstruction error: \",\n    f\"{np.sum((X - X_reconstructed) ** 2) / np.sum(X**2):.5f}\",\n)\n\n# %%\n# :class:`~cluster.BisectingKMeans`: divide and cluster\n# -----------------------------------------------------\n# The new class :class:`~cluster.BisectingKMeans` is a variant of\n# :class:`~cluster.KMeans`, using divisive hierarchical clustering. Instead of\n# creating all centroids at once, centroids are picked progressively based on a\n# previous clustering: a cluster is split into two new clusters repeatedly\n# until the target number of clusters is reached, giving a hierarchical\n# structure to the clustering.\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans, BisectingKMeans\nimport matplotlib.pyplot as plt\n\nX, _ = make_blobs(n_samples=1000, centers=2, random_state=0)\n\nkm = KMeans(n_clusters=5, random_state=0, n_init=\"auto\").fit(X)\nbisect_km = BisectingKMeans(n_clusters=5, random_state=0).fit(X)\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].scatter(X[:, 0], X[:, 1], s=10, c=km.labels_)\nax[0].scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], s=20, c=\"r\")\nax[0].set_title(\"KMeans\")\n\nax[1].scatter(X[:, 0], X[:, 1], s=10, c=bisect_km.labels_)\nax[1].scatter(\n    bisect_km.cluster_centers_[:, 0], bisect_km.cluster_centers_[:, 1], s=20, c=\"r\"\n)\n_ = ax[1].set_title(\"BisectingKMeans\")",
                "filename": "examples/release_highlights/plot_release_highlights_1_1_0.py",
                "start_index": 5956,
                "end_index": 8623,
                "start_line": 163,
                "end_line": 229,
                "max_line": 229,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "# Author: Mathieu Blondel <mathieu@mblondel.org>\n#         Arnaud Joly <a.joly@ulg.ac.be>\n#         Maheshakya Wijewardena <maheshakya.10@cse.mrt.ac.lk>\n# License: BSD 3 clause\n\nimport warnings\nfrom numbers import Integral, Real\n\nimport numpy as np\nimport scipy.sparse as sp\n\nfrom .base import (\n    BaseEstimator,\n    ClassifierMixin,\n    MultiOutputMixin,\n    RegressorMixin,\n    _fit_context,\n)\nfrom .utils import check_random_state\nfrom .utils._param_validation import Interval, StrOptions\nfrom .utils.multiclass import class_distribution\nfrom .utils.random import _random_choice_csc\nfrom .utils.stats import _weighted_percentile\nfrom .utils.validation import (\n    _check_sample_weight,\n    _num_samples,\n    check_array,\n    check_consistent_length,\n    check_is_fitted,\n)",
                "filename": "sklearn/dummy.py",
                "start_index": 0,
                "end_index": 778,
                "start_line": 1,
                "end_line": 682,
                "max_line": 682,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "from sklearn.pipeline import make_pipeline\n\nX, y = make_classification(random_state=0)\n\nwith TemporaryDirectory(prefix=\"sklearn_cache_\") as tmpdir:\n    estimator = make_pipeline(\n        KNeighborsTransformer(n_neighbors=10, mode=\"distance\"),\n        Isomap(n_neighbors=10, metric=\"precomputed\"),\n        memory=tmpdir,\n    )\n    estimator.fit(X)\n\n    # We can decrease the number of neighbors and the graph will not be\n    # recomputed.\n    estimator.set_params(isomap__n_neighbors=5)\n    estimator.fit(X)\n\n# %%\n# KNN Based Imputation\n# ------------------------------------\n# We now support imputation for completing missing values using k-Nearest\n# Neighbors.\n#\n# Each sample's missing values are imputed using the mean value from\n# ``n_neighbors`` nearest neighbors found in the training set. Two samples are\n# close if the features that neither is missing are close.\n# By default, a euclidean distance metric\n# that supports missing values,\n# :func:`~sklearn.metrics.pairwise.nan_euclidean_distances`, is used to find the nearest\n# neighbors.\n#\n# Read more in the :ref:`User Guide <knnimpute>`.\n\nfrom sklearn.impute import KNNImputer\n\nX = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\nimputer = KNNImputer(n_neighbors=2)\nprint(imputer.fit_transform(X))\n\n# %%\n# Tree pruning\n# ------------\n#\n# It is now possible to prune most tree-based estimators once the trees are\n# built. The pruning is based on minimal cost-complexity. Read more in the\n# :ref:`User Guide <minimal_cost_complexity_pruning>` for details.\n\nX, y = make_classification(random_state=0)\n\nrf = RandomForestClassifier(random_state=0, ccp_alpha=0).fit(X, y)\nprint(\n    \"Average number of nodes without pruning {:.1f}\".format(\n        np.mean([e.tree_.node_count for e in rf.estimators_])\n    )\n)\n\nrf = RandomForestClassifier(random_state=0, ccp_alpha=0.05).fit(X, y)\nprint(\n    \"Average number of nodes with pruning {:.1f}\".format(\n        np.mean([e.tree_.node_count for e in rf.estimators_])\n    )\n)\n\n# %%\n# Retrieve dataframes from OpenML\n# -------------------------------\n# :func:`datasets.fetch_openml` can now return pandas dataframe and thus\n# properly handle datasets with heterogeneous data:\n\nfrom sklearn.datasets import fetch_openml\n\ntitanic = fetch_openml(\"titanic\", version=1, as_frame=True, parser=\"pandas\")\nprint(titanic.data.head()[[\"pclass\", \"embarked\"]])\n\n# %%\n# Checking scikit-learn compatibility of an estimator\n# ---------------------------------------------------\n# Developers can check the compatibility of their scikit-learn compatible\n# estimators using :func:`~utils.estimator_checks.check_estimator`. For\n# instance, the ``check_estimator(LinearSVC())`` passes.\n#\n# We now provide a ``pytest`` specific decorator which allows ``pytest``\n# to run all checks independently and report the checks that are failing.\n#\n# ..note::\n#   This entry was slightly updated in version 0.24, where passing classes\n#   isn't supported anymore: pass instances instead.",
                "filename": "examples/release_highlights/plot_release_highlights_0_22_0.py",
                "start_index": 5945,
                "end_index": 8900,
                "start_line": 85,
                "end_line": 248,
                "max_line": 282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_classifiers_one_label(name, classifier_orig):\n    error_string_fit = \"Classifier can't train when only one class is present.\"\n    error_string_predict = \"Classifier can't predict when only one class is present.\"\n    rnd = np.random.RandomState(0)\n    X_train = rnd.uniform(size=(10, 3))\n    X_test = rnd.uniform(size=(10, 3))\n    y = np.ones(10)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        classifier = clone(classifier_orig)\n        with raises(\n            ValueError, match=\"class\", may_pass=True, err_msg=error_string_fit\n        ) as cm:\n            classifier.fit(X_train, y)\n\n        if cm.raised_and_matched:\n            # ValueError was raised with proper error message\n            return\n\n        assert_array_equal(classifier.predict(X_test), y, err_msg=error_string_predict)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_classifiers_one_label_sample_weights(name, classifier_orig):\n    \"\"\"Check that classifiers accepting sample_weight fit or throws a ValueError with\n    an explicit message if the problem is reduced to one class.\n    \"\"\"\n    error_fit = (\n        f\"{name} failed when fitted on one label after sample_weight trimming. Error \"\n        \"message is not explicit, it should have 'class'.\"\n    )\n    error_predict = f\"{name} prediction results should only output the remaining class.\"\n    rnd = np.random.RandomState(0)\n    # X should be square for test on SVC with precomputed kernel\n    X_train = rnd.uniform(size=(10, 10))\n    X_test = rnd.uniform(size=(10, 10))\n    y = np.arange(10) % 2\n    sample_weight = y.copy()  # select a single class\n    classifier = clone(classifier_orig)\n\n    if has_fit_parameter(classifier, \"sample_weight\"):\n        match = [r\"\\bclass(es)?\\b\", error_predict]\n        err_type, err_msg = (AssertionError, ValueError), error_fit\n    else:\n        match = r\"\\bsample_weight\\b\"\n        err_type, err_msg = (TypeError, ValueError), None\n\n    with raises(err_type, match=match, may_pass=True, err_msg=err_msg) as cm:\n        classifier.fit(X_train, y, sample_weight=sample_weight)\n        if cm.raised_and_matched:\n            # raise the proper error type with the proper error message\n            return\n        # for estimators that do not fail, they should be able to predict the only\n        # class remaining during fit\n        assert_array_equal(\n            classifier.predict(X_test), np.ones(10), err_msg=error_predict\n        )",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 79371,
                "end_index": 81868,
                "start_line": 181,
                "end_line": 4639,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "class _BaseNMF(ClassNamePrefixFeaturesOutMixin, TransformerMixin, BaseEstimator, ABC):",
                "filename": "sklearn/decomposition/_nmf.py",
                "start_index": 35978,
                "end_index": 36064,
                "start_line": 1138,
                "end_line": 1138,
                "max_line": 2443,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_dont_overwrite_parameters(name, estimator_orig):\n    # check that fit method only changes or sets private attributes\n    if hasattr(estimator_orig.__init__, \"deprecated_original\"):\n        # to not check deprecated classes\n        return\n    estimator = clone(estimator_orig)\n    rnd = np.random.RandomState(0)\n    X = 3 * rnd.uniform(size=(20, 3))\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = X[:, 0].astype(int)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    if hasattr(estimator, \"n_components\"):\n        estimator.n_components = 1\n    if hasattr(estimator, \"n_clusters\"):\n        estimator.n_clusters = 1\n\n    set_random_state(estimator, 1)\n    dict_before_fit = estimator.__dict__.copy()\n    estimator.fit(X, y)\n\n    dict_after_fit = estimator.__dict__\n\n    public_keys_after_fit = [\n        key for key in dict_after_fit.keys() if _is_public_parameter(key)\n    ]\n\n    attrs_added_by_fit = [\n        key for key in public_keys_after_fit if key not in dict_before_fit.keys()\n    ]\n\n    # check that fit doesn't add any public attribute\n    assert not attrs_added_by_fit, (\n        \"Estimator adds public attribute(s) during\"\n        \" the fit method.\"\n        \" Estimators are only allowed to add private attributes\"\n        \" either started with _ or ended\"\n        \" with _ but %s added\"\n        % \", \".join(attrs_added_by_fit)\n    )\n\n    # check that fit doesn't change any public attribute\n    attrs_changed_by_fit = [\n        key\n        for key in public_keys_after_fit\n        if (dict_before_fit[key] is not dict_after_fit[key])\n    ]\n\n    assert not attrs_changed_by_fit, (\n        \"Estimator changes public attribute(s) during\"\n        \" the fit method. Estimators are only allowed\"\n        \" to change attributes started\"\n        \" or ended with _, but\"\n        \" %s changed\"\n        % \", \".join(attrs_changed_by_fit)\n    )\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_fit2d_predict1d(name, estimator_orig):\n    # check by fitting a 2d array and predicting with a 1d array\n    rnd = np.random.RandomState(0)\n    X = 3 * rnd.uniform(size=(20, 3))\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = X[:, 0].astype(int)\n    estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    if hasattr(estimator, \"n_components\"):\n        estimator.n_components = 1\n    if hasattr(estimator, \"n_clusters\"):\n        estimator.n_clusters = 1\n\n    set_random_state(estimator, 1)\n    estimator.fit(X, y)\n\n    for method in [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]:\n        if hasattr(estimator, method):\n            assert_raise_message(\n                ValueError, \"Reshape your data\", getattr(estimator, method), X[0]\n            )",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 48853,
                "end_index": 51626,
                "start_line": 181,
                "end_line": 4630,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_estimators_partial_fit_n_features(name, estimator_orig):\n    # check if number of features changes between calls to partial_fit.\n    if not hasattr(estimator_orig, \"partial_fit\"):\n        return\n    estimator = clone(estimator_orig)\n    X, y = make_blobs(n_samples=50, random_state=1)\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n\n    try:\n        if is_classifier(estimator):\n            classes = np.unique(y)\n            estimator.partial_fit(X, y, classes=classes)\n        else:\n            estimator.partial_fit(X, y)\n    except NotImplementedError:\n        return\n\n    with raises(\n        ValueError,\n        err_msg=(\n            f\"The estimator {name} does not raise an error when the \"\n            \"number of features changes between calls to partial_fit.\"\n        ),\n    ):\n        estimator.partial_fit(X[:, :-1], y)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 72345,
                "end_index": 73285,
                "start_line": 181,
                "end_line": 2142,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                "sha": "",
                "context_relevance": 0.2
            }
        ],
        "classification": "other",
        "snippet_processor_task": {
            "sklearn/utils/deprecation.py": [
                {
                    "chunk": {
                        "code": "import functools\nimport warnings\n\n__all__ = [\"deprecated\"]\n\n\nclass deprecated:\n    \"\"\"Decorator to mark a function or class as deprecated.\n\n    Issue a warning when the function is called/the class is instantiated and\n    adds a warning to the docstring.\n\n    The optional extra argument will be appended to the deprecation message\n    and the docstring. Note: to use this with the default value for extra, put\n    in an empty of parentheses:\n\n    >>> from sklearn.utils import deprecated\n    >>> deprecated()\n    <sklearn.utils.deprecation.deprecated object at ...>\n\n    >>> @deprecated()\n    ... def some_function(): pass\n\n    Parameters\n    ----------\n    extra : str, default=''\n          To be added to the deprecation messages.\n    \"\"\"\n\n    # Adapted from https://wiki.python.org/moin/PythonDecoratorLibrary,\n    # but with many changes.\n\n    def __init__(self, extra=\"\"):\n        self.extra = extra\n\n    def __call__(self, obj):\n        \"\"\"Call method\n\n        Parameters\n        ----------\n        obj : object\n        \"\"\"\n        if isinstance(obj, type):\n            return self._decorate_class(obj)\n        elif isinstance(obj, property):\n            # Note that this is only triggered properly if the `property`\n            # decorator comes before the `deprecated` decorator, like so:\n            #\n            # @deprecated(msg)\n            # @property\n            # def deprecated_attribute_(self):\n            #     ...\n            return self._decorate_property(obj)\n        else:\n            return self._decorate_fun(obj)\n\n    def _decorate_class(self, cls):\n        msg = \"Class %s is deprecated\" % cls.__name__\n        if self.extra:\n            msg += \"; %s\" % self.extra\n\n        new = cls.__new__\n\n        def wrapped(cls, *args, **kwargs):\n            warnings.warn(msg, category=FutureWarning)\n            if new is object.__new__:\n                return object.__new__(cls)\n            return new(cls, *args, **kwargs)\n\n        cls.__new__ = wrapped\n\n        wrapped.__name__ = \"__new__\"\n        wrapped.deprecated_original = new\n\n        return cls\n\n    def _decorate_fun(self, fun):\n        \"\"\"Decorate function fun\"\"\"\n\n        msg = \"Function %s is deprecated\" % fun.__name__\n        if self.extra:\n            msg += \"; %s\" % self.extra\n\n        @functools.wraps(fun)\n        def wrapped(*args, **kwargs):\n            warnings.warn(msg, category=FutureWarning)\n            return fun(*args, **kwargs)\n\n        # Add a reference to the wrapped function so that we can introspect\n        # on function arguments in Python 2 (already works in Python 3)\n        wrapped.__wrapped__ = fun\n\n        return wrapped\n\n    def _decorate_property(self, prop):\n        msg = self.extra\n\n        @property\n        @functools.wraps(prop)\n        def wrapped(*args, **kwargs):\n            warnings.warn(msg, category=FutureWarning)\n            return prop.fget(*args, **kwargs)\n\n        return wrapped",
                        "filename": "sklearn/utils/deprecation.py",
                        "start_index": 0,
                        "end_index": 2917,
                        "start_line": 1,
                        "end_line": 104,
                        "max_line": 115,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__1.3",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the deprecated decorator which is directly related to the issue of the FutureWarning not being issued. The fix involves modifying the __new__ method within this decorator."
                }
            ]
        },
        "solution_task": "- Apply the `deprecated` decorator to the `GMMBayes` class to issue a `FutureWarning` when the class is instantiated.\n- Ensure that the `__new__` method of the `GMMBayes` class is properly wrapped by the `deprecated` decorator to issue the warning.\n- Modify the `GMMBayes` class definition to use the `deprecated` decorator, passing in the appropriate version and reason for deprecation.\n\n```python\nfrom sklearn.utils.deprecation import deprecated\n\n@deprecated(extra=\"GMMBayes is deprecated in version X.X and will be removed in version Y.Y. Use ZZZ instead.\")\nclass GMMBayes(BaseNB):\n    def __init__(self, n_components=None):\n        # ... existing code ...\n```\n\n- Replace `X.X` with the version in which `GMMBayes` is deprecated and `Y.Y` with the version in which it will be removed.\n- Replace `ZZZ` with the alternative class or method that should be used instead of `GMMBayes`.",
        "bouncer_response": {
            "score": 7,
            "criteria": "RESPONSES that are highly relevant, offering clear and comprehensive guidance or solutions for the described bug, should score between 7 and 9.",
            "supporting_evidence": "The RESPONSE provides a clear and actionable solution to the issue of the FutureWarning not being issued for the deprecated class. It suggests applying the `deprecated` decorator to the `GMMBayes` class and ensuring that the `__new__` method is properly wrapped by the decorator. This directly addresses the problem described in the PROMPT. The RESPONSE also includes a code snippet that demonstrates how to use the `deprecated` decorator, which is helpful for implementing the fix. However, the RESPONSE does not address the part of the PROMPT discussing the potential use of a generic deprecation package or the interest in collaboration with other projects on this matter. Therefore, the RESPONSE is not fully comprehensive in addressing all aspects of the PROMPT.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711738151.830473,
        "result": "- Apply the `deprecated` decorator to the `GMMBayes` class to issue a `FutureWarning` when the class is instantiated.\n- Ensure that the `__new__` method of the `GMMBayes` class is properly wrapped by the `deprecated` decorator to issue the warning.\n- Modify the `GMMBayes` class definition to use the `deprecated` decorator, passing in the appropriate version and reason for deprecation.\n\n```python\nfrom sklearn.utils.deprecation import deprecated\n\n@deprecated(extra=\"GMMBayes is deprecated in version X.X and will be removed in version Y.Y. Use ZZZ instead.\")\nclass GMMBayes(BaseNB):\n    def __init__(self, n_components=None):\n        # ... existing code ...\n```\n\n- Replace `X.X` with the version in which `GMMBayes` is deprecated and `Y.Y` with the version in which it will be removed.\n- Replace `ZZZ` with the alternative class or method that should be used instead of `GMMBayes`.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__1.3/tree//sklearn/utils)- [Lines 1 - 104](https://github.com/testbed/scikit-learn__scikit-learn__1.3/blob//sklearn/utils/deprecation.py#L1-L104)\n\n This snippet contains the deprecated decorator which is directly related to the issue of the FutureWarning not being issued. The fix involves modifying the __new__ method within this decorator.",
        "context_relevance": 0.34,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers the PROMPT completely.\nSupporting Evidence: The RESPONSE directly addresses the issue described in the PROMPT by providing a solution to ensure that a `FutureWarning` is issued when the `GMMBayes` class is instantiated. It suggests applying the `deprecated` decorator to the class and ensuring the `__new__` method is wrapped correctly. The RESPONSE also includes a code snippet that demonstrates how to modify the class definition with the `deprecated` decorator, which is the exact issue raised in the PROMPT. The RESPONSE is fully relevant to the technical details and the context of the problem described, including the reference to the GitHub issue and the specific versions for deprecation."
        },
        "qa_relevance": 1.0
    }
}