{
    "id": "scikit-learn__scikit-learn-13454",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
    "task_id": 2790667893274542535,
    "title": "Confusing error message in OrdinalEncoder when passing single list of categories",
    "body": "Small example:\r\n\r\n```py\r\nIn [38]: from sklearn.preprocessing import OrdinalEncoder \r\n\r\nIn [39]: X = np.array([['L', 'M', 'S', 'M', 'L']], dtype=object).T\r\n\r\nIn [40]: ohe = OrdinalEncoder(categories=['S', 'M', 'L'])\r\n\r\nIn [41]: ohe.fit(X)\r\n...\r\nValueError: Shape mismatch: if n_values is an array, it has to be of shape (n_features,).\r\n```\r\n\r\nThe error message is still using the old `n_values`, which makes it very confusing.\r\n\r\n(another issue is that we might be able to actually detect this case)\r\n\r\n#### Versions\r\n```\r\nSystem:\r\n    python: 3.7.1 | packaged by conda-forge | (default, Feb 18 2019, 01:42:00)  [GCC 7.3.0]\r\nexecutable: /home/joris/miniconda3/bin/python\r\n   machine: Linux-4.4.0-142-generic-x86_64-with-debian-stretch-sid\r\n\r\nBLAS:\r\n    macros: HAVE_CBLAS=None\r\n  lib_dirs: /home/joris/miniconda3/lib\r\ncblas_libs: openblas, openblas\r\n\r\nPython deps:\r\n       pip: 19.0.2\r\nsetuptools: 40.8.0\r\n   sklearn: 0.20.2\r\n     numpy: 1.16.1\r\n     scipy: 1.2.1\r\n    Cython: None\r\n    pandas: 0.23.4\r\n```\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.21.git",
    "requested_commit": "",
    "mayil_response": "- The error message indicates that the `categories` parameter is expected to be a list of arrays, where each array corresponds to the categories for a feature. The provided `categories` parameter is a single list, which is causing the shape mismatch error.\n- The correct usage of the `OrdinalEncoder` with a custom list of categories should be as follows:\n\n```py\nfrom sklearn.preprocessing import OrdinalEncoder\nimport numpy as np\n\nX = np.array([['L', 'M', 'S', 'M', 'L']], dtype=object).T\nohe = OrdinalEncoder(categories=[['S', 'M', 'L']])\nohe.fit(X)\n```\n\n- The `categories` parameter should be a list containing a single list of categories for the one feature in `X`.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn) \u2192 [preprocessing](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn/preprocessing)- [Lines 1463 - 1557](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/preprocessing/_encoders.py#L1463-L1557)\n\n This snippet contains the error message logic for the OrdinalEncoder, which is relevant to the issue as the error message needs to be updated. \n\n\n   - [Lines 74 - 91](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/preprocessing/_encoders.py#L74-L91)\n\n This snippet checks the shape of the categories array, which is directly related to the issue reported, as the error message mentions a shape mismatch.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0008225,
        "snippet_processor": 0.051160000000000004,
        "issue_star_creation": 0.035809999999999995,
        "issue_star_solver": 0.07194,
        "bouncer": 0.02488
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711740446.661814,
        "relevant_snippets": [
            {
                "code": "if self.handle_unknown == \"use_encoded_value\":\n            for cardinality in cardinalities:\n                if 0 <= self.unknown_value < cardinality:\n                    raise ValueError(\n                        \"The used value for unknown_value \"\n                        f\"{self.unknown_value} is one of the \"\n                        \"values already used for encoding the \"\n                        \"seen categories.\"\n                    )\n\n        if self._missing_indices:\n            if np.dtype(self.dtype).kind != \"f\" and is_scalar_nan(\n                self.encoded_missing_value\n            ):\n                raise ValueError(\n                    \"There are missing values in features \"\n                    f\"{list(self._missing_indices)}. For OrdinalEncoder to \"\n                    f\"encode missing values with dtype: {self.dtype}, set \"\n                    \"encoded_missing_value to a non-nan value, or \"\n                    \"set dtype to a float\"\n                )\n\n            if not is_scalar_nan(self.encoded_missing_value):\n                # Features are invalid when they contain a missing category\n                # and encoded_missing_value was already used to encode a\n                # known category\n                invalid_features = [\n                    cat_idx\n                    for cat_idx, cardinality in enumerate(cardinalities)\n                    if cat_idx in self._missing_indices\n                    and 0 <= self.encoded_missing_value < cardinality\n                ]\n\n                if invalid_features:\n                    # Use feature names if they are available\n                    if hasattr(self, \"feature_names_in_\"):\n                        invalid_features = self.feature_names_in_[invalid_features]\n                    raise ValueError(\n                        f\"encoded_missing_value ({self.encoded_missing_value}) \"\n                        \"is already used to encode a known category in features: \"\n                        f\"{invalid_features}\"\n                    )\n\n        return self",
                "filename": "sklearn/preprocessing/_encoders.py",
                "start_index": 60923,
                "end_index": 62960,
                "start_line": 1463,
                "end_line": 1557,
                "max_line": 1674,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "from sklearn.preprocessing import OrdinalEncoder\nimport numpy as np\n\nX = np.array(\n    [[\"dog\"] * 5 + [\"cat\"] * 20 + [\"rabbit\"] * 10 + [\"snake\"] * 3], dtype=object\n).T\nenc = OrdinalEncoder(min_frequency=6).fit(X)\nenc.infrequent_categories_",
                "filename": "examples/release_highlights/plot_release_highlights_1_3_0.py",
                "start_index": 5955,
                "end_index": 6194,
                "start_line": 149,
                "end_line": 156,
                "max_line": 156,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "default='error'\n        Specifies the way unknown categories are handled during :meth:`transform`.\n\n        - 'error' : Raise an error if an unknown category is present during transform.\n        - 'ignore' : When an unknown category is encountered during\n          transform, the resulting one-hot encoded columns for this feature\n          will be all zeros. In the inverse transform, an unknown category\n          will be denoted as None.\n        - 'infrequent_if_exist' : When an unknown category is encountered\n          during transform, the resulting one-hot encoded columns for this\n          feature will map to the infrequent category if it exists. The\n          infrequent category will be mapped to the last position in the\n          encoding. During inverse transform, an unknown category will be\n          mapped to the category denoted `'infrequent'` if it exists. If the\n          `'infrequent'` category does not exist, then :meth:`transform` and\n          :meth:`inverse_transform` will handle an unknown category as with\n          `handle_unknown='ignore'`. Infrequent categories exist based on\n          `min_frequency` and `max_categories`. Read more in the\n          :ref:`User Guide <encoder_infrequent_categories>`.\n\n        .. versionchanged:: 1.1\n            `'infrequent_if_exist'` was added to automatically handle unknown\n            categories and infrequent categories.\n\n    min_frequency : int or float, default=None\n        Specifies the minimum frequency below which a category will be\n        considered infrequent.\n\n        - If `int`, categories with a smaller cardinality will be considered\n          infrequent.\n\n        - If `float`, categories with a smaller cardinality than\n          `min_frequency * n_samples`  will be considered infrequent.\n\n        .. versionadded:: 1.1\n            Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n\n    max_categories : int, default=None\n        Specifies an upper limit to the number of output features for each input\n        feature when considering infrequent categories. If there are infrequent\n        categories, `max_categories` includes the category representing the\n        infrequent categories along with the frequent categories. If `None`,\n        there is no limit to the number of output features.\n\n        .. versionadded:: 1.1\n            Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n\n    feature_name_combiner : \"concat\" or callable, default=\"concat\"\n        Callable with signature `def callable(input_feature, category)` that returns a\n        string. This is used to create feature names to be returned by\n        :meth:`get_feature_names_out`.\n\n        `\"concat\"` concatenates encoded feature name and category with\n        `feature + \"_\" + str(category)`.E.g. feature X with values 1, 6, 7 create\n        feature names `X_1, X_6, X_7`.\n\n        .. versionadded:: 1.3\n\n    Attributes\n    ----------\n    categories_ : list of arrays\n        The categories of each feature determined during fitting\n        (in order of the features in X and corresponding with the output\n        of ``transform``). This includes the category specified in ``drop``\n        (if any).\n\n    drop_idx_ : array of shape (n_features,)\n        - ``drop_idx_[i]`` is the index in ``categories_[i]`` of the category\n          to be dropped for each feature.\n        - ``drop_idx_[i] = None`` if no category is to be dropped from the\n          feature with index ``i``, e.g. when `drop='if_binary'` and the\n          feature isn't binary.\n        - ``drop_idx_ = None`` if all the transformed features will be\n          retained.\n\n        If infrequent categories are enabled by setting `min_frequency` or\n        `max_categories` to a non-default value and `drop_idx[i]` corresponds\n        to a infrequent category, then the entire infrequent category is\n        dropped.\n\n        .. versionchanged:: 0.23\n           Added the possibility to contain `None` values.\n\n    infrequent_categories_ : list of ndarray\n        Defined only if infrequent categories are enabled by setting\n        `min_frequency` or `max_categories` to a non-default value.\n        `infrequent_categories_[i]` are the infrequent categories for feature\n        `i`. If the feature `i` has no infrequent categories\n        `infrequent_categories_[i]` is None.\n\n        .. versionadded:: 1.1\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 1.0\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    feature_name_combiner : callable or None\n        Callable with signature `def callable(input_feature, category)` that returns a\n        string. This is used to create feature names to be returned by\n        :meth:`get_feature_names_out`.\n\n        .. versionadded:: 1.3\n\n    See Also\n    --------\n    OrdinalEncoder : Performs an ordinal (integer)\n      encoding of the categorical features.\n    TargetEncoder : Encodes categorical features using the target.\n    sklearn.feature_extraction.DictVectorizer : Performs a one-hot encoding of\n      dictionary items (also handles string-valued features).\n    sklearn.feature_extraction.FeatureHasher : Performs an approximate one-hot\n      encoding of dictionary items or strings.\n    LabelBinarizer : Binarizes labels in a one-vs-all\n      fashion.\n    MultiLabelBinarizer : Transforms between iterable of\n      iterables and a multilabel format, e.g. a (samples x classes) binary\n      matrix indicating the presence of a class label.\n\n    Examples\n    --------\n    Given a dataset with two features, we let the encoder find the unique\n    values per feature and transform the data to a binary one-hot encoding.\n\n    >>> from sklearn.preprocessing import OneHotEncoder\n\n    One can discard categories not seen during `fit`:\n\n    >>> enc = OneHotEncoder(handle_unknown='ignore')\n    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    >>> enc.fit(X)\n    OneHotEncoder(handle_unknown='ignore')\n    >>> enc.categories_\n    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n    >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n    array([[1., 0., 1., 0., 0.],\n           [0., 1., 0., 0., 0.]])\n    >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n    array([['Male', 1],\n           [None, 2]], dtype=object)\n    >>> enc.get_feature_names_out(['gender', 'group'])\n    array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'], ...)\n\n    One can always drop the first column for each feature:\n\n    >>> drop_enc = OneHotEncoder(drop='first').fit(X)\n    >>> drop_enc.categories_\n    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n    >>> drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n    array([[0., 0., 0.],\n           [1., 1., 0.]])\n\n    Or drop a column for feature only having 2 categories:\n\n    >>> drop_binary_enc = OneHotEncoder(drop='if_binary').fit(X)\n    >>> drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n    array([[0., 1., 0., 0.],\n           [1., 0., 1., 0.]])\n\n    One can change the way feature names are created.\n\n    >>> def custom_combiner(feature, category):\n    ...     return str(feature) + \"_\" + type(category).__name__ + \"_\" + str(category)\n    >>> custom_fnames_enc = OneHotEncoder(feature_name_combiner=custom_combiner).fit(X)\n    >>> custom_fnames_enc.get_feature_names_out()\n    array(['x0_str_Female', 'x0_str_Male', 'x1_int_1', 'x1_int_2', 'x1_int_3'],\n          dtype=object)\n\n    Infrequent categories are enabled by setting `max_categories` or `min_frequency`.\n\n    >>> import numpy as np\n    >>> X = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3], dtype=object).T\n    >>> ohe = OneHotEncoder(max_categories=3, sparse_output=False).fit(X)\n    >>> ohe.infrequent_categories_\n    [array(['a', 'd'], dtype=object)]\n    >>> ohe.transform([[\"a\"], [\"b\"]])\n    array([[0., 0., 1.],\n           [1., 0., 0.]])\n    \"\"\"",
                "filename": "sklearn/preprocessing/_encoders.py",
                "start_index": 21466,
                "end_index": 29587,
                "start_line": 531,
                "end_line": 1603,
                "max_line": 1674,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"\n    Encode categorical features as an integer array.\n\n    The input to this transformer should be an array-like of integers or\n    strings, denoting the values taken on by categorical (discrete) features.\n    The features are converted to ordinal integers. This results in\n    a single column of integers (0 to n_categories - 1) per feature.\n\n    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n\n    .. versionadded:: 0.20\n\n    Parameters\n    ----------\n    categories : 'auto' or a list of array-like, default='auto'\n        Categories (unique values) per feature:\n\n        - 'auto' : Determine categories automatically from the training data.\n        - list : ``categories[i]`` holds the categories expected in the ith\n          column. The passed categories should not mix strings and numeric\n          values, and should be sorted in case of numeric values.\n\n        The used categories can be found in the ``categories_`` attribute.\n\n    dtype : number type, default=np.float64\n        Desired dtype of output.\n\n    handle_unknown : {'error', 'use_encoded_value'}, default='error'\n        When set to 'error' an error will be raised in case an unknown\n        categorical feature is present during transform. When set to\n        'use_encoded_value', the encoded value of unknown categories will be\n        set to the value given for the parameter `unknown_value`. In\n        :meth:`inverse_transform`, an unknown category will be denoted as None.\n\n        .. versionadded:: 0.24\n\n    unknown_value : int or np.nan, default=None\n        When the parameter handle_unknown is set to 'use_encoded_value', this\n        parameter is required and will set the encoded value of unknown\n        categories. It has to be distinct from the values used to encode any of\n        the categories in `fit`. If set to np.nan, the `dtype` parameter must\n        be a float dtype.\n\n        .. versionadded:: 0.24\n\n    encoded_missing_value : int or np.nan, default=np.nan\n        Encoded value of missing categories. If set to `np.nan`, then the `dtype`\n        parameter must be a float dtype.\n\n        .. versionadded:: 1.1\n\n    min_frequency : int or float, default=None\n        Specifies the minimum frequency below which a category will be\n        considered infrequent.\n\n        - If `int`, categories with a smaller cardinality will be considered\n          infrequent.\n\n        - If `float`, categories with a smaller cardinality than\n          `min_frequency * n_samples`  will be considered infrequent.\n\n        .. versionadded:: 1.3\n            Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n\n    max_categories : int, default=None\n        Specifies an upper limit to the number of output categories for each input\n        feature when considering infrequent categories. If there are infrequent\n        categories, `max_categories` includes the category representing the\n        infrequent categories along with the frequent categories. If `None`,\n        there is no limit to the number of output features.\n\n        `max_categories` do **not** take into account missing or unknown\n        categories. Setting `unknown_value` or `encoded_missing_value` to an\n        integer will increase the number of unique integer codes by one each.\n        This can result in up to `max_categories + 2` integer codes.\n\n        .. versionadded:: 1.3\n            Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n\n    Attributes\n    ----------\n    categories_ : list of arrays\n        The categories of each feature determined during ``fit`` (in order of\n        the features in X and corresponding with the output of ``transform``).\n        This does not include categories that weren't seen during ``fit``.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 1.0\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    infrequent_categories_ : list of ndarray\n        Defined only if infrequent categories are enabled by setting\n        `min_frequency` or `max_categories` to a non-default value.\n        `infrequent_categories_[i]` are the infrequent categories for feature\n        `i`. If the feature `i` has no infrequent categories\n        `infrequent_categories_[i]` is None.\n\n        .. versionadded:: 1.3\n\n    See Also\n    --------\n    OneHotEncoder : Performs a one-hot encoding of categorical features. This encoding\n        is suitable for low to medium cardinality categorical variables, both in\n        supervised and unsupervised settings.\n    TargetEncoder : Encodes categorical features using supervised signal\n        in a classification or regression pipeline. This encoding is typically\n        suitable for high cardinality categorical variables.\n    LabelEncoder : Encodes target labels with values between 0 and\n        ``n_classes-1``.\n\n    Notes\n    -----\n    With a high proportion of `nan` values, inferring categories becomes slow with\n    Python versions before 3.10. The handling of `nan` values was improved\n    from Python 3.10 onwards, (c.f.\n    `bpo-43475 <https://github.com/python/cpython/issues/87641>`_).\n\n    Examples\n    --------\n    Given a dataset with two features, we let the encoder find the unique\n    values per feature and transform the data to an ordinal encoding.\n\n    >>> from sklearn.preprocessing import OrdinalEncoder\n    >>> enc = OrdinalEncoder()\n    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    >>> enc.fit(X)\n    OrdinalEncoder()\n    >>> enc.categories_\n    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n    >>> enc.transform([['Female', 3], ['Male', 1]])\n    array([[0., 2.],\n           [1., 0.]])\n\n    >>> enc.inverse_transform([[1, 0], [0, 1]])\n    array([['Male', 1],\n           ['Female', 2]], dtype=object)\n\n    By default, :class:`OrdinalEncoder` is lenient towards missing values by\n    propagating them.\n\n    >>> import numpy as np\n    >>> X = [['Male', 1], ['Female', 3], ['Female', np.nan]]\n    >>> enc.fit_transform(X)\n    array([[ 1.,  0.],\n           [ 0.,  1.],\n           [ 0., nan]])\n\n    You can use the parameter `encoded_missing_value` to encode missing values.\n\n    >>> enc.set_params(encoded_missing_value=-1).fit_transform(X)\n    array([[ 1.,  0.],\n           [ 0.,  1.],\n           [ 0., -1.]])\n\n    Infrequent categories are enabled by setting `max_categories` or `min_frequency`.\n    In the following example, \"a\" and \"d\" are considered infrequent and grouped\n    together into a single category, \"b\" and \"c\" are their own categories, unknown\n    values are encoded as 3 and missing values are encoded as 4.\n\n    >>> X_train = np.array(\n    ...     [[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3 + [np.nan]],\n    ...     dtype=object).T\n    >>> enc = OrdinalEncoder(\n    ...     handle_unknown=\"use_encoded_value\", unknown_value=3,\n    ...     max_categories=3, encoded_missing_value=4)\n    >>> _ = enc.fit(X_train)\n    >>> X_test = np.array([[\"a\"], [\"b\"], [\"c\"], [\"d\"], [\"e\"], [np.nan]], dtype=object)\n    >>> enc.transform(X_test)\n    array([[2.],\n           [0.],\n           [1.],\n           [2.],\n           [3.],\n           [4.]])\n    \"\"\"",
                "filename": "sklearn/preprocessing/_encoders.py",
                "start_index": 49615,
                "end_index": 56949,
                "start_line": 23,
                "end_line": 1603,
                "max_line": 1674,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "# More details in the :ref:`User Guide <target_encoder>`.\nimport numpy as np\nfrom sklearn.preprocessing import TargetEncoder\n\nX = np.array([[\"cat\"] * 30 + [\"dog\"] * 20 + [\"snake\"] * 38], dtype=object).T\ny = [90.3] * 30 + [20.4] * 20 + [21.2] * 38\n\nenc = TargetEncoder(random_state=0)\nX_trans = enc.fit_transform(X, y)\n\nenc.encodings_\n\n# %%\n# Missing values support in decision trees\n# ----------------------------------------\n# The classes :class:`tree.DecisionTreeClassifier` and\n# :class:`tree.DecisionTreeRegressor` now support missing values. For each potential\n# threshold on the non-missing data, the splitter will evaluate the split with all the\n# missing values going to the left node or the right node.\n# More details in the :ref:`User Guide <tree_missing_value_support>`.\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n\nX = np.array([0, 1, 6, np.nan]).reshape(-1, 1)\ny = [0, 0, 1, 1]\n\ntree = DecisionTreeClassifier(random_state=0).fit(X, y)\ntree.predict(X)\n\n# %%\n# New display `model_selection.ValidationCurveDisplay`\n# ----------------------------------------------------\n# :class:`model_selection.ValidationCurveDisplay` is now available to plot results\n# from :func:`model_selection.validation_curve`.\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import ValidationCurveDisplay\n\nX, y = make_classification(1000, 10, random_state=0)\n\n_ = ValidationCurveDisplay.from_estimator(\n    LogisticRegression(),\n    X,\n    y,\n    param_name=\"C\",\n    param_range=np.geomspace(1e-5, 1e3, num=9),\n    score_type=\"both\",\n    score_name=\"Accuracy\",\n)\n\n# %%\n# Gamma loss for gradient boosting\n# --------------------------------\n# The class :class:`ensemble.HistGradientBoostingRegressor` supports the\n# Gamma deviance loss function via `loss=\"gamma\"`. This loss function is useful for\n# modeling strictly positive targets with a right-skewed distribution.\nimport numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import make_low_rank_matrix\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\nn_samples, n_features = 500, 10\nrng = np.random.RandomState(0)\nX = make_low_rank_matrix(n_samples, n_features, random_state=rng)\ncoef = rng.uniform(low=-10, high=20, size=n_features)\ny = rng.gamma(shape=2, scale=np.exp(X @ coef) / 2)\ngbdt = HistGradientBoostingRegressor(loss=\"gamma\")\ncross_val_score(gbdt, X, y).mean()\n\n# %%\n# Grouping infrequent categories in :class:`preprocessing.OrdinalEncoder`\n# -----------------------------------------------------------------------\n# Similarly to :class:`preprocessing.OneHotEncoder`, the class\n# :class:`preprocessing.OrdinalEncoder` now supports aggregating infrequent categories\n# into a single output for each feature. The parameters to enable the gathering of\n# infrequent categories are `min_frequency` and `max_categories`.\n# See the :ref:`User Guide <encoder_infrequent_categories>` for more details.",
                "filename": "examples/release_highlights/plot_release_highlights_1_3_0.py",
                "start_index": 2966,
                "end_index": 5954,
                "start_line": 72,
                "end_line": 148,
                "max_line": 156,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "self._check_infrequent_enabled()\n        self._check_n_features(X, reset=True)\n        self._check_feature_names(X, reset=True)\n        X_list, n_samples, n_features = self._check_X(\n            X, force_all_finite=force_all_finite\n        )\n        self.n_features_in_ = n_features\n\n        if self.categories != \"auto\":\n            if len(self.categories) != n_features:\n                raise ValueError(\n                    \"Shape mismatch: if categories is an array,\"\n                    \" it has to be of shape (n_features,).\"\n                )\n\n        self.categories_ = []\n        category_counts = []\n        compute_counts = return_counts or self._infrequent_enabled",
                "filename": "sklearn/preprocessing/_encoders.py",
                "start_index": 2663,
                "end_index": 3339,
                "start_line": 74,
                "end_line": 91,
                "max_line": 1674,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_classifiers_one_label(name, classifier_orig):\n    error_string_fit = \"Classifier can't train when only one class is present.\"\n    error_string_predict = \"Classifier can't predict when only one class is present.\"\n    rnd = np.random.RandomState(0)\n    X_train = rnd.uniform(size=(10, 3))\n    X_test = rnd.uniform(size=(10, 3))\n    y = np.ones(10)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        classifier = clone(classifier_orig)\n        with raises(\n            ValueError, match=\"class\", may_pass=True, err_msg=error_string_fit\n        ) as cm:\n            classifier.fit(X_train, y)\n\n        if cm.raised_and_matched:\n            # ValueError was raised with proper error message\n            return\n\n        assert_array_equal(classifier.predict(X_test), y, err_msg=error_string_predict)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_classifiers_one_label_sample_weights(name, classifier_orig):\n    \"\"\"Check that classifiers accepting sample_weight fit or throws a ValueError with\n    an explicit message if the problem is reduced to one class.\n    \"\"\"\n    error_fit = (\n        f\"{name} failed when fitted on one label after sample_weight trimming. Error \"\n        \"message is not explicit, it should have 'class'.\"\n    )\n    error_predict = f\"{name} prediction results should only output the remaining class.\"\n    rnd = np.random.RandomState(0)\n    # X should be square for test on SVC with precomputed kernel\n    X_train = rnd.uniform(size=(10, 10))\n    X_test = rnd.uniform(size=(10, 10))\n    y = np.arange(10) % 2\n    sample_weight = y.copy()  # select a single class\n    classifier = clone(classifier_orig)\n\n    if has_fit_parameter(classifier, \"sample_weight\"):\n        match = [r\"\\bclass(es)?\\b\", error_predict]\n        err_type, err_msg = (AssertionError, ValueError), error_fit\n    else:\n        match = r\"\\bsample_weight\\b\"\n        err_type, err_msg = (TypeError, ValueError), None\n\n    with raises(err_type, match=match, may_pass=True, err_msg=err_msg) as cm:\n        classifier.fit(X_train, y, sample_weight=sample_weight)\n        if cm.raised_and_matched:\n            # raise the proper error type with the proper error message\n            return\n        # for estimators that do not fail, they should be able to predict the only\n        # class remaining during fit\n        assert_array_equal(\n            classifier.predict(X_test), np.ones(10), err_msg=error_predict\n        )",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 79371,
                "end_index": 81868,
                "start_line": 181,
                "end_line": 4639,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"\n============================================\nComparing Target Encoder with Other Encoders\n============================================\n\n.. currentmodule:: sklearn.preprocessing\n\nThe :class:`TargetEncoder` uses the value of the target to encode each\ncategorical feature. In this example, we will compare three different approaches\nfor handling categorical features: :class:`TargetEncoder`,\n:class:`OrdinalEncoder`, :class:`OneHotEncoder` and dropping the category.\n\n.. note::\n    `fit(X, y).transform(X)` does not equal `fit_transform(X, y)` because a\n    cross fitting scheme is used in `fit_transform` for encoding. See the\n    :ref:`User Guide <target_encoder>`. for details.\n\"\"\"\n\n# %%\n# Loading Data from OpenML\n# ========================\n# First, we load the wine reviews dataset, where the target is the points given\n# be a reviewer:\nfrom sklearn.datasets import fetch_openml\n\nwine_reviews = fetch_openml(data_id=42074, as_frame=True, parser=\"pandas\")\n\ndf = wine_reviews.frame\ndf.head()\n\n# %%\n# For this example, we use the following subset of numerical and categorical\n# features in the data. The target are continuous values from 80 to 100:\nnumerical_features = [\"price\"]\ncategorical_features = [\n    \"country\",\n    \"province\",\n    \"region_1\",\n    \"region_2\",\n    \"variety\",\n    \"winery\",\n]\ntarget_name = \"points\"\n\nX = df[numerical_features + categorical_features]\ny = df[target_name]\n\n_ = y.hist()\n\n# %%\n# Training and Evaluating Pipelines with Different Encoders\n# =========================================================\n# In this section, we will evaluate pipelines with\n# :class:`~sklearn.ensemble.HistGradientBoostingRegressor` with different encoding\n# strategies. First, we list out the encoders we will be using to preprocess\n# the categorical features:\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, TargetEncoder\n\ncategorical_preprocessors = [\n    (\"drop\", \"drop\"),\n    (\"ordinal\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n    (\n        \"one_hot\",\n        OneHotEncoder(handle_unknown=\"ignore\", max_categories=20, sparse_output=False),\n    ),\n    (\"target\", TargetEncoder(target_type=\"continuous\")),\n]\n\n# %%\n# Next, we evaluate the models using cross validation and record the results:\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.pipeline import make_pipeline\n\nn_cv_folds = 3\nmax_iter = 20\nresults = []",
                "filename": "examples/preprocessing/plot_target_encoder.py",
                "start_index": 0,
                "end_index": 2498,
                "start_line": 1,
                "end_line": 78,
                "max_line": 225,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "# Authors: Andreas Mueller <amueller@ais.uni-bonn.de>\n#          Joris Van den Bossche <jorisvandenbossche@gmail.com>\n# License: BSD 3 clause\n\nimport numbers\nimport warnings\nfrom numbers import Integral\n\nimport numpy as np\nfrom scipy import sparse\n\nfrom ..base import BaseEstimator, OneToOneFeatureMixin, TransformerMixin, _fit_context\nfrom ..utils import _safe_indexing, check_array, is_scalar_nan\nfrom ..utils._encode import _check_unknown, _encode, _get_counts, _unique\nfrom ..utils._mask import _get_mask\nfrom ..utils._param_validation import Hidden, Interval, RealNotInt, StrOptions\nfrom ..utils.validation import _check_feature_names_in, check_is_fitted\n\n__all__ = [\"OneHotEncoder\", \"OrdinalEncoder\"]",
                "filename": "sklearn/preprocessing/_encoders.py",
                "start_index": 0,
                "end_index": 706,
                "start_line": 1,
                "end_line": 19,
                "max_line": 1674,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_sample_weights_shape(name, estimator_orig):\n    # check that estimators raise an error if sample_weight\n    # shape mismatches the input\n    estimator = clone(estimator_orig)\n    X = np.array(\n        [\n            [1, 3],\n            [1, 3],\n            [1, 3],\n            [1, 3],\n            [2, 1],\n            [2, 1],\n            [2, 1],\n            [2, 1],\n            [3, 3],\n            [3, 3],\n            [3, 3],\n            [3, 3],\n            [4, 1],\n            [4, 1],\n            [4, 1],\n            [4, 1],\n        ]\n    )\n    y = np.array([1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2])\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    estimator.fit(X, y, sample_weight=np.ones(len(y)))\n\n    with raises(ValueError):\n        estimator.fit(X, y, sample_weight=np.ones(2 * len(y)))\n\n    with raises(ValueError):\n        estimator.fit(X, y, sample_weight=np.ones((len(y), 2)))",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 41433,
                "end_index": 42380,
                "start_line": 181,
                "end_line": 1218,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sklearn/preprocessing/_encoders.py": [
                {
                    "chunk": {
                        "code": "if self.handle_unknown == \"use_encoded_value\":\n            for cardinality in cardinalities:\n                if 0 <= self.unknown_value < cardinality:\n                    raise ValueError(\n                        \"The used value for unknown_value \"\n                        f\"{self.unknown_value} is one of the \"\n                        \"values already used for encoding the \"\n                        \"seen categories.\"\n                    )\n\n        if self._missing_indices:\n            if np.dtype(self.dtype).kind != \"f\" and is_scalar_nan(\n                self.encoded_missing_value\n            ):\n                raise ValueError(\n                    \"There are missing values in features \"\n                    f\"{list(self._missing_indices)}. For OrdinalEncoder to \"\n                    f\"encode missing values with dtype: {self.dtype}, set \"\n                    \"encoded_missing_value to a non-nan value, or \"\n                    \"set dtype to a float\"\n                )\n\n            if not is_scalar_nan(self.encoded_missing_value):\n                # Features are invalid when they contain a missing category\n                # and encoded_missing_value was already used to encode a\n                # known category\n                invalid_features = [\n                    cat_idx\n                    for cat_idx, cardinality in enumerate(cardinalities)\n                    if cat_idx in self._missing_indices\n                    and 0 <= self.encoded_missing_value < cardinality\n                ]\n\n                if invalid_features:\n                    # Use feature names if they are available\n                    if hasattr(self, \"feature_names_in_\"):\n                        invalid_features = self.feature_names_in_[invalid_features]\n                    raise ValueError(\n                        f\"encoded_missing_value ({self.encoded_missing_value}) \"\n                        \"is already used to encode a known category in features: \"\n                        f\"{invalid_features}\"\n                    )\n\n        return self",
                        "filename": "sklearn/preprocessing/_encoders.py",
                        "start_index": 60923,
                        "end_index": 62960,
                        "start_line": 1463,
                        "end_line": 1557,
                        "max_line": 1674,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the error message logic for the OrdinalEncoder, which is relevant to the issue as the error message needs to be updated."
                },
                {
                    "chunk": {
                        "code": "self._check_infrequent_enabled()\n        self._check_n_features(X, reset=True)\n        self._check_feature_names(X, reset=True)\n        X_list, n_samples, n_features = self._check_X(\n            X, force_all_finite=force_all_finite\n        )\n        self.n_features_in_ = n_features\n\n        if self.categories != \"auto\":\n            if len(self.categories) != n_features:\n                raise ValueError(\n                    \"Shape mismatch: if categories is an array,\"\n                    \" it has to be of shape (n_features,).\"\n                )\n\n        self.categories_ = []\n        category_counts = []\n        compute_counts = return_counts or self._infrequent_enabled",
                        "filename": "sklearn/preprocessing/_encoders.py",
                        "start_index": 2663,
                        "end_index": 3339,
                        "start_line": 74,
                        "end_line": 91,
                        "max_line": 1674,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet checks the shape of the categories array, which is directly related to the issue reported, as the error message mentions a shape mismatch."
                }
            ]
        },
        "solution_task": "- The error message indicates that the `categories` parameter is expected to be a list of arrays, where each array corresponds to the categories for a feature. The provided `categories` parameter is a single list, which is causing the shape mismatch error.\n- The correct usage of the `OrdinalEncoder` with a custom list of categories should be as follows:\n\n```py\nfrom sklearn.preprocessing import OrdinalEncoder\nimport numpy as np\n\nX = np.array([['L', 'M', 'S', 'M', 'L']], dtype=object).T\nohe = OrdinalEncoder(categories=[['S', 'M', 'L']])\nohe.fit(X)\n```\n\n- The `categories` parameter should be a list containing a single list of categories for the one feature in `X`.",
        "bouncer_response": {
            "score": 9,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant hints and solutions that can directly lead to resolving the issues outlined in the PROMPT.",
            "supporting_evidence": "The RESPONSE correctly identifies the cause of the error message, which is the incorrect format of the 'categories' parameter passed to the OrdinalEncoder. It provides a clear and actionable solution by showing the correct way to pass the 'categories' parameter as a list of lists. Additionally, the RESPONSE points to specific code snippets in the sklearn repository that are relevant to the error message logic and the shape check of the categories array, which would be the places to look for when attempting to fix the error message and potentially improve the detection of incorrect input formats. The RESPONSE does not address the secondary issue of improving the detection of incorrect input formats, but it does provide a solution to the primary issue of the confusing error message.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711740643.3459141,
        "result": "- The error message indicates that the `categories` parameter is expected to be a list of arrays, where each array corresponds to the categories for a feature. The provided `categories` parameter is a single list, which is causing the shape mismatch error.\n- The correct usage of the `OrdinalEncoder` with a custom list of categories should be as follows:\n\n```py\nfrom sklearn.preprocessing import OrdinalEncoder\nimport numpy as np\n\nX = np.array([['L', 'M', 'S', 'M', 'L']], dtype=object).T\nohe = OrdinalEncoder(categories=[['S', 'M', 'L']])\nohe.fit(X)\n```\n\n- The `categories` parameter should be a list containing a single list of categories for the one feature in `X`.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn) \u2192 [preprocessing](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn/preprocessing)- [Lines 1463 - 1557](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/preprocessing/_encoders.py#L1463-L1557)\n\n This snippet contains the error message logic for the OrdinalEncoder, which is relevant to the issue as the error message needs to be updated. \n\n\n   - [Lines 74 - 91](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/preprocessing/_encoders.py#L74-L91)\n\n This snippet checks the shape of the categories array, which is directly related to the issue reported, as the error message mentions a shape mismatch.",
        "context_relevance": 0.2800000000000001,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers the PROMPT completely.\nSupporting Evidence: The RESPONSE addresses the confusion in the error message by explaining the expected format for the `categories` parameter in the `OrdinalEncoder`. It provides a corrected code example that would prevent the error, which is directly related to the problem described in the PROMPT. Additionally, the RESPONSE includes relevant links to the code snippets in the scikit-learn repository that pertain to the error message and the shape checking of the categories array, which are the core issues in the PROMPT. The RESPONSE is comprehensive and directly addresses all aspects of the PROMPT, thus earning a score of 10."
        },
        "qa_relevance": 1.0
    }
}