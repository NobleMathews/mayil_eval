{
    "id": "pytest-dev__pytest-9709",
    "repo_name": "testbed/pytest-dev__pytest__7.1",
    "task_id": 8673082305834180210,
    "title": "Current implementation of `pytest.approx()` cannot be used to compare sets",
    "body": "The current implementation of `pytest.approx()` yields incorrect results when used to compare sets.\r\n\r\nConsider the following self-explanatory code comparing two (equal as by `__eq__()`) sets:\r\n\r\n```\r\nimport numpy as np\r\nimport pytest\r\n\r\n\r\na = 2**np.arange(12)\r\nb = 2**np.arange(12)\r\nnp.random.shuffle(a)\r\n\r\nprint(a)\r\nprint(b)\r\n\r\nprint(*set(a))\r\nprint(*set(b))\r\n\r\nprint(set(a) == set(b))\r\nprint(set(a) == pytest.approx(set(b)))\r\n\r\n```\r\n\r\nAlthough the two sets are obviously the same, the last equality check using approx is failing.\r\n\r\nA quick view into the implementation of `approx()` makes it obvious why this is the case:\r\n\r\n```\r\nclass ApproxSequencelike(ApproxBase):\r\n    \"\"\"Perform approximate comparisons where the expected value is a sequence of numbers.\"\"\"\r\n\r\n    def __repr__(self) -> str:\r\n        seq_type = type(self.expected)\r\n        if seq_type not in (tuple, list, set):\r\n            seq_type = list\r\n        return \"approx({!r})\".format(\r\n            seq_type(self._approx_scalar(x) for x in self.expected)\r\n        )\r\n\r\n    def _yield_comparisons(self, actual):\r\n        return zip(actual, self.expected)\r\n```\r\n\r\nIn `_yield_comparisons()`, only `__iter__()` is used (in `zip()`), but since sets are unordered, so is the resulting iterator. This means, for sets such an implementation cannot work.\r\nWhat makes things worse is the confusion that seems to exist here between the different abstract base classes:\r\nIn the `__repr__()` method, clearly `set` is mentioned, explicitly. However, a set is not a sequence type, but only a collection type (because of the missing order). It is, however, iterable and since this is the only thing that is actually checked in the implementation, the code seems to work for sets, where, in fact, it does not. As a first step, I would suggest one could keep the current implementation, but explicitly check for sequence types (i.e. classes having a `__getitem__()` method) and delete all mentions of `set` in the code as well as on the documentation page and make it crystal clear that there is only an implementation for sequence types.\r\nBut what would be way better would, of course, be an implementation for arbitrary container comparisons.\r\n\r\nTested with pytest version 7.0.1.\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/pytest-dev__pytest__7.1.git",
    "requested_commit": "",
    "mayil_response": "- The issue is with the use of `pytest.approx()` with sets, which are unordered collections. The `pytest.approx()` function is designed for ordered sequences, and using it with sets can lead to unpredictable results because the order of elements in a set is not guaranteed.\n\n- The relevant code snippet causing the issue is:\n  ```python\n  print(set(a) == pytest.approx(set(b)))\n  ```\n\n- To resolve the issue:\n  - Remove the use of `pytest.approx()` with sets.\n  - If approximate comparison of unordered collections is required, consider implementing a custom comparison function that does not rely on the order of elements.\n  - Alternatively, if the elements are sortable, convert the sets to lists, sort them, and then use `pytest.approx()`:\n    ```python\n    print(sorted(a) == pytest.approx(sorted(b)))\n    ```",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0021904999999999997,
        "snippet_processor": 0.05927,
        "issue_star_creation": 0.07475000000000001,
        "issue_star_solver": 0.04054,
        "bouncer": 0.05904
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711734377.108083,
        "relevant_snippets": [
            {
                "code": "rtd:\n  project: pytest",
                "filename": ".github/config.yml",
                "start_index": 0,
                "end_index": 22,
                "start_line": 1,
                "end_line": 2,
                "max_line": 2,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "import pytest\n\nSKIP = True\n\n\n@pytest.mark.parametrize(\"x\", range(5000))\ndef test_foo(x):\n    if SKIP:\n        pytest.skip(\"heh\")",
                "filename": "bench/skip.py",
                "start_index": 0,
                "end_index": 128,
                "start_line": 1,
                "end_line": 9,
                "max_line": 9,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "blank_issues_enabled: false\ncontact_links:\n  - name: \u2753 Support Question\n    url: https://github.com/pytest-dev/pytest/discussions\n    about: Use GitHub's new Discussions feature for questions",
                "filename": ".github/ISSUE_TEMPLATE/config.yml",
                "start_index": 0,
                "end_index": 191,
                "start_line": 1,
                "end_line": 5,
                "max_line": 5,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "# shim for pylib going away\n# if pylib is installed this file will get skipped\n# (`py/__init__.py` has higher precedence)\nimport sys\n\nimport _pytest._py.error as error\nimport _pytest._py.path as path\n\nsys.modules[\"py.error\"] = error\nsys.modules[\"py.path\"] = path",
                "filename": "src/py.py",
                "start_index": 0,
                "end_index": 262,
                "start_line": 1,
                "end_line": 10,
                "max_line": 10,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "# 10000 iterations, just for relative comparison\n#                      2.7.5     3.3.2\n# FilesCompleter       75.1109   69.2116\n# FastFilesCompleter    0.7383    1.0760\nimport timeit\n\nimports = [\n    \"from argcomplete.completers import FilesCompleter as completer\",\n    \"from _pytest._argcomplete import FastFilesCompleter as completer\",\n]\n\ncount = 1000  # only a few seconds\nsetup = \"%s\\nfc = completer()\"\nrun = 'fc(\"/d\")'\n\n\nif __name__ == \"__main__\":\n    print(timeit.timeit(run, setup=setup % imports[0], number=count))\n    print(timeit.timeit(run, setup=setup % imports[1], number=count))",
                "filename": "bench/bench_argcomplete.py",
                "start_index": 0,
                "end_index": 593,
                "start_line": 1,
                "end_line": 19,
                "max_line": 19,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "import pytest\n\n\n@pytest.fixture(scope=\"module\", params=range(966))\ndef foo(request):\n    return request.param\n\n\ndef test_it(foo):\n    pass\n\n\ndef test_it2(foo):\n    pass",
                "filename": "bench/manyparam.py",
                "start_index": 0,
                "end_index": 168,
                "start_line": 1,
                "end_line": 14,
                "max_line": 14,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "import sys\n\nif __name__ == \"__main__\":\n    import cProfile\n    import pytest  # NOQA\n    import pstats\n\n    script = sys.argv[1:] if len(sys.argv) > 1 else [\"empty.py\"]\n    cProfile.run(\"pytest.cmdline.main(%r)\" % script, \"prof\")\n    p = pstats.Stats(\"prof\")\n    p.strip_dirs()\n    p.sort_stats(\"cumulative\")\n    print(p.print_stats(500))",
                "filename": "bench/bench.py",
                "start_index": 0,
                "end_index": 338,
                "start_line": 1,
                "end_line": 13,
                "max_line": 13,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "import json\nfrom pathlib import Path\n\nimport requests\n\nissues_url = \"https://api.github.com/repos/pytest-dev/pytest/issues\"\n\n\ndef get_issues():\n    issues = []\n    url = issues_url\n    while 1:\n        get_data = {\"state\": \"all\"}\n        r = requests.get(url, params=get_data)\n        data = r.json()\n        if r.status_code == 403:\n            # API request limit exceeded\n            print(data[\"message\"])\n            exit(1)\n        issues.extend(data)\n\n        # Look for next page\n        links = requests.utils.parse_header_links(r.headers[\"Link\"])\n        another_page = False\n        for link in links:\n            if link[\"rel\"] == \"next\":\n                url = link[\"url\"]\n                another_page = True\n        if not another_page:\n            return issues\n\n\ndef main(args):\n    cachefile = Path(args.cache)\n    if not cachefile.exists() or args.refresh:\n        issues = get_issues()\n        cachefile.write_text(json.dumps(issues), \"utf-8\")\n    else:\n        issues = json.loads(cachefile.read_text(\"utf-8\"))\n\n    open_issues = [x for x in issues if x[\"state\"] == \"open\"]\n\n    open_issues.sort(key=lambda x: x[\"number\"])\n    report(open_issues)\n\n\ndef _get_kind(issue):\n    labels = [label[\"name\"] for label in issue[\"labels\"]]\n    for key in (\"bug\", \"enhancement\", \"proposal\"):\n        if key in labels:\n            return key\n    return \"issue\"\n\n\ndef report(issues):\n    for issue in issues:\n        title = issue[\"title\"]\n        # body = issue[\"body\"]\n        kind = _get_kind(issue)\n        status = issue[\"state\"]\n        number = issue[\"number\"]\n        link = \"https://github.com/pytest-dev/pytest/issues/%s/\" % number\n        print(\"----\")\n        print(status, kind, link)\n        print(title)\n        # print()\n        # lines = body.split(\"\\n\")\n        # print(\"\\n\".join(lines[:3]))\n        # if len(lines) > 3 or len(body) > 240:\n        #    print(\"...\")\n    print(\"\\n\\nFound %s open issues\" % len(issues))\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser(\"process bitbucket issues\")\n    parser.add_argument(\n        \"--refresh\", action=\"store_true\", help=\"invalidate cache, refresh issues\"\n    )\n    parser.add_argument(\n        \"--cache\", action=\"store\", default=\"issues.json\", help=\"cache file\"\n    )\n    args = parser.parse_args()\n    main(args)",
                "filename": "extra/get_issues.py",
                "start_index": 0,
                "end_index": 2321,
                "start_line": 1,
                "end_line": 85,
                "max_line": 85,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "import datetime\nimport pathlib\nimport re\nfrom textwrap import dedent\nfrom textwrap import indent\n\nimport packaging.version\nimport platformdirs\nimport tabulate\nimport wcwidth\nfrom requests_cache import CachedResponse\nfrom requests_cache import CachedSession\nfrom requests_cache import OriginalResponse\nfrom requests_cache import SQLiteCache\nfrom tqdm import tqdm\n\n\nFILE_HEAD = r\"\"\"\n.. Note this file is autogenerated by scripts/update-plugin-list.py - usually weekly via github action\n\n.. _plugin-list:\n\nPlugin List\n===========\n\nPyPI projects that match \"pytest-\\*\" are considered plugins and are listed\nautomatically together with a manually-maintained list in `the source\ncode <https://github.com/pytest-dev/pytest/blob/main/scripts/update-plugin-list.py>`_.\nPackages classified as inactive are excluded.\n\n.. The following conditional uses a different format for this list when\n   creating a PDF, because otherwise the table gets far too wide for the\n   page.\n\n\"\"\"\nDEVELOPMENT_STATUS_CLASSIFIERS = (\n    \"Development Status :: 1 - Planning\",\n    \"Development Status :: 2 - Pre-Alpha\",\n    \"Development Status :: 3 - Alpha\",\n    \"Development Status :: 4 - Beta\",\n    \"Development Status :: 5 - Production/Stable\",\n    \"Development Status :: 6 - Mature\",\n    \"Development Status :: 7 - Inactive\",\n)\nADDITIONAL_PROJECTS = {  # set of additional projects to consider as plugins\n    \"logassert\",\n    \"nuts\",\n}\n\n\ndef escape_rst(text: str) -> str:\n    \"\"\"Rudimentary attempt to escape special RST characters to appear as\n    plain text.\"\"\"\n    text = (\n        text.replace(\"*\", \"\\\\*\")\n        .replace(\"<\", \"\\\\<\")\n        .replace(\">\", \"\\\\>\")\n        .replace(\"`\", \"\\\\`\")\n    )\n    text = re.sub(r\"_\\b\", \"\", text)\n    return text\n\n\ndef project_response_with_refresh(\n    session: CachedSession, name: str, last_serial: int\n) -> OriginalResponse | CachedResponse:\n    \"\"\"Get a http cached pypi project\n\n    force refresh in case of last serial mismatch\n    \"\"\"\n\n    response = session.get(f\"https://pypi.org/pypi/{name}/json\")\n    if int(response.headers.get(\"X-PyPI-Last-Serial\", -1)) != last_serial:\n        response = session.get(f\"https://pypi.org/pypi/{name}/json\", refresh=True)\n    return response\n\n\ndef get_session() -> CachedSession:\n    \"\"\"Configures the requests-cache session\"\"\"\n    cache_path = platformdirs.user_cache_path(\"pytest-plugin-list\")\n    cache_path.mkdir(exist_ok=True, parents=True)\n    cache_file = cache_path.joinpath(\"http_cache.sqlite3\")\n    return CachedSession(backend=SQLiteCache(cache_file))\n\n\ndef pytest_plugin_projects_from_pypi(session: CachedSession) -> dict[str, int]:\n    response = session.get(\n        \"https://pypi.org/simple\",\n        headers={\"Accept\": \"application/vnd.pypi.simple.v1+json\"},\n        refresh=True,\n    )\n    return {\n        name: p[\"_last-serial\"]\n        for p in response.json()[\"projects\"]\n        if (name := p[\"name\"]).startswith(\"pytest-\") or name in ADDITIONAL_PROJECTS\n    }",
                "filename": "scripts/update-plugin-list.py",
                "start_index": 0,
                "end_index": 2939,
                "start_line": 1,
                "end_line": 155,
                "max_line": 195,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "for i in range(5000):\n    exec(\n        f\"\"\"\nclass Test{i}:\n    @classmethod\n    def setup_class(cls): pass\n    def test_1(self): pass\n    def test_2(self): pass\n    def test_3(self): pass\n\"\"\"\n    )",
                "filename": "bench/xunit.py",
                "start_index": 0,
                "end_index": 198,
                "start_line": 1,
                "end_line": 11,
                "max_line": 11,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.1",
                "sha": "",
                "context_relevance": 0.0
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {},
        "solution_task": "- The issue is with the use of `pytest.approx()` with sets, which are unordered collections. The `pytest.approx()` function is designed for ordered sequences, and using it with sets can lead to unpredictable results because the order of elements in a set is not guaranteed.\n\n- The relevant code snippet causing the issue is:\n  ```python\n  print(set(a) == pytest.approx(set(b)))\n  ```\n\n- To resolve the issue:\n  - Remove the use of `pytest.approx()` with sets.\n  - If approximate comparison of unordered collections is required, consider implementing a custom comparison function that does not rely on the order of elements.\n  - Alternatively, if the elements are sortable, convert the sets to lists, sort them, and then use `pytest.approx()`:\n    ```python\n    print(sorted(a) == pytest.approx(sorted(b)))\n    ```",
        "bouncer_response": {
            "score": 7,
            "criteria": "The RESPONSE must provide actionable, relevant guidance to more parts of the PROMPT's described issue to score higher.",
            "supporting_evidence": "The RESPONSE correctly identifies the core issue with using `pytest.approx()` on sets, which is that sets are unordered and `pytest.approx()` is designed for ordered sequences. The RESPONSE provides actionable advice by suggesting the removal of `pytest.approx()` when dealing with sets and offers two alternative solutions: implementing a custom comparison function or converting sets to sorted lists before using `pytest.approx()`. This advice is practical and directly addresses the problem described in the PROMPT. However, the RESPONSE does not address the underlying implementation details of `pytest.approx()` or provide a suggestion for improving the `pytest` library itself, which was part of the PROMPT's discussion. Therefore, while the RESPONSE is helpful and relevant, it is not comprehensive in addressing all aspects of the PROMPT, such as the suggestion to remove mentions of `set` from the code and documentation or to develop an implementation for arbitrary container comparisons.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711734449.013126,
        "result": "- The issue is with the use of `pytest.approx()` with sets, which are unordered collections. The `pytest.approx()` function is designed for ordered sequences, and using it with sets can lead to unpredictable results because the order of elements in a set is not guaranteed.\n\n- The relevant code snippet causing the issue is:\n  ```python\n  print(set(a) == pytest.approx(set(b)))\n  ```\n\n- To resolve the issue:\n  - Remove the use of `pytest.approx()` with sets.\n  - If approximate comparison of unordered collections is required, consider implementing a custom comparison function that does not rely on the order of elements.\n  - Alternatively, if the elements are sortable, convert the sets to lists, sort them, and then use `pytest.approx()`:\n    ```python\n    print(sorted(a) == pytest.approx(sorted(b)))\n    ```",
        "context_relevance": 0.04,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers the entire PROMPT completely, but it does not address the specific suggestion to remove mentions of `set` from the code and documentation, which is part of the detailed solution proposed in the PROMPT.\nSupporting Evidence: The RESPONSE correctly identifies the problem with using `pytest.approx()` with sets, which is the main issue described in the PROMPT. It also provides a relevant code snippet that is causing the issue, aligning with the example given in the PROMPT. Furthermore, the RESPONSE offers practical solutions to resolve the issue, such as not using `pytest.approx()` with sets or sorting the elements before comparison, which are in line with the type of solutions the PROMPT is seeking. However, it does not mention the specific suggestion to amend the code and documentation to remove references to sets, which is a part of the detailed solution proposed in the PROMPT, hence the score of 9 instead of 10."
        },
        "qa_relevance": 0.9
    }
}