{
    "id": "scikit-learn__scikit-learn-10577",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
    "task_id": 614987591160217739,
    "title": "Allow n_samples to be a tuple in make_blobs",
    "body": "I'd like make_blobs to accept lists or tuples for n_samples to generate imbalanced classes. Could be used here for example:\r\n\r\nhttp://scikit-learn.org/dev/auto_examples/svm/plot_separating_hyperplane_unbalanced.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-unbalanced-py\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.20.git",
    "requested_commit": "",
    "mayil_response": "To implement the feature request of allowing `n_samples` to be a tuple in `make_blobs`, follow these steps:\n\n- Modify the `make_blobs` function signature to accept `n_samples` as an `int` or a `tuple` of `int`.\n- Update the function to handle `n_samples` when it is a tuple by generating the specified number of samples for each class.\n- Ensure that the total number of samples generated matches the sum of the elements in the tuple.\n- Update the documentation to reflect the new functionality.\n- Add tests to verify that the function behaves as expected when `n_samples` is a tuple.\n\nHere is a code snippet that demonstrates the changes to the `make_blobs` function:\n\n```python\nfrom sklearn.utils import check_random_state, shuffle as util_shuffle\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n@_deprecate_positional_args\ndef make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0,\n               center_box=(-10.0, 10.0), shuffle=True, random_state=None,\n               return_centers=False):\n    # Handle tuple for n_samples\n    if isinstance(n_samples, tuple):\n        if centers is not None and len(centers) != len(n_samples):\n            raise ValueError(\"If n_samples is a tuple, centers must be None or have the same length.\")\n        n_samples_per_center = n_samples\n        n_samples = sum(n_samples)\n    else:\n        if centers is None:\n            centers = 3\n        if isinstance(centers, int):\n            centers = generator.uniform(center_box[0], center_box[1], size=(centers, n_features))\n        n_samples_per_center = [n_samples // len(centers)] * len(centers)\n        for i in range(n_samples % len(centers)):\n            n_samples_per_center[i] += 1\n\n    # Rest of the function remains unchanged, but use n_samples_per_center\n    # to generate the appropriate number of samples for each cluster\n\n    # ... (existing code to generate blobs)\n\n    return X, y\n```\n\n- Update the documentation string to include the new functionality.\n- Add unit tests to cover cases where `n_samples` is a tuple, including edge cases and error handling.\n- Ensure that existing tests pass with the new changes.\n\nFor further research, you may want to look into:\n- NumPy for array manipulations and random number generation.\n- scikit-learn's utilities for input validation and shuffling.\n- Unit testing frameworks such as pytest to write and run tests for the new feature.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [datasets](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/datasets)- [Lines 877 - 2099](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L877-L2099)\n\n This snippet defines the make_blobs function, which is directly related to the issue as it needs to be modified to accept tuples for n_samples. \n\n\n   - [Lines 888 - 2074](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L888-L2074)\n\n This snippet contains the documentation of the make_blobs function, which will need to be updated to reflect the changes allowing n_samples to be a tuple. \n\n\n   - [Lines 42 - 2124](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L42-L2124)\n\n This snippet includes parameter validation for the make_blobs function, which will likely need to be updated to validate the new tuple input for n_samples. \n\n\n   - [Lines 710 - 1880](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L710-L1880)\n\n This snippet from make_circles function shows an example of handling tuple input for n_samples, which can serve as a reference for implementing similar functionality in make_blobs.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.000641,
        "snippet_processor": 0.08109000000000001,
        "issue_star_creation": 0.027979999999999998,
        "issue_star_solver": 0.06982000000000001,
        "bouncer": 0.03111
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711742308.422337,
        "relevant_snippets": [
            {
                "code": "def make_blobs(\n    n_samples=100,\n    n_features=2,\n    *,\n    centers=None,\n    cluster_std=1.0,\n    center_box=(-10.0, 10.0),\n    shuffle=True,\n    random_state=None,\n    return_centers=False,\n):",
                "filename": "sklearn/datasets/_samples_generator.py",
                "start_index": 31128,
                "end_index": 31326,
                "start_line": 877,
                "end_line": 2099,
                "max_line": 2126,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "X_m, y_m = make_blobs(n_samples=300, random_state=0)\n    X_m = X_m.astype(X_dtype)\n    X_m, y_m = shuffle(X_m, y_m, random_state=7)\n    X_m = StandardScaler().fit_transform(X_m)\n    # generate binary problem from multi-class one\n    y_b = y_m[y_m != 2]\n    X_b = X_m[y_m != 2]\n\n    if name in [\"BernoulliNB\", \"MultinomialNB\", \"ComplementNB\", \"CategoricalNB\"]:\n        X_m -= X_m.min()\n        X_b -= X_b.min()\n\n    if readonly_memmap:\n        X_m, y_m, X_b, y_b = create_memmap_backed_data([X_m, y_m, X_b, y_b])\n\n    problems = [(X_b, y_b)]\n    tags = _safe_tags(classifier_orig)\n    if not tags[\"binary_only\"]:\n        problems.append((X_m, y_m))",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 82036,
                "end_index": 82683,
                "start_line": 2371,
                "end_line": 2389,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def make_multilabel_classification(\n    n_samples=100,\n    n_features=20,\n    *,\n    n_classes=5,\n    n_labels=2,\n    length=50,\n    allow_unlabeled=True,\n    sparse=False,\n    return_indicator=\"dense\",\n    return_distributions=False,\n    random_state=None,\n):",
                "filename": "sklearn/datasets/_samples_generator.py",
                "start_index": 12322,
                "end_index": 12582,
                "start_line": 328,
                "end_line": 2099,
                "max_line": 2126,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def one_run(n_samples):",
                "filename": "benchmarks/bench_hist_gradient_boosting.py",
                "start_index": 2917,
                "end_index": 2940,
                "start_line": 93,
                "end_line": 93,
                "max_line": 292,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"\n====================================\nDemonstration of k-means assumptions\n====================================\n\nThis example is meant to illustrate situations where k-means produces\nunintuitive and possibly undesirable clusters.\n\n\"\"\"\n\n# Author: Phil Roth <mr.phil.roth@gmail.com>\n#         Arturo Amor <david-arturo.amor-quiroz@inria.fr>\n# License: BSD 3 clause\n\n# %%\n# Data generation\n# ---------------\n#\n# The function :func:`~sklearn.datasets.make_blobs` generates isotropic\n# (spherical) gaussian blobs. To obtain anisotropic (elliptical) gaussian blobs\n# one has to define a linear `transformation`.\n\nimport numpy as np\n\nfrom sklearn.datasets import make_blobs\n\nn_samples = 1500\nrandom_state = 170\ntransformation = [[0.60834549, -0.63667341], [-0.40887718, 0.85253229]]\n\nX, y = make_blobs(n_samples=n_samples, random_state=random_state)\nX_aniso = np.dot(X, transformation)  # Anisotropic blobs\nX_varied, y_varied = make_blobs(\n    n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state\n)  # Unequal variance\nX_filtered = np.vstack(\n    (X[y == 0][:500], X[y == 1][:100], X[y == 2][:10])\n)  # Unevenly sized blobs\ny_filtered = [0] * 500 + [1] * 100 + [2] * 10\n\n# %%\n# We can visualize the resulting data:\n\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n\naxs[0, 0].scatter(X[:, 0], X[:, 1], c=y)\naxs[0, 0].set_title(\"Mixture of Gaussian Blobs\")\n\naxs[0, 1].scatter(X_aniso[:, 0], X_aniso[:, 1], c=y)\naxs[0, 1].set_title(\"Anisotropically Distributed Blobs\")\n\naxs[1, 0].scatter(X_varied[:, 0], X_varied[:, 1], c=y_varied)\naxs[1, 0].set_title(\"Unequal Variance\")\n\naxs[1, 1].scatter(X_filtered[:, 0], X_filtered[:, 1], c=y_filtered)\naxs[1, 1].set_title(\"Unevenly Sized Blobs\")\n\nplt.suptitle(\"Ground truth clusters\").set_y(0.95)\nplt.show()\n\n# %%\n# Fit models and plot results\n# ---------------------------\n#\n# The previously generated data is now used to show how\n# :class:`~sklearn.cluster.KMeans` behaves in the following scenarios:\n#\n# - Non-optimal number of clusters: in a real setting there is no uniquely\n#   defined **true** number of clusters. An appropriate number of clusters has\n#   to be decided from data-based criteria and knowledge of the intended goal.\n# - Anisotropically distributed blobs: k-means consists of minimizing sample's\n#   euclidean distances to the centroid of the cluster they are assigned to. As\n#   a consequence, k-means is more appropriate for clusters that are isotropic\n#   and normally distributed (i.e. spherical gaussians).\n# - Unequal variance: k-means is equivalent to taking the maximum likelihood\n#   estimator for a \"mixture\" of k gaussian distributions with the same\n#   variances but with possibly different means.\n# - Unevenly sized blobs: there is no theoretical result about k-means that\n#   states that it requires similar cluster sizes to perform well, yet\n#   minimizing euclidean distances does mean that the more sparse and",
                "filename": "examples/cluster/plot_kmeans_assumptions.py",
                "start_index": 0,
                "end_index": 2947,
                "start_line": 1,
                "end_line": 82,
                "max_line": 179,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def make_circles(\n    n_samples=100, *, shuffle=True, noise=None, random_state=None, factor=0.8\n):\n    \"\"\"Make a large circle containing a smaller circle in 2d.\n\n    A simple toy dataset to visualize clustering and classification\n    algorithms.\n\n    Read more in the :ref:`User Guide <sample_generators>`.\n\n    Parameters\n    ----------\n    n_samples : int or tuple of shape (2,), dtype=int, default=100\n        If int, it is the total number of points generated.\n        For odd numbers, the inner circle will have one point more than the\n        outer circle.\n        If two-element tuple, number of points in outer circle and inner\n        circle.\n\n        .. versionchanged:: 0.23\n           Added two-element tuple.\n\n    shuffle : bool, default=True\n        Whether to shuffle the samples.\n\n    noise : float, default=None\n        Standard deviation of Gaussian noise added to the data.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for dataset shuffling and noise.\n        Pass an int for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    factor : float, default=.8\n        Scale factor between inner and outer circle in the range `[0, 1)`.\n\n    Returns\n    -------\n    X : ndarray of shape (n_samples, 2)\n        The generated samples.\n\n    y : ndarray of shape (n_samples,)\n        The integer labels (0 or 1) for class membership of each sample.\n    \"\"\"\n    if isinstance(n_samples, numbers.Integral):\n        n_samples_out = n_samples // 2\n        n_samples_in = n_samples - n_samples_out\n    else:  # n_samples is a tuple\n        if len(n_samples) != 2:\n            raise ValueError(\"When a tuple, n_samples must have exactly two elements.\")\n        n_samples_out, n_samples_in = n_samples\n\n    generator = check_random_state(random_state)\n    # so as not to have the first point = last point, we set endpoint=False\n    linspace_out = np.linspace(0, 2 * np.pi, n_samples_out, endpoint=False)\n    linspace_in = np.linspace(0, 2 * np.pi, n_samples_in, endpoint=False)\n    outer_circ_x = np.cos(linspace_out)\n    outer_circ_y = np.sin(linspace_out)\n    inner_circ_x = np.cos(linspace_in) * factor\n    inner_circ_y = np.sin(linspace_in) * factor\n\n    X = np.vstack(\n        [np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]\n    ).T\n    y = np.hstack(\n        [np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)]\n    )\n    if shuffle:\n        X, y = util_shuffle(X, y, random_state=generator)\n\n    if noise is not None:\n        X += generator.normal(scale=noise, size=X.shape)\n\n    return X, y",
                "filename": "sklearn/datasets/_samples_generator.py",
                "start_index": 25335,
                "end_index": 28008,
                "start_line": 710,
                "end_line": 1880,
                "max_line": 2126,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.7
            },
            {
                "code": "def make_classification(\n    n_samples=100,\n    n_features=20,\n    *,\n    n_informative=2,\n    n_redundant=2,\n    n_repeated=0,\n    n_classes=2,\n    n_clusters_per_class=2,\n    weights=None,\n    flip_y=0.01,\n    class_sep=1.0,\n    hypercube=True,\n    shift=0.0,\n    scale=1.0,\n    shuffle=True,\n    random_state=None,\n):",
                "filename": "sklearn/datasets/_samples_generator.py",
                "start_index": 2193,
                "end_index": 2513,
                "start_line": 62,
                "end_line": 2099,
                "max_line": 2126,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"\n==============================================\nPlot randomly generated multilabel dataset\n==============================================\n\nThis illustrates the :func:`~sklearn.datasets.make_multilabel_classification`\ndataset generator. Each sample consists of counts of two features (up to 50 in\ntotal), which are differently distributed in each of two classes.\n\nPoints are labeled as follows, where Y means the class is present:\n\n    =====  =====  =====  ======\n      1      2      3    Color\n    =====  =====  =====  ======\n      Y      N      N    Red\n      N      Y      N    Blue\n      N      N      Y    Yellow\n      Y      Y      N    Purple\n      Y      N      Y    Orange\n      Y      Y      N    Green\n      Y      Y      Y    Brown\n    =====  =====  =====  ======\n\nA star marks the expected sample for each class; its size reflects the\nprobability of selecting that class label.\n\nThe left and right examples highlight the ``n_labels`` parameter:\nmore of the samples in the right plot have 2 or 3 labels.\n\nNote that this two-dimensional example is very degenerate:\ngenerally the number of features would be much greater than the\n\"document length\", while here we have much larger documents than vocabulary.\nSimilarly, with ``n_classes > n_features``, it is much less likely that a\nfeature distinguishes a particular class.\n\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.datasets import make_multilabel_classification as make_ml_clf\n\nCOLORS = np.array(\n    [\n        \"!\",\n        \"#FF3333\",  # red\n        \"#0198E1\",  # blue\n        \"#BF5FFF\",  # purple\n        \"#FCD116\",  # yellow\n        \"#FF7216\",  # orange\n        \"#4DBD33\",  # green\n        \"#87421F\",  # brown\n    ]\n)\n\n# Use same random seed for multiple calls to make_multilabel_classification to\n# ensure same distributions\nRANDOM_SEED = np.random.randint(2**10)\n\n\ndef plot_2d(ax, n_labels=1, n_classes=3, length=50):\n    X, Y, p_c, p_w_c = make_ml_clf(\n        n_samples=150,\n        n_features=2,\n        n_classes=n_classes,\n        n_labels=n_labels,\n        length=length,\n        allow_unlabeled=False,\n        return_distributions=True,\n        random_state=RANDOM_SEED,\n    )\n\n    ax.scatter(\n        X[:, 0], X[:, 1], color=COLORS.take((Y * [1, 2, 4]).sum(axis=1)), marker=\".\"\n    )\n    ax.scatter(\n        p_w_c[0] * length,\n        p_w_c[1] * length,\n        marker=\"*\",\n        linewidth=0.5,\n        edgecolor=\"black\",\n        s=20 + 1500 * p_c**2,\n        color=COLORS.take([1, 2, 4]),\n    )\n    ax.set_xlabel(\"Feature 0 count\")\n    return p_c, p_w_c\n\n\n_, (ax1, ax2) = plt.subplots(1, 2, sharex=\"row\", sharey=\"row\", figsize=(8, 4))\nplt.subplots_adjust(bottom=0.15)\n\np_c, p_w_c = plot_2d(ax1, n_labels=1)\nax1.set_title(\"n_labels=1, length=50\")\nax1.set_ylabel(\"Feature 1 count\")\n\nplot_2d(ax2, n_labels=3)\nax2.set_title(\"n_labels=3, length=50\")\nax2.set_xlim(left=0, auto=True)\nax2.set_ylim(bottom=0, auto=True)\n\nplt.show()\n\nprint(\"The data was generated from (random_state=%d):\" % RANDOM_SEED)",
                "filename": "examples/datasets/plot_random_multilabel_dataset.py",
                "start_index": 0,
                "end_index": 2999,
                "start_line": 1,
                "end_line": 103,
                "max_line": 106,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"Generate isotropic Gaussian blobs for clustering.\n\n    Read more in the :ref:`User Guide <sample_generators>`.\n\n    Parameters\n    ----------\n    n_samples : int or array-like, default=100\n        If int, it is the total number of points equally divided among\n        clusters.\n        If array-like, each element of the sequence indicates\n        the number of samples per cluster.\n\n        .. versionchanged:: v0.20\n            one can now pass an array-like to the ``n_samples`` parameter\n\n    n_features : int, default=2\n        The number of features for each sample.\n\n    centers : int or array-like of shape (n_centers, n_features), default=None\n        The number of centers to generate, or the fixed center locations.\n        If n_samples is an int and centers is None, 3 centers are generated.\n        If n_samples is array-like, centers must be\n        either None or an array of length equal to the length of n_samples.\n\n    cluster_std : float or array-like of float, default=1.0\n        The standard deviation of the clusters.\n\n    center_box : tuple of float (min, max), default=(-10.0, 10.0)\n        The bounding box for each cluster center when centers are\n        generated at random.\n\n    shuffle : bool, default=True\n        Shuffle the samples.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for dataset creation. Pass an int\n        for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    return_centers : bool, default=False\n        If True, then return the centers of each cluster.\n\n        .. versionadded:: 0.23\n\n    Returns\n    -------\n    X : ndarray of shape (n_samples, n_features)\n        The generated samples.\n\n    y : ndarray of shape (n_samples,)\n        The integer labels for cluster membership of each sample.\n\n    centers : ndarray of shape (n_centers, n_features)\n        The centers of each cluster. Only returned if\n        ``return_centers=True``.\n\n    See Also\n    --------\n    make_classification : A more intricate variant.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_blobs\n    >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n    ...                   random_state=0)\n    >>> print(X.shape)\n    (10, 2)\n    >>> y\n    array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n    >>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n    ...                   random_state=0)\n    >>> print(X.shape)\n    (10, 2)\n    >>> y\n    array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n    \"\"\"\n    generator = check_random_state(random_state)",
                "filename": "sklearn/datasets/_samples_generator.py",
                "start_index": 31331,
                "end_index": 33948,
                "start_line": 888,
                "end_line": 2074,
                "max_line": 2126,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "@validate_params(\n    {\n        \"n_samples\": [Interval(Integral, 0, None, closed=\"left\"), tuple],\n        \"shuffle\": [\"boolean\"],\n        \"noise\": [Interval(Real, 0, None, closed=\"left\"), None],\n        \"random_state\": [\"random_state\"],\n        \"factor\": [Interval(Real, 0, 1, closed=\"left\")],\n    },\n    prefer_skip_nested_validation=True,\n)",
                "filename": "sklearn/datasets/_samples_generator.py",
                "start_index": 24992,
                "end_index": 25334,
                "start_line": 42,
                "end_line": 2124,
                "max_line": 2126,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 1.0
            }
        ],
        "classification": "feature request",
        "snippet_processor_task": {
            "sklearn/datasets/_samples_generator.py": [
                {
                    "chunk": {
                        "code": "def make_blobs(\n    n_samples=100,\n    n_features=2,\n    *,\n    centers=None,\n    cluster_std=1.0,\n    center_box=(-10.0, 10.0),\n    shuffle=True,\n    random_state=None,\n    return_centers=False,\n):",
                        "filename": "sklearn/datasets/_samples_generator.py",
                        "start_index": 31128,
                        "end_index": 31326,
                        "start_line": 877,
                        "end_line": 2099,
                        "max_line": 2126,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet defines the make_blobs function, which is directly related to the issue as it needs to be modified to accept tuples for n_samples."
                },
                {
                    "chunk": {
                        "code": "\"\"\"Generate isotropic Gaussian blobs for clustering.\n\n    Read more in the :ref:`User Guide <sample_generators>`.\n\n    Parameters\n    ----------\n    n_samples : int or array-like, default=100\n        If int, it is the total number of points equally divided among\n        clusters.\n        If array-like, each element of the sequence indicates\n        the number of samples per cluster.\n\n        .. versionchanged:: v0.20\n            one can now pass an array-like to the ``n_samples`` parameter\n\n    n_features : int, default=2\n        The number of features for each sample.\n\n    centers : int or array-like of shape (n_centers, n_features), default=None\n        The number of centers to generate, or the fixed center locations.\n        If n_samples is an int and centers is None, 3 centers are generated.\n        If n_samples is array-like, centers must be\n        either None or an array of length equal to the length of n_samples.\n\n    cluster_std : float or array-like of float, default=1.0\n        The standard deviation of the clusters.\n\n    center_box : tuple of float (min, max), default=(-10.0, 10.0)\n        The bounding box for each cluster center when centers are\n        generated at random.\n\n    shuffle : bool, default=True\n        Shuffle the samples.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for dataset creation. Pass an int\n        for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    return_centers : bool, default=False\n        If True, then return the centers of each cluster.\n\n        .. versionadded:: 0.23\n\n    Returns\n    -------\n    X : ndarray of shape (n_samples, n_features)\n        The generated samples.\n\n    y : ndarray of shape (n_samples,)\n        The integer labels for cluster membership of each sample.\n\n    centers : ndarray of shape (n_centers, n_features)\n        The centers of each cluster. Only returned if\n        ``return_centers=True``.\n\n    See Also\n    --------\n    make_classification : A more intricate variant.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_blobs\n    >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n    ...                   random_state=0)\n    >>> print(X.shape)\n    (10, 2)\n    >>> y\n    array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n    >>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n    ...                   random_state=0)\n    >>> print(X.shape)\n    (10, 2)\n    >>> y\n    array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n    \"\"\"\n    generator = check_random_state(random_state)",
                        "filename": "sklearn/datasets/_samples_generator.py",
                        "start_index": 31331,
                        "end_index": 33948,
                        "start_line": 888,
                        "end_line": 2074,
                        "max_line": 2126,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the documentation of the make_blobs function, which will need to be updated to reflect the changes allowing n_samples to be a tuple."
                },
                {
                    "chunk": {
                        "code": "@validate_params(\n    {\n        \"n_samples\": [Interval(Integral, 0, None, closed=\"left\"), tuple],\n        \"shuffle\": [\"boolean\"],\n        \"noise\": [Interval(Real, 0, None, closed=\"left\"), None],\n        \"random_state\": [\"random_state\"],\n        \"factor\": [Interval(Real, 0, 1, closed=\"left\")],\n    },\n    prefer_skip_nested_validation=True,\n)",
                        "filename": "sklearn/datasets/_samples_generator.py",
                        "start_index": 24992,
                        "end_index": 25334,
                        "start_line": 42,
                        "end_line": 2124,
                        "max_line": 2126,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet includes parameter validation for the make_blobs function, which will likely need to be updated to validate the new tuple input for n_samples."
                },
                {
                    "chunk": {
                        "code": "def make_circles(\n    n_samples=100, *, shuffle=True, noise=None, random_state=None, factor=0.8\n):\n    \"\"\"Make a large circle containing a smaller circle in 2d.\n\n    A simple toy dataset to visualize clustering and classification\n    algorithms.\n\n    Read more in the :ref:`User Guide <sample_generators>`.\n\n    Parameters\n    ----------\n    n_samples : int or tuple of shape (2,), dtype=int, default=100\n        If int, it is the total number of points generated.\n        For odd numbers, the inner circle will have one point more than the\n        outer circle.\n        If two-element tuple, number of points in outer circle and inner\n        circle.\n\n        .. versionchanged:: 0.23\n           Added two-element tuple.\n\n    shuffle : bool, default=True\n        Whether to shuffle the samples.\n\n    noise : float, default=None\n        Standard deviation of Gaussian noise added to the data.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for dataset shuffling and noise.\n        Pass an int for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    factor : float, default=.8\n        Scale factor between inner and outer circle in the range `[0, 1)`.\n\n    Returns\n    -------\n    X : ndarray of shape (n_samples, 2)\n        The generated samples.\n\n    y : ndarray of shape (n_samples,)\n        The integer labels (0 or 1) for class membership of each sample.\n    \"\"\"\n    if isinstance(n_samples, numbers.Integral):\n        n_samples_out = n_samples // 2\n        n_samples_in = n_samples - n_samples_out\n    else:  # n_samples is a tuple\n        if len(n_samples) != 2:\n            raise ValueError(\"When a tuple, n_samples must have exactly two elements.\")\n        n_samples_out, n_samples_in = n_samples\n\n    generator = check_random_state(random_state)\n    # so as not to have the first point = last point, we set endpoint=False\n    linspace_out = np.linspace(0, 2 * np.pi, n_samples_out, endpoint=False)\n    linspace_in = np.linspace(0, 2 * np.pi, n_samples_in, endpoint=False)\n    outer_circ_x = np.cos(linspace_out)\n    outer_circ_y = np.sin(linspace_out)\n    inner_circ_x = np.cos(linspace_in) * factor\n    inner_circ_y = np.sin(linspace_in) * factor\n\n    X = np.vstack(\n        [np.append(outer_circ_x, inner_circ_x), np.append(outer_circ_y, inner_circ_y)]\n    ).T\n    y = np.hstack(\n        [np.zeros(n_samples_out, dtype=np.intp), np.ones(n_samples_in, dtype=np.intp)]\n    )\n    if shuffle:\n        X, y = util_shuffle(X, y, random_state=generator)\n\n    if noise is not None:\n        X += generator.normal(scale=noise, size=X.shape)\n\n    return X, y",
                        "filename": "sklearn/datasets/_samples_generator.py",
                        "start_index": 25335,
                        "end_index": 28008,
                        "start_line": 710,
                        "end_line": 1880,
                        "max_line": 2126,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet from make_circles function shows an example of handling tuple input for n_samples, which can serve as a reference for implementing similar functionality in make_blobs."
                }
            ]
        },
        "solution_task": "To implement the feature request of allowing `n_samples` to be a tuple in `make_blobs`, follow these steps:\n\n- Modify the `make_blobs` function signature to accept `n_samples` as an `int` or a `tuple` of `int`.\n- Update the function to handle `n_samples` when it is a tuple by generating the specified number of samples for each class.\n- Ensure that the total number of samples generated matches the sum of the elements in the tuple.\n- Update the documentation to reflect the new functionality.\n- Add tests to verify that the function behaves as expected when `n_samples` is a tuple.\n\nHere is a code snippet that demonstrates the changes to the `make_blobs` function:\n\n```python\nfrom sklearn.utils import check_random_state, shuffle as util_shuffle\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n@_deprecate_positional_args\ndef make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0,\n               center_box=(-10.0, 10.0), shuffle=True, random_state=None,\n               return_centers=False):\n    # Handle tuple for n_samples\n    if isinstance(n_samples, tuple):\n        if centers is not None and len(centers) != len(n_samples):\n            raise ValueError(\"If n_samples is a tuple, centers must be None or have the same length.\")\n        n_samples_per_center = n_samples\n        n_samples = sum(n_samples)\n    else:\n        if centers is None:\n            centers = 3\n        if isinstance(centers, int):\n            centers = generator.uniform(center_box[0], center_box[1], size=(centers, n_features))\n        n_samples_per_center = [n_samples // len(centers)] * len(centers)\n        for i in range(n_samples % len(centers)):\n            n_samples_per_center[i] += 1\n\n    # Rest of the function remains unchanged, but use n_samples_per_center\n    # to generate the appropriate number of samples for each cluster\n\n    # ... (existing code to generate blobs)\n\n    return X, y\n```\n\n- Update the documentation string to include the new functionality.\n- Add unit tests to cover cases where `n_samples` is a tuple, including edge cases and error handling.\n- Ensure that existing tests pass with the new changes.\n\nFor further research, you may want to look into:\n- NumPy for array manipulations and random number generation.\n- scikit-learn's utilities for input validation and shuffling.\n- Unit testing frameworks such as pytest to write and run tests for the new feature.",
        "bouncer_response": {
            "score": 9,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant suggestions that can directly lead to the successful implementation or improvement of the requested feature.",
            "supporting_evidence": "The RESPONSE provides a clear and detailed plan for implementing the feature request, including modifying the function signature, updating the function logic, and ensuring the total number of samples matches the sum of the tuple elements. It also includes a code snippet demonstrating the proposed changes, which is directly applicable and provides a practical example of how to handle the tuple input for n_samples. Additionally, the RESPONSE suggests updating the documentation, adding tests for the new functionality, and ensuring existing tests pass, which are all essential steps in the development process. The RESPONSE also points to further research and resources, such as NumPy and unit testing frameworks, which are relevant to the feature development. Lastly, it provides specific code snippets from the scikit-learn repository to check, which is valuable for developers working on this feature.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711742506.329144,
        "result": "To implement the feature request of allowing `n_samples` to be a tuple in `make_blobs`, follow these steps:\n\n- Modify the `make_blobs` function signature to accept `n_samples` as an `int` or a `tuple` of `int`.\n- Update the function to handle `n_samples` when it is a tuple by generating the specified number of samples for each class.\n- Ensure that the total number of samples generated matches the sum of the elements in the tuple.\n- Update the documentation to reflect the new functionality.\n- Add tests to verify that the function behaves as expected when `n_samples` is a tuple.\n\nHere is a code snippet that demonstrates the changes to the `make_blobs` function:\n\n```python\nfrom sklearn.utils import check_random_state, shuffle as util_shuffle\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n@_deprecate_positional_args\ndef make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0,\n               center_box=(-10.0, 10.0), shuffle=True, random_state=None,\n               return_centers=False):\n    # Handle tuple for n_samples\n    if isinstance(n_samples, tuple):\n        if centers is not None and len(centers) != len(n_samples):\n            raise ValueError(\"If n_samples is a tuple, centers must be None or have the same length.\")\n        n_samples_per_center = n_samples\n        n_samples = sum(n_samples)\n    else:\n        if centers is None:\n            centers = 3\n        if isinstance(centers, int):\n            centers = generator.uniform(center_box[0], center_box[1], size=(centers, n_features))\n        n_samples_per_center = [n_samples // len(centers)] * len(centers)\n        for i in range(n_samples % len(centers)):\n            n_samples_per_center[i] += 1\n\n    # Rest of the function remains unchanged, but use n_samples_per_center\n    # to generate the appropriate number of samples for each cluster\n\n    # ... (existing code to generate blobs)\n\n    return X, y\n```\n\n- Update the documentation string to include the new functionality.\n- Add unit tests to cover cases where `n_samples` is a tuple, including edge cases and error handling.\n- Ensure that existing tests pass with the new changes.\n\nFor further research, you may want to look into:\n- NumPy for array manipulations and random number generation.\n- scikit-learn's utilities for input validation and shuffling.\n- Unit testing frameworks such as pytest to write and run tests for the new feature.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [datasets](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/datasets)- [Lines 877 - 2099](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L877-L2099)\n\n This snippet defines the make_blobs function, which is directly related to the issue as it needs to be modified to accept tuples for n_samples. \n\n\n   - [Lines 888 - 2074](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L888-L2074)\n\n This snippet contains the documentation of the make_blobs function, which will need to be updated to reflect the changes allowing n_samples to be a tuple. \n\n\n   - [Lines 42 - 2124](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L42-L2124)\n\n This snippet includes parameter validation for the make_blobs function, which will likely need to be updated to validate the new tuple input for n_samples. \n\n\n   - [Lines 710 - 1880](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/datasets/_samples_generator.py#L710-L1880)\n\n This snippet from make_circles function shows an example of handling tuple input for n_samples, which can serve as a reference for implementing similar functionality in make_blobs.",
        "context_relevance": 0.41,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers the PROMPT completely.\nSupporting Evidence: The RESPONSE provides a detailed explanation of how to implement the feature request for `make_blobs` to accept a tuple for `n_samples`, which is exactly what the PROMPT is asking for. It includes steps for modifying the function, updating documentation, and adding tests, as well as a code snippet demonstrating the changes. Additionally, it provides relevant links to the scikit-learn repository for further research and examples, which directly relates to the example given in the PROMPT. The RESPONSE is comprehensive and addresses all aspects of the PROMPT, thus earning a score of 10."
        },
        "qa_relevance": 1.0
    }
}