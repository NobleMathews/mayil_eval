{
    "id": "pydata__xarray-5180",
    "repo_name": "testbed/pydata__xarray__0.12",
    "task_id": 637232547830657454,
    "title": "open_dataset uses cftime, not datetime64, when calendar attribute is \"Gregorian\"",
    "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports: http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples: https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nI used `xarray.open_dataset` to open a NetCDF file whose `time` coordinate had the `calendar` attribute set to `Gregorian`. All dates were within the Timestamp-valid range.\r\n\r\nThe resulting dataset represented the `time` co-ordinate as a\r\n`cftime._cftime.DatetimeGregorian`.\r\n\r\n**What you expected to happen**:\r\n\r\nI expected the dataset to represent the `time` co-ordinate as a `datetime64[ns]`, as documented [here](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html) and [here](http://xarray.pydata.org/en/stable/weather-climate.html#non-standard-calendars-and-dates-outside-the-timestamp-valid-range).\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport xarray as xr\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\ndef print_time_type(dataset):\r\n    print(dataset.time.dtype, type(dataset.time[0].item()))\r\n\r\nda = xr.DataArray(\r\n    data=[32, 16, 8],\r\n    dims=[\"time\"],\r\n    coords=dict(\r\n        time=pd.date_range(\"2014-09-06\", periods=3),\r\n        reference_time=pd.Timestamp(\"2014-09-05\"),\r\n    ),\r\n)\r\n\r\n\r\n# Create dataset and confirm type of time\r\nds1 = xr.Dataset({\"myvar\": da})\r\nprint_time_type(ds1)  # prints \"datetime64[ns]\" <class 'int'>\r\n\r\n# Manually set time attributes to \"Gregorian\" rather\r\n# than default \"proleptic_gregorian\".\r\nds1.time.encoding[\"calendar\"] = \"Gregorian\"\r\nds1.reference_time.encoding[\"calendar\"] = \"Gregorian\"\r\nds1.to_netcdf(\"test-capitalized.nc\")\r\n\r\nds2 = xr.open_dataset(\"test-capitalized.nc\")\r\nprint_time_type(ds2)\r\n# prints \"object <class 'cftime._cftime.DatetimeGregorian'>\"\r\n\r\n# Workaround: add \"Gregorian\" to list of standard calendars.\r\nxr.coding.times._STANDARD_CALENDARS.add(\"Gregorian\")\r\nds3 = xr.open_dataset(\"test-capitalized.nc\")\r\nprint_time_type(ds3)  # prints \"datetime64[ns]\" <class 'int'>\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nThe [documentation for the `use_cftime` parameter of `open_dataset`](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html) says:\r\n\r\n> If None (default), attempt to decode times to `np.datetime64[ns]` objects; if this is not possible, decode times to `cftime.datetime` objects.\r\n\r\nIn practice, we are getting some `cftime.datetime`s even for times which are interpretable and representable as `np.datetime64[ns]`s. In particular, we have some NetCDF files in which the `time` variable has a `calendar` attribute with a value of `Gregorian` (with a capital \u2018G\u2019). CF conventions [allow this](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.8/cf-conventions.html#_attributes):\r\n\r\n> When this standard defines string attributes that may take various prescribed values, the possible values are generally given in lower case. However, applications programs should not be sensitive to case in these attributes.\r\n\r\nHowever, xarray regards `Gregorian` as a non-standard calendar and falls back to `cftime.datetime`. If (as in the example) `Gregorian` is added to `xr.coding.times._STANDARD_CALENDARS`, the times are read as `np.datetime64[ns]`s.\r\n\r\nSuggested fix: in [`xarray.coding.times._decode_datetime_with_pandas`](https://github.com/pydata/xarray/blob/45b4436bd5a82e7020357cf681b13067a8dd59e9/xarray/coding/times.py#L169), change \u2018`if calendar not in _STANDARD_CALENDARS:`\u2019 to \u2018`if calendar.lower() not in _STANDARD_CALENDARS:`\u2019.\r\n\r\n**Environment**:\r\n\r\n<details><summary>Output of <tt>xr.show_versions()</tt></summary>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.9.2 | packaged by conda-forge | (default, Feb 21 2021, 05:02:46) \r\n[GCC 9.3.0]\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 5.8.0-48-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_GB.UTF-8\r\nLOCALE: en_GB.UTF-8\r\nlibhdf5: 1.10.6\r\nlibnetcdf: 4.7.4\r\n\r\nxarray: 0.17.1.dev39+g45b4436b\r\npandas: 1.2.3\r\nnumpy: 1.20.2\r\nscipy: None\r\nnetCDF4: 1.5.6\r\npydap: None\r\nh5netcdf: None\r\nh5py: None\r\nNio: None\r\nzarr: None\r\ncftime: 1.4.1\r\nnc_time_axis: None\r\nPseudoNetCDF: None\r\nrasterio: None\r\ncfgrib: None\r\niris: None\r\nbottleneck: None\r\ndask: None\r\ndistributed: None\r\nmatplotlib: None\r\ncartopy: None\r\nseaborn: None\r\nnumbagg: None\r\npint: None\r\nsetuptools: 49.6.0.post20210108\r\npip: 21.0.1\r\nconda: None\r\npytest: None\r\nIPython: None\r\nsphinx: None\r\n\r\n<!-- Paste the output here xr.show_versions() here -->\r\n\r\n</details>\r\n\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/pydata__xarray__0.12.git",
    "requested_commit": "",
    "mayil_response": "To address the issue where `xarray.open_dataset` is not handling the `calendar` attribute case-insensitively, leading to the `time` coordinate being represented as `cftime._cftime.DatetimeGregorian` instead of `datetime64[ns]`, the following changes should be made:\n\n- Modify the `_is_standard_calendar` function in `xarray/coding/times.py` to perform a case-insensitive comparison by converting the `calendar` string to lowercase before checking if it is in `_STANDARD_CALENDARS`.\n- Ensure that any other comparisons with calendar names in `xarray/coding/times.py` are also case-insensitive.\n\nHere is the updated `_is_standard_calendar` function:\n\n```python\ndef _is_standard_calendar(calendar: str) -> bool:\n    return calendar.lower() in {cal.lower() for cal in _STANDARD_CALENDARS}\n```\n\nMake sure to apply the `.lower()` method to the `calendar` variable in any other place where it is compared to the entries in `_STANDARD_CALENDARS` or any other set of calendar names.\n\n### Code snippets to check\n\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [coding](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/coding)- [Lines 1 - 122](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/coding/times.py#L1-L122)\n\n This snippet contains the definition of _STANDARD_CALENDARS and the function _is_standard_calendar which is directly related to the issue of recognizing 'Gregorian' as a standard calendar. \n\n\n   - [Lines 265 - 342](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/coding/times.py#L265-L342)\n\n This snippet contains the decode_cf_datetime function which is responsible for decoding time units and may need to be modified to handle the 'Gregorian' calendar attribute correctly. \n\n\n   - [Lines 345 - 405](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/coding/times.py#L345-L405)\n\n This snippet includes the infer_calendar_name function which could be relevant if the calendar inference logic needs to be updated to handle different cases of calendar attribute capitalization.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0005495,
        "snippet_processor": 0.06112,
        "issue_star_creation": 0.025959999999999997,
        "issue_star_solver": 0.08023,
        "bouncer": 0.027180000000000003
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711759330.691326,
        "relevant_snippets": [
            {
                "code": "from __future__ import annotations\n\nimport re\nimport warnings\nfrom collections.abc import Hashable\nfrom datetime import datetime, timedelta\nfrom functools import partial\nfrom typing import TYPE_CHECKING, Callable, Union\n\nimport numpy as np\nimport pandas as pd\nfrom pandas.errors import OutOfBoundsDatetime, OutOfBoundsTimedelta\n\nfrom xarray.coding.variables import (\n    SerializationWarning,\n    VariableCoder,\n    lazy_elemwise_func,\n    pop_to,\n    safe_setitem,\n    unpack_for_decoding,\n    unpack_for_encoding,\n)\nfrom xarray.core import indexing\nfrom xarray.core.common import contains_cftime_datetimes, is_np_datetime_like\nfrom xarray.core.formatting import first_n_items, format_timestamp, last_item\nfrom xarray.core.pdcompat import nanosecond_precision_timestamp\nfrom xarray.core.pycompat import is_duck_dask_array\nfrom xarray.core.variable import Variable\n\ntry:\n    import cftime\nexcept ImportError:\n    cftime = None\n\nif TYPE_CHECKING:\n    from xarray.core.types import CFCalendar\n\n    T_Name = Union[Hashable, None]\n\n# standard calendars recognized by cftime\n_STANDARD_CALENDARS = {\"standard\", \"gregorian\", \"proleptic_gregorian\"}\n\n_NS_PER_TIME_DELTA = {\n    \"ns\": 1,\n    \"us\": int(1e3),\n    \"ms\": int(1e6),\n    \"s\": int(1e9),\n    \"m\": int(1e9) * 60,\n    \"h\": int(1e9) * 60 * 60,\n    \"D\": int(1e9) * 60 * 60 * 24,\n}\n\n_US_PER_TIME_DELTA = {\n    \"microseconds\": 1,\n    \"milliseconds\": 1_000,\n    \"seconds\": 1_000_000,\n    \"minutes\": 60 * 1_000_000,\n    \"hours\": 60 * 60 * 1_000_000,\n    \"days\": 24 * 60 * 60 * 1_000_000,\n}\n\n_NETCDF_TIME_UNITS_CFTIME = [\n    \"days\",\n    \"hours\",\n    \"minutes\",\n    \"seconds\",\n    \"milliseconds\",\n    \"microseconds\",\n]\n\n_NETCDF_TIME_UNITS_NUMPY = _NETCDF_TIME_UNITS_CFTIME + [\"nanoseconds\"]\n\nTIME_UNITS = frozenset(\n    [\n        \"days\",\n        \"hours\",\n        \"minutes\",\n        \"seconds\",\n        \"milliseconds\",\n        \"microseconds\",\n        \"nanoseconds\",\n    ]\n)\n\n\ndef _is_standard_calendar(calendar: str) -> bool:\n    return calendar.lower() in _STANDARD_CALENDARS\n\n\ndef _is_numpy_compatible_time_range(times):\n    if is_np_datetime_like(times.dtype):\n        return True\n    # times array contains cftime objects\n    times = np.asarray(times)\n    tmin = times.min()\n    tmax = times.max()\n    try:\n        convert_time_or_go_back(tmin, pd.Timestamp)\n        convert_time_or_go_back(tmax, pd.Timestamp)\n    except pd.errors.OutOfBoundsDatetime:\n        return False\n    except ValueError as err:\n        if err.args[0] == \"year 0 is out of range\":\n            return False\n        raise\n    else:\n        return True\n\n\ndef _netcdf_to_numpy_timeunit(units: str) -> str:\n    units = units.lower()\n    if not units.endswith(\"s\"):\n        units = f\"{units}s\"\n    return {\n        \"nanoseconds\": \"ns\",\n        \"microseconds\": \"us\",\n        \"milliseconds\": \"ms\",\n        \"seconds\": \"s\",\n        \"minutes\": \"m\",\n        \"hours\": \"h\",\n        \"days\": \"D\",\n    }[units]",
                "filename": "xarray/coding/times.py",
                "start_index": 0,
                "end_index": 2910,
                "start_line": 1,
                "end_line": 122,
                "max_line": 762,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "from __future__ import annotations\n\nimport warnings\nfrom typing import TYPE_CHECKING, Generic\n\nimport numpy as np\nimport pandas as pd\n\nfrom xarray.coding.times import infer_calendar_name\nfrom xarray.core.common import (\n    _contains_datetime_like_objects,\n    is_np_datetime_like,\n    is_np_timedelta_like,\n)\nfrom xarray.core.pycompat import is_duck_dask_array\nfrom xarray.core.types import T_DataArray\nfrom xarray.core.variable import IndexVariable\n\nif TYPE_CHECKING:\n    from numpy.typing import DTypeLike\n\n    from xarray.core.dataarray import DataArray\n    from xarray.core.dataset import Dataset\n    from xarray.core.types import CFCalendar\n\n\ndef _season_from_months(months):\n    \"\"\"Compute season (DJF, MAM, JJA, SON) from month ordinal\"\"\"\n    # TODO: Move \"season\" accessor upstream into pandas\n    seasons = np.array([\"DJF\", \"MAM\", \"JJA\", \"SON\", \"nan\"])\n    months = np.asarray(months)\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\n            \"ignore\", message=\"invalid value encountered in floor_divide\"\n        )\n        warnings.filterwarnings(\n            \"ignore\", message=\"invalid value encountered in remainder\"\n        )\n        idx = (months // 3) % 4\n\n    idx[np.isnan(idx)] = 4\n    return seasons[idx.astype(int)]\n\n\ndef _access_through_cftimeindex(values, name):\n    \"\"\"Coerce an array of datetime-like values to a CFTimeIndex\n    and access requested datetime component\n    \"\"\"\n    from xarray.coding.cftimeindex import CFTimeIndex\n\n    if not isinstance(values, CFTimeIndex):\n        values_as_cftimeindex = CFTimeIndex(values.ravel())\n    else:\n        values_as_cftimeindex = values\n    if name == \"season\":\n        months = values_as_cftimeindex.month\n        field_values = _season_from_months(months)\n    elif name == \"date\":\n        raise AttributeError(\n            \"'CFTimeIndex' object has no attribute `date`. Consider using the floor method instead, for instance: `.time.dt.floor('D')`.\"\n        )\n    else:\n        field_values = getattr(values_as_cftimeindex, name)\n    return field_values.reshape(values.shape)\n\n\ndef _access_through_series(values, name):\n    \"\"\"Coerce an array of datetime-like values to a pandas Series and\n    access requested datetime component\n    \"\"\"\n    values_as_series = pd.Series(values.ravel(), copy=False)\n    if name == \"season\":\n        months = values_as_series.dt.month.values\n        field_values = _season_from_months(months)\n    elif name == \"isocalendar\":\n        # isocalendar returns iso- year, week, and weekday -> reshape\n        field_values = np.array(values_as_series.dt.isocalendar(), dtype=np.int64)\n        return field_values.T.reshape(3, *values.shape)\n    else:\n        field_values = getattr(values_as_series.dt, name).values\n    return field_values.reshape(values.shape)",
                "filename": "xarray/core/accessor_dt.py",
                "start_index": 0,
                "end_index": 2782,
                "start_line": 1,
                "end_line": 140,
                "max_line": 599,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def _decode_cf_datetime_dtype(\n    data, units: str, calendar: str, use_cftime: bool | None\n) -> np.dtype:\n    # Verify that at least the first and last date can be decoded\n    # successfully. Otherwise, tracebacks end up swallowed by\n    # Dataset.__repr__ when users try to view their lazily decoded array.\n    values = indexing.ImplicitToExplicitIndexingAdapter(indexing.as_indexable(data))\n    example_value = np.concatenate(\n        [first_n_items(values, 1) or [0], last_item(values) or [0]]\n    )\n\n    try:\n        result = decode_cf_datetime(example_value, units, calendar, use_cftime)\n    except Exception:\n        calendar_msg = (\n            \"the default calendar\" if calendar is None else f\"calendar {calendar!r}\"\n        )\n        msg = (\n            f\"unable to decode time units {units!r} with {calendar_msg!r}. Try \"\n            \"opening your dataset with decode_times=False or installing cftime \"\n            \"if it is not installed.\"\n        )\n        raise ValueError(msg)\n    else:\n        dtype = getattr(result, \"dtype\", np.dtype(\"object\"))\n\n    return dtype\n\n\ndef _decode_datetime_with_cftime(\n    num_dates: np.ndarray, units: str, calendar: str\n) -> np.ndarray:\n    if cftime is None:\n        raise ModuleNotFoundError(\"No module named 'cftime'\")\n    if num_dates.size > 0:\n        return np.asarray(\n            cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)\n        )\n    else:\n        return np.array([], dtype=object)",
                "filename": "xarray/coding/times.py",
                "start_index": 5064,
                "end_index": 6539,
                "start_line": 174,
                "end_line": 213,
                "max_line": 762,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "def decode_cf_datetime(\n    num_dates, units: str, calendar: str | None = None, use_cftime: bool | None = None\n) -> np.ndarray:\n    \"\"\"Given an array of numeric dates in netCDF format, convert it into a\n    numpy array of date time objects.\n\n    For standard (Gregorian) calendars, this function uses vectorized\n    operations, which makes it much faster than cftime.num2date. In such a\n    case, the returned array will be of type np.datetime64.\n\n    Note that time unit in `units` must not be smaller than microseconds and\n    not larger than days.\n\n    See Also\n    --------\n    cftime.num2date\n    \"\"\"\n    num_dates = np.asarray(num_dates)\n    flat_num_dates = num_dates.ravel()\n    if calendar is None:\n        calendar = \"standard\"\n\n    if use_cftime is None:\n        try:\n            dates = _decode_datetime_with_pandas(flat_num_dates, units, calendar)\n        except (KeyError, OutOfBoundsDatetime, OutOfBoundsTimedelta, OverflowError):\n            dates = _decode_datetime_with_cftime(\n                flat_num_dates.astype(float), units, calendar\n            )\n\n            if (\n                dates[np.nanargmin(num_dates)].year < 1678\n                or dates[np.nanargmax(num_dates)].year >= 2262\n            ):\n                if _is_standard_calendar(calendar):\n                    warnings.warn(\n                        \"Unable to decode time axis into full \"\n                        \"numpy.datetime64 objects, continuing using \"\n                        \"cftime.datetime objects instead, reason: dates out \"\n                        \"of range\",\n                        SerializationWarning,\n                        stacklevel=3,\n                    )\n            else:\n                if _is_standard_calendar(calendar):\n                    dates = cftime_to_nptime(dates)\n    elif use_cftime:\n        dates = _decode_datetime_with_cftime(flat_num_dates, units, calendar)\n    else:\n        dates = _decode_datetime_with_pandas(flat_num_dates, units, calendar)\n\n    return dates.reshape(num_dates.shape)\n\n\ndef to_timedelta_unboxed(value, **kwargs):\n    result = pd.to_timedelta(value, **kwargs).to_numpy()\n    assert result.dtype == \"timedelta64[ns]\"\n    return result\n\n\ndef to_datetime_unboxed(value, **kwargs):\n    result = pd.to_datetime(value, **kwargs).to_numpy()\n    assert result.dtype == \"datetime64[ns]\"\n    return result\n\n\ndef decode_cf_timedelta(num_timedeltas, units: str) -> np.ndarray:\n    \"\"\"Given an array of numeric timedeltas in netCDF format, convert it into a\n    numpy timedelta64[ns] array.\n    \"\"\"\n    num_timedeltas = np.asarray(num_timedeltas)\n    units = _netcdf_to_numpy_timeunit(units)\n    result = to_timedelta_unboxed(num_timedeltas.ravel(), unit=units)\n    return result.reshape(num_timedeltas.shape)\n\n\ndef _unit_timedelta_cftime(units: str) -> timedelta:\n    return timedelta(microseconds=_US_PER_TIME_DELTA[units])",
                "filename": "xarray/coding/times.py",
                "start_index": 8857,
                "end_index": 11720,
                "start_line": 265,
                "end_line": 342,
                "max_line": 762,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.7
            },
            {
                "code": "def _unit_timedelta_numpy(units: str) -> np.timedelta64:\n    numpy_units = _netcdf_to_numpy_timeunit(units)\n    return np.timedelta64(_NS_PER_TIME_DELTA[numpy_units], \"ns\")\n\n\ndef _infer_time_units_from_diff(unique_timedeltas) -> str:\n    unit_timedelta: Callable[[str], timedelta] | Callable[[str], np.timedelta64]\n    zero_timedelta: timedelta | np.timedelta64\n    if unique_timedeltas.dtype == np.dtype(\"O\"):\n        time_units = _NETCDF_TIME_UNITS_CFTIME\n        unit_timedelta = _unit_timedelta_cftime\n        zero_timedelta = timedelta(microseconds=0)\n    else:\n        time_units = _NETCDF_TIME_UNITS_NUMPY\n        unit_timedelta = _unit_timedelta_numpy\n        zero_timedelta = np.timedelta64(0, \"ns\")\n    for time_unit in time_units:\n        if np.all(unique_timedeltas % unit_timedelta(time_unit) == zero_timedelta):\n            return time_unit\n    return \"seconds\"\n\n\ndef infer_calendar_name(dates) -> CFCalendar:\n    \"\"\"Given an array of datetimes, infer the CF calendar name\"\"\"\n    if is_np_datetime_like(dates.dtype):\n        return \"proleptic_gregorian\"\n    elif dates.dtype == np.dtype(\"O\") and dates.size > 0:\n        # Logic copied from core.common.contains_cftime_datetimes.\n        if cftime is not None:\n            sample = np.asarray(dates).flat[0]\n            if is_duck_dask_array(sample):\n                sample = sample.compute()\n                if isinstance(sample, np.ndarray):\n                    sample = sample.item()\n            if isinstance(sample, cftime.datetime):\n                return sample.calendar\n\n    # Error raise if dtype is neither datetime or \"O\", if cftime is not importable, and if element of 'O' dtype is not cftime.\n    raise ValueError(\"Array does not contain datetime objects.\")\n\n\ndef infer_datetime_units(dates) -> str:\n    \"\"\"Given an array of datetimes, returns a CF compatible time-unit string of\n    the form \"{time_unit} since {date[0]}\", where `time_unit` is 'days',\n    'hours', 'minutes' or 'seconds' (the first one that can evenly divide all\n    unique time deltas in `dates`)\n    \"\"\"\n    dates = np.asarray(dates).ravel()\n    if np.asarray(dates).dtype == \"datetime64[ns]\":\n        dates = to_datetime_unboxed(dates)\n        dates = dates[pd.notnull(dates)]\n        reference_date = dates[0] if len(dates) > 0 else \"1970-01-01\"\n        # TODO: the strict enforcement of nanosecond precision Timestamps can be\n        # relaxed when addressing GitHub issue #7493.\n        reference_date = nanosecond_precision_timestamp(reference_date)\n    else:\n        reference_date = dates[0] if len(dates) > 0 else \"1970-01-01\"\n        reference_date = format_cftime_datetime(reference_date)\n    unique_timedeltas = np.unique(np.diff(dates))\n    units = _infer_time_units_from_diff(unique_timedeltas)\n    return f\"{units} since {reference_date}\"",
                "filename": "xarray/coding/times.py",
                "start_index": 11723,
                "end_index": 14521,
                "start_line": 345,
                "end_line": 405,
                "max_line": 762,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"Time offset classes for use with cftime.datetime objects\"\"\"\n# The offset classes and mechanisms for generating time ranges defined in\n# this module were copied/adapted from those defined in pandas.  See in\n# particular the objects and methods defined in pandas.tseries.offsets\n# and pandas.core.indexes.datetimes.\n\n# For reference, here is a copy of the pandas copyright notice:\n\n# (c) 2011-2012, Lambda Foundry, Inc. and PyData Development Team\n# All rights reserved.\n\n# Copyright (c) 2008-2011 AQR Capital Management, LLC\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are\n# met:\n\n#     * Redistributions of source code must retain the above copyright\n#        notice, this list of conditions and the following disclaimer.\n\n#     * Redistributions in binary form must reproduce the above\n#        copyright notice, this list of conditions and the following\n#        disclaimer in the documentation and/or other materials provided\n#        with the distribution.\n\n#     * Neither the name of the copyright holder nor the names of any\n#        contributors may be used to endorse or promote products derived\n#        from this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDER AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nfrom __future__ import annotations\n\nimport re\nfrom datetime import datetime, timedelta\nfrom functools import partial\nfrom typing import TYPE_CHECKING, ClassVar\n\nimport numpy as np\nimport pandas as pd\n\nfrom xarray.coding.cftimeindex import CFTimeIndex, _parse_iso8601_with_reso\nfrom xarray.coding.times import (\n    _is_standard_calendar,\n    _should_cftime_be_used,\n    convert_time_or_go_back,\n    format_cftime_datetime,\n)\nfrom xarray.core.common import _contains_datetime_like_objects, is_np_datetime_like\nfrom xarray.core.pdcompat import (\n    NoDefault,\n    count_not_none,\n    nanosecond_precision_timestamp,\n    no_default,\n)\nfrom xarray.core.utils import emit_user_level_warning\n\ntry:\n    import cftime\nexcept ImportError:\n    cftime = None\n\n\nif TYPE_CHECKING:\n    from xarray.core.types import InclusiveOptions, SideOptions",
                "filename": "xarray/coding/cftime_offsets.py",
                "start_index": 0,
                "end_index": 2906,
                "start_line": 1,
                "end_line": 75,
                "max_line": 1322,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "from __future__ import annotations\n\nimport functools\nimport io\nimport os\nfrom collections.abc import Iterable\nfrom typing import TYPE_CHECKING, Any\n\nfrom xarray.backends.common import (\n    BACKEND_ENTRYPOINTS,\n    BackendEntrypoint,\n    WritableCFDataStore,\n    _normalize_path,\n    find_root_and_group,\n)\nfrom xarray.backends.file_manager import CachingFileManager, DummyFileManager\nfrom xarray.backends.locks import HDF5_LOCK, combine_locks, ensure_lock, get_write_lock\nfrom xarray.backends.netCDF4_ import (\n    BaseNetCDF4Array,\n    _encode_nc4_variable,\n    _ensure_no_forward_slash_in_name,\n    _extract_nc4_variable_encoding,\n    _get_datatype,\n    _nc4_require_group,\n)\nfrom xarray.backends.store import StoreBackendEntrypoint\nfrom xarray.core import indexing\nfrom xarray.core.utils import (\n    FrozenDict,\n    is_remote_uri,\n    read_magic_number_from_file,\n    try_read_magic_number_from_file_or_path,\n)\nfrom xarray.core.variable import Variable\n\nif TYPE_CHECKING:\n    from io import BufferedIOBase\n\n    from xarray.backends.common import AbstractDataStore\n    from xarray.core.dataset import Dataset\n\n\nclass H5NetCDFArrayWrapper(BaseNetCDF4Array):\n    def get_array(self, needs_lock=True):\n        ds = self.datastore._acquire(needs_lock)\n        return ds.variables[self.variable_name]\n\n    def __getitem__(self, key):\n        return indexing.explicit_indexing_adapter(\n            key, self.shape, indexing.IndexingSupport.OUTER_1VECTOR, self._getitem\n        )\n\n    def _getitem(self, key):\n        with self.datastore.lock:\n            array = self.get_array(needs_lock=False)\n            return array[key]\n\n\ndef maybe_decode_bytes(txt):\n    if isinstance(txt, bytes):\n        return txt.decode(\"utf-8\")\n    else:\n        return txt\n\n\ndef _read_attributes(h5netcdf_var):\n    # GH451\n    # to ensure conventions decoding works properly on Python 3, decode all\n    # bytes attributes to strings\n    attrs = {}\n    for k, v in h5netcdf_var.attrs.items():\n        if k not in [\"_FillValue\", \"missing_value\"]:\n            v = maybe_decode_bytes(v)\n        attrs[k] = v\n    return attrs\n\n\n_extract_h5nc_encoding = functools.partial(\n    _extract_nc4_variable_encoding,\n    lsd_okay=False,\n    h5py_okay=True,\n    backend=\"h5netcdf\",\n    unlimited_dims=None,\n)\n\n\ndef _h5netcdf_create_group(dataset, name):\n    return dataset.create_group(name)",
                "filename": "xarray/backends/h5netcdf_.py",
                "start_index": 0,
                "end_index": 2353,
                "start_line": 1,
                "end_line": 88,
                "max_line": 425,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "import numpy as np\n\nimport xarray as xr\n\nfrom . import parameterized\n\nNTIME = 365 * 30\n\n\n@parameterized([\"calendar\"], [(\"standard\", \"noleap\")])\nclass DateTimeAccessor:\n    def setup(self, calendar):\n        np.random.randn(NTIME)\n        time = xr.date_range(\"2000\", periods=30 * 365, calendar=calendar)\n        data = np.ones((NTIME,))\n        self.da = xr.DataArray(data, dims=\"time\", coords={\"time\": time})\n\n    def time_dayofyear(self, calendar):\n        self.da.time.dt.dayofyear\n\n    def time_year(self, calendar):\n        self.da.time.dt.year\n\n    def time_floor(self, calendar):\n        self.da.time.dt.floor(\"D\")",
                "filename": "asv_bench/benchmarks/accessors.py",
                "start_index": 0,
                "end_index": 621,
                "start_line": 1,
                "end_line": 25,
                "max_line": 25,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "from __future__ import annotations\n\nimport numpy as np\nimport pandas as pd\n\nfrom xarray.coding.cftime_offsets import date_range_like, get_date_type\nfrom xarray.coding.cftimeindex import CFTimeIndex\nfrom xarray.coding.times import _should_cftime_be_used, convert_times\nfrom xarray.core.common import _contains_datetime_like_objects, is_np_datetime_like\n\ntry:\n    import cftime\nexcept ImportError:\n    cftime = None\n\n\n_CALENDARS_WITHOUT_YEAR_ZERO = [\n    \"gregorian\",\n    \"proleptic_gregorian\",\n    \"julian\",\n    \"standard\",\n]\n\n\ndef _days_in_year(year, calendar, use_cftime=True):\n    \"\"\"Return the number of days in the input year according to the input calendar.\"\"\"\n    date_type = get_date_type(calendar, use_cftime=use_cftime)\n    if year == -1 and calendar in _CALENDARS_WITHOUT_YEAR_ZERO:\n        difference = date_type(year + 2, 1, 1) - date_type(year, 1, 1)\n    else:\n        difference = date_type(year + 1, 1, 1) - date_type(year, 1, 1)\n    return difference.days",
                "filename": "xarray/coding/calendar_ops.py",
                "start_index": 0,
                "end_index": 971,
                "start_line": 1,
                "end_line": 32,
                "max_line": 343,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def _parsed_string_to_bounds(date_type, resolution, parsed):\n    \"\"\"Generalization of\n    pandas.tseries.index.DatetimeIndex._parsed_string_to_bounds\n    for use with non-standard calendars and cftime.datetime\n    objects.\n    \"\"\"\n    if resolution == \"year\":\n        return (\n            date_type(parsed.year, 1, 1),\n            date_type(parsed.year + 1, 1, 1) - timedelta(microseconds=1),\n        )\n    elif resolution == \"month\":\n        if parsed.month == 12:\n            end = date_type(parsed.year + 1, 1, 1) - timedelta(microseconds=1)\n        else:\n            end = date_type(parsed.year, parsed.month + 1, 1) - timedelta(\n                microseconds=1\n            )\n        return date_type(parsed.year, parsed.month, 1), end\n    elif resolution == \"day\":\n        start = date_type(parsed.year, parsed.month, parsed.day)\n        return start, start + timedelta(days=1, microseconds=-1)\n    elif resolution == \"hour\":\n        start = date_type(parsed.year, parsed.month, parsed.day, parsed.hour)\n        return start, start + timedelta(hours=1, microseconds=-1)\n    elif resolution == \"minute\":\n        start = date_type(\n            parsed.year, parsed.month, parsed.day, parsed.hour, parsed.minute\n        )\n        return start, start + timedelta(minutes=1, microseconds=-1)\n    elif resolution == \"second\":\n        start = date_type(\n            parsed.year,\n            parsed.month,\n            parsed.day,\n            parsed.hour,\n            parsed.minute,\n            parsed.second,\n        )\n        return start, start + timedelta(seconds=1, microseconds=-1)\n    else:\n        raise KeyError\n\n\ndef get_date_field(datetimes, field):\n    \"\"\"Adapted from pandas.tslib.get_date_field\"\"\"\n    return np.array([getattr(date, field) for date in datetimes])\n\n\ndef _field_accessor(name, docstring=None, min_cftime_version=\"0.0\"):\n    \"\"\"Adapted from pandas.tseries.index._field_accessor\"\"\"\n\n    def f(self, min_cftime_version=min_cftime_version):\n        if cftime is None:\n            raise ModuleNotFoundError(\"No module named 'cftime'\")\n\n        if Version(cftime.__version__) >= Version(min_cftime_version):\n            return get_date_field(self._data, name)\n        else:\n            raise ImportError(\n                f\"The {name:!r} accessor requires a minimum \"\n                f\"version of cftime of {min_cftime_version}. Found an \"\n                f\"installed version of {cftime.__version__}.\"\n            )\n\n    f.__name__ = name\n    f.__doc__ = docstring\n    return property(f)\n\n\ndef get_date_type(self):\n    if self._data.size:\n        return type(self._data[0])\n    else:\n        return None",
                "filename": "xarray/coding/cftimeindex.py",
                "start_index": 4759,
                "end_index": 7378,
                "start_line": 144,
                "end_line": 218,
                "max_line": 859,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": "",
                "context_relevance": 0.2
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "xarray/coding/times.py": [
                {
                    "chunk": {
                        "code": "from __future__ import annotations\n\nimport re\nimport warnings\nfrom collections.abc import Hashable\nfrom datetime import datetime, timedelta\nfrom functools import partial\nfrom typing import TYPE_CHECKING, Callable, Union\n\nimport numpy as np\nimport pandas as pd\nfrom pandas.errors import OutOfBoundsDatetime, OutOfBoundsTimedelta\n\nfrom xarray.coding.variables import (\n    SerializationWarning,\n    VariableCoder,\n    lazy_elemwise_func,\n    pop_to,\n    safe_setitem,\n    unpack_for_decoding,\n    unpack_for_encoding,\n)\nfrom xarray.core import indexing\nfrom xarray.core.common import contains_cftime_datetimes, is_np_datetime_like\nfrom xarray.core.formatting import first_n_items, format_timestamp, last_item\nfrom xarray.core.pdcompat import nanosecond_precision_timestamp\nfrom xarray.core.pycompat import is_duck_dask_array\nfrom xarray.core.variable import Variable\n\ntry:\n    import cftime\nexcept ImportError:\n    cftime = None\n\nif TYPE_CHECKING:\n    from xarray.core.types import CFCalendar\n\n    T_Name = Union[Hashable, None]\n\n# standard calendars recognized by cftime\n_STANDARD_CALENDARS = {\"standard\", \"gregorian\", \"proleptic_gregorian\"}\n\n_NS_PER_TIME_DELTA = {\n    \"ns\": 1,\n    \"us\": int(1e3),\n    \"ms\": int(1e6),\n    \"s\": int(1e9),\n    \"m\": int(1e9) * 60,\n    \"h\": int(1e9) * 60 * 60,\n    \"D\": int(1e9) * 60 * 60 * 24,\n}\n\n_US_PER_TIME_DELTA = {\n    \"microseconds\": 1,\n    \"milliseconds\": 1_000,\n    \"seconds\": 1_000_000,\n    \"minutes\": 60 * 1_000_000,\n    \"hours\": 60 * 60 * 1_000_000,\n    \"days\": 24 * 60 * 60 * 1_000_000,\n}\n\n_NETCDF_TIME_UNITS_CFTIME = [\n    \"days\",\n    \"hours\",\n    \"minutes\",\n    \"seconds\",\n    \"milliseconds\",\n    \"microseconds\",\n]\n\n_NETCDF_TIME_UNITS_NUMPY = _NETCDF_TIME_UNITS_CFTIME + [\"nanoseconds\"]\n\nTIME_UNITS = frozenset(\n    [\n        \"days\",\n        \"hours\",\n        \"minutes\",\n        \"seconds\",\n        \"milliseconds\",\n        \"microseconds\",\n        \"nanoseconds\",\n    ]\n)\n\n\ndef _is_standard_calendar(calendar: str) -> bool:\n    return calendar.lower() in _STANDARD_CALENDARS\n\n\ndef _is_numpy_compatible_time_range(times):\n    if is_np_datetime_like(times.dtype):\n        return True\n    # times array contains cftime objects\n    times = np.asarray(times)\n    tmin = times.min()\n    tmax = times.max()\n    try:\n        convert_time_or_go_back(tmin, pd.Timestamp)\n        convert_time_or_go_back(tmax, pd.Timestamp)\n    except pd.errors.OutOfBoundsDatetime:\n        return False\n    except ValueError as err:\n        if err.args[0] == \"year 0 is out of range\":\n            return False\n        raise\n    else:\n        return True\n\n\ndef _netcdf_to_numpy_timeunit(units: str) -> str:\n    units = units.lower()\n    if not units.endswith(\"s\"):\n        units = f\"{units}s\"\n    return {\n        \"nanoseconds\": \"ns\",\n        \"microseconds\": \"us\",\n        \"milliseconds\": \"ms\",\n        \"seconds\": \"s\",\n        \"minutes\": \"m\",\n        \"hours\": \"h\",\n        \"days\": \"D\",\n    }[units]",
                        "filename": "xarray/coding/times.py",
                        "start_index": 0,
                        "end_index": 2910,
                        "start_line": 1,
                        "end_line": 122,
                        "max_line": 762,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__0.12",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the definition of _STANDARD_CALENDARS and the function _is_standard_calendar which is directly related to the issue of recognizing 'Gregorian' as a standard calendar."
                },
                {
                    "chunk": {
                        "code": "def decode_cf_datetime(\n    num_dates, units: str, calendar: str | None = None, use_cftime: bool | None = None\n) -> np.ndarray:\n    \"\"\"Given an array of numeric dates in netCDF format, convert it into a\n    numpy array of date time objects.\n\n    For standard (Gregorian) calendars, this function uses vectorized\n    operations, which makes it much faster than cftime.num2date. In such a\n    case, the returned array will be of type np.datetime64.\n\n    Note that time unit in `units` must not be smaller than microseconds and\n    not larger than days.\n\n    See Also\n    --------\n    cftime.num2date\n    \"\"\"\n    num_dates = np.asarray(num_dates)\n    flat_num_dates = num_dates.ravel()\n    if calendar is None:\n        calendar = \"standard\"\n\n    if use_cftime is None:\n        try:\n            dates = _decode_datetime_with_pandas(flat_num_dates, units, calendar)\n        except (KeyError, OutOfBoundsDatetime, OutOfBoundsTimedelta, OverflowError):\n            dates = _decode_datetime_with_cftime(\n                flat_num_dates.astype(float), units, calendar\n            )\n\n            if (\n                dates[np.nanargmin(num_dates)].year < 1678\n                or dates[np.nanargmax(num_dates)].year >= 2262\n            ):\n                if _is_standard_calendar(calendar):\n                    warnings.warn(\n                        \"Unable to decode time axis into full \"\n                        \"numpy.datetime64 objects, continuing using \"\n                        \"cftime.datetime objects instead, reason: dates out \"\n                        \"of range\",\n                        SerializationWarning,\n                        stacklevel=3,\n                    )\n            else:\n                if _is_standard_calendar(calendar):\n                    dates = cftime_to_nptime(dates)\n    elif use_cftime:\n        dates = _decode_datetime_with_cftime(flat_num_dates, units, calendar)\n    else:\n        dates = _decode_datetime_with_pandas(flat_num_dates, units, calendar)\n\n    return dates.reshape(num_dates.shape)\n\n\ndef to_timedelta_unboxed(value, **kwargs):\n    result = pd.to_timedelta(value, **kwargs).to_numpy()\n    assert result.dtype == \"timedelta64[ns]\"\n    return result\n\n\ndef to_datetime_unboxed(value, **kwargs):\n    result = pd.to_datetime(value, **kwargs).to_numpy()\n    assert result.dtype == \"datetime64[ns]\"\n    return result\n\n\ndef decode_cf_timedelta(num_timedeltas, units: str) -> np.ndarray:\n    \"\"\"Given an array of numeric timedeltas in netCDF format, convert it into a\n    numpy timedelta64[ns] array.\n    \"\"\"\n    num_timedeltas = np.asarray(num_timedeltas)\n    units = _netcdf_to_numpy_timeunit(units)\n    result = to_timedelta_unboxed(num_timedeltas.ravel(), unit=units)\n    return result.reshape(num_timedeltas.shape)\n\n\ndef _unit_timedelta_cftime(units: str) -> timedelta:\n    return timedelta(microseconds=_US_PER_TIME_DELTA[units])",
                        "filename": "xarray/coding/times.py",
                        "start_index": 8857,
                        "end_index": 11720,
                        "start_line": 265,
                        "end_line": 342,
                        "max_line": 762,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__0.12",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the decode_cf_datetime function which is responsible for decoding time units and may need to be modified to handle the 'Gregorian' calendar attribute correctly."
                },
                {
                    "chunk": {
                        "code": "def _unit_timedelta_numpy(units: str) -> np.timedelta64:\n    numpy_units = _netcdf_to_numpy_timeunit(units)\n    return np.timedelta64(_NS_PER_TIME_DELTA[numpy_units], \"ns\")\n\n\ndef _infer_time_units_from_diff(unique_timedeltas) -> str:\n    unit_timedelta: Callable[[str], timedelta] | Callable[[str], np.timedelta64]\n    zero_timedelta: timedelta | np.timedelta64\n    if unique_timedeltas.dtype == np.dtype(\"O\"):\n        time_units = _NETCDF_TIME_UNITS_CFTIME\n        unit_timedelta = _unit_timedelta_cftime\n        zero_timedelta = timedelta(microseconds=0)\n    else:\n        time_units = _NETCDF_TIME_UNITS_NUMPY\n        unit_timedelta = _unit_timedelta_numpy\n        zero_timedelta = np.timedelta64(0, \"ns\")\n    for time_unit in time_units:\n        if np.all(unique_timedeltas % unit_timedelta(time_unit) == zero_timedelta):\n            return time_unit\n    return \"seconds\"\n\n\ndef infer_calendar_name(dates) -> CFCalendar:\n    \"\"\"Given an array of datetimes, infer the CF calendar name\"\"\"\n    if is_np_datetime_like(dates.dtype):\n        return \"proleptic_gregorian\"\n    elif dates.dtype == np.dtype(\"O\") and dates.size > 0:\n        # Logic copied from core.common.contains_cftime_datetimes.\n        if cftime is not None:\n            sample = np.asarray(dates).flat[0]\n            if is_duck_dask_array(sample):\n                sample = sample.compute()\n                if isinstance(sample, np.ndarray):\n                    sample = sample.item()\n            if isinstance(sample, cftime.datetime):\n                return sample.calendar\n\n    # Error raise if dtype is neither datetime or \"O\", if cftime is not importable, and if element of 'O' dtype is not cftime.\n    raise ValueError(\"Array does not contain datetime objects.\")\n\n\ndef infer_datetime_units(dates) -> str:\n    \"\"\"Given an array of datetimes, returns a CF compatible time-unit string of\n    the form \"{time_unit} since {date[0]}\", where `time_unit` is 'days',\n    'hours', 'minutes' or 'seconds' (the first one that can evenly divide all\n    unique time deltas in `dates`)\n    \"\"\"\n    dates = np.asarray(dates).ravel()\n    if np.asarray(dates).dtype == \"datetime64[ns]\":\n        dates = to_datetime_unboxed(dates)\n        dates = dates[pd.notnull(dates)]\n        reference_date = dates[0] if len(dates) > 0 else \"1970-01-01\"\n        # TODO: the strict enforcement of nanosecond precision Timestamps can be\n        # relaxed when addressing GitHub issue #7493.\n        reference_date = nanosecond_precision_timestamp(reference_date)\n    else:\n        reference_date = dates[0] if len(dates) > 0 else \"1970-01-01\"\n        reference_date = format_cftime_datetime(reference_date)\n    unique_timedeltas = np.unique(np.diff(dates))\n    units = _infer_time_units_from_diff(unique_timedeltas)\n    return f\"{units} since {reference_date}\"",
                        "filename": "xarray/coding/times.py",
                        "start_index": 11723,
                        "end_index": 14521,
                        "start_line": 345,
                        "end_line": 405,
                        "max_line": 762,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__0.12",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet includes the infer_calendar_name function which could be relevant if the calendar inference logic needs to be updated to handle different cases of calendar attribute capitalization."
                }
            ]
        },
        "solution_task": "To address the issue where `xarray.open_dataset` is not handling the `calendar` attribute case-insensitively, leading to the `time` coordinate being represented as `cftime._cftime.DatetimeGregorian` instead of `datetime64[ns]`, the following changes should be made:\n\n- Modify the `_is_standard_calendar` function in `xarray/coding/times.py` to perform a case-insensitive comparison by converting the `calendar` string to lowercase before checking if it is in `_STANDARD_CALENDARS`.\n- Ensure that any other comparisons with calendar names in `xarray/coding/times.py` are also case-insensitive.\n\nHere is the updated `_is_standard_calendar` function:\n\n```python\ndef _is_standard_calendar(calendar: str) -> bool:\n    return calendar.lower() in {cal.lower() for cal in _STANDARD_CALENDARS}\n```\n\nMake sure to apply the `.lower()` method to the `calendar` variable in any other place where it is compared to the entries in `_STANDARD_CALENDARS` or any other set of calendar names.",
        "bouncer_response": {
            "score": 9,
            "criteria": "The RESPONSE must provide precise, actionable guidance and directly address all aspects of the described bug to facilitate its resolution.",
            "supporting_evidence": "The RESPONSE provides a clear and actionable solution to the bug described in the PROMPT by suggesting a modification to the `_is_standard_calendar` function to perform a case-insensitive comparison. This directly addresses the issue of `xarray.open_dataset` not handling the `calendar` attribute case-insensitively. The RESPONSE also advises ensuring that all other comparisons with calendar names in the code are case-insensitive, which is a comprehensive approach to the problem. Additionally, the RESPONSE provides a code snippet for the updated function, which is helpful for implementing the fix. The inclusion of specific code snippets to check in the xarray repository further adds to the utility of the RESPONSE. The only reason it does not score a 10 is that it does not explicitly mention testing the changes, which is a critical step in resolving software bugs.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711759538.740597,
        "result": "To address the issue where `xarray.open_dataset` is not handling the `calendar` attribute case-insensitively, leading to the `time` coordinate being represented as `cftime._cftime.DatetimeGregorian` instead of `datetime64[ns]`, the following changes should be made:\n\n- Modify the `_is_standard_calendar` function in `xarray/coding/times.py` to perform a case-insensitive comparison by converting the `calendar` string to lowercase before checking if it is in `_STANDARD_CALENDARS`.\n- Ensure that any other comparisons with calendar names in `xarray/coding/times.py` are also case-insensitive.\n\nHere is the updated `_is_standard_calendar` function:\n\n```python\ndef _is_standard_calendar(calendar: str) -> bool:\n    return calendar.lower() in {cal.lower() for cal in _STANDARD_CALENDARS}\n```\n\nMake sure to apply the `.lower()` method to the `calendar` variable in any other place where it is compared to the entries in `_STANDARD_CALENDARS` or any other set of calendar names.\n\n### Code snippets to check\n\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [coding](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/coding)- [Lines 1 - 122](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/coding/times.py#L1-L122)\n\n This snippet contains the definition of _STANDARD_CALENDARS and the function _is_standard_calendar which is directly related to the issue of recognizing 'Gregorian' as a standard calendar. \n\n\n   - [Lines 265 - 342](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/coding/times.py#L265-L342)\n\n This snippet contains the decode_cf_datetime function which is responsible for decoding time units and may need to be modified to handle the 'Gregorian' calendar attribute correctly. \n\n\n   - [Lines 345 - 405](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/coding/times.py#L345-L405)\n\n This snippet includes the infer_calendar_name function which could be relevant if the calendar inference logic needs to be updated to handle different cases of calendar attribute capitalization.",
        "context_relevance": 0.39,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers it completely.\nSupporting Evidence: The RESPONSE provides a detailed explanation of the issue with `xarray.open_dataset` handling the `calendar` attribute case-insensitively, which is the core of the PROMPT. It then offers a specific solution to the problem, including code modifications, which directly addresses the user's concern. The RESPONSE also includes additional steps to ensure that the solution is comprehensive, which is exactly what the PROMPT is seeking. The RESPONSE is entirely relevant and provides a complete answer to the PROMPT."
        },
        "qa_relevance": 1.0
    }
}