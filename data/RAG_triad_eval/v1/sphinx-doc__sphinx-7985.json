{
    "id": "sphinx-doc__sphinx-7985",
    "repo_name": "testbed/sphinx-doc__sphinx__3.2",
    "task_id": 503630442455017416,
    "title": "linkcheck could also check local (internal) links",
    "body": "Subject: linkcheck currently doesn't check local (internal) links, but this would be useful.\r\n\r\n<!--\r\n  Important: This is a list of issues for Sphinx, not a forum.\r\n  If you'd like to post a question, please move to sphinx-users group.\r\n  https://groups.google.com/forum/#!forum/sphinx-users\r\n\r\n  Thanks,\r\n-->\r\n\r\n### Problem\r\nSee above.\r\n\r\n#### Procedure to reproduce the problem\r\nCreate a template project with sphinx-quickstart, put the following in index.rst\r\n```\r\nbroken external-link_\r\nbroken local-link_\r\n\r\n.. _external-link: https://lkfqhlkghflkhs\r\n.. _local-link: doesntexist\r\n```\r\n\r\nRun `make linkcheck`\r\n\r\n#### Error logs / results\r\n```\r\nRunning Sphinx v1.7.6\r\nmaking output directory...\r\nloading pickled environment... done\r\nbuilding [mo]: targets for 0 po files that are out of date\r\nbuilding [linkcheck]: targets for 1 source files that are out of date\r\nupdating environment: 0 added, 0 changed, 0 removed\r\nlooking for now-outdated files... none found\r\npreparing documents... done\r\nwriting output... [100%] index                                                                   \r\n(line   14) -local-   doesntexist\r\n(line   14) broken    https://lkfqhlkghflkhs - HTTPSConnectionPool(host='lkfqhlkghflkhs', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7faed7ddfc88>: Failed to establish a new connection: [Errno -2] Name or service not known',))\r\n\r\nbuild finished with problems.\r\nmake: *** [Makefile:20: linkcheck] Error 1\r\n```\r\n\r\n#### Expected results\r\nAlso a check for the local link.\r\n\r\n### Reproducible project / your project\r\nN/A\r\n\r\n### Environment info\r\n- OS: Arch Linux\r\n- Python version: 3.6\r\n- Sphinx version: 1.7.6\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/sphinx-doc__sphinx__3.2.git",
    "requested_commit": "",
    "mayil_response": "- Add a new function `check_local_link` to handle the checking of local links.\n- Modify the `check` function to call `check_local_link` when a local link is detected.\n- Ensure that `check_local_link` verifies the existence of the local file or directory referenced by the link.\n- Update the `process_result` function to handle the status returned by `check_local_link`.\n- Add unit tests for the new `check_local_link` function to ensure it correctly identifies valid and invalid local links.\n\n### Code snippets to check\n\n-  \u2192 [sphinx](https://github.com/testbed/sphinx-doc__sphinx__3.2/tree//sphinx) \u2192 [builders](https://github.com/testbed/sphinx-doc__sphinx__3.2/tree//sphinx/builders)- [Lines 382 - 452](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L382-L452)\n\n This snippet contains the logic for checking URIs and determining if they are broken or working. It includes a condition for local URIs, which is directly related to the issue of checking local (internal) links. \n\n\n   - [Lines 122 - 176](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L122-L176)\n\n This snippet processes the results of the link checks and logs the status of each link. It handles different statuses including 'local', which is relevant to the issue of checking internal links. \n\n\n   - [Lines 1 - 120](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L1-L120)\n\n This snippet is part of the initialization of the linkcheck builder and sets the context for the issue, although it does not contain the logic for checking local links directly. \n\n\n   - [Lines 562 - 592](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L562-L592)\n\n This snippet sets up the linkcheck builder and its configuration values. It may need to be reviewed to ensure that the configuration supports checking local links.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0015914999999999998,
        "snippet_processor": 0.06452000000000001,
        "issue_star_creation": 0.05056,
        "issue_star_solver": 0.08367,
        "bouncer": 0.050420000000000006
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711703739.7826,
        "relevant_snippets": [
            {
                "code": "\"\"\"\n    Checks for broken external links.\n    \"\"\"\n    name = 'linkcheck'\n    epilog = __('Look for any errors in the above output or in '\n                '%(outdir)s/output.txt')\n\n    def init(self) -> None:\n        self.broken_hyperlinks = 0\n        self.hyperlinks: dict[str, Hyperlink] = {}\n        # set a timeout for non-responding servers\n        socket.setdefaulttimeout(5.0)",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 3091,
                "end_index": 3473,
                "start_line": 1,
                "end_line": 120,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.7
            },
            {
                "code": "def setup(app: Sphinx) -> dict[str, Any]:\n    app.add_builder(CheckExternalLinksBuilder)\n    app.add_post_transform(HyperlinkCollector)\n\n    app.add_config_value('linkcheck_ignore', [], False)\n    app.add_config_value('linkcheck_exclude_documents', [], False)\n    app.add_config_value('linkcheck_allowed_redirects', {}, False)\n    app.add_config_value('linkcheck_auth', [], False)\n    app.add_config_value('linkcheck_request_headers', {}, False)\n    app.add_config_value('linkcheck_retries', 1, False)\n    app.add_config_value('linkcheck_timeout', None, False, [int, float])\n    app.add_config_value('linkcheck_workers', 5, False)\n    app.add_config_value('linkcheck_anchors', True, False)\n    # Anchors starting with ! are ignored since they are\n    # commonly used for dynamic pages\n    app.add_config_value('linkcheck_anchors_ignore', [\"^!\"], False)\n    app.add_config_value('linkcheck_rate_limit_timeout', 300.0, False)\n\n    app.add_event('linkcheck-process-uri')\n\n    app.connect('config-inited', compile_linkcheck_allowed_redirects, priority=800)\n\n    # FIXME: Disable URL rewrite handler for github.com temporarily.\n    # ref: https://github.com/sphinx-doc/sphinx/issues/9435\n    # app.connect('linkcheck-process-uri', rewrite_github_anchor)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 21954,
                "end_index": 23325,
                "start_line": 562,
                "end_line": 592,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def allowed_redirect(url: str, new_url: str) -> bool:\n            return any(\n                from_url.match(url) and to_url.match(new_url)\n                for from_url, to_url\n                in self.config.linkcheck_allowed_redirects.items()\n            )\n\n        def check(docname: str) -> tuple[str, str, int]:\n            # check for various conditions without bothering the network\n\n            for doc_matcher in self.documents_exclude:\n                if doc_matcher.match(docname):\n                    info = (\n                        f'{docname} matched {doc_matcher.pattern} from '\n                        'linkcheck_exclude_documents'\n                    )\n                    return 'ignored', info, 0\n\n            if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'tel:')):\n                return 'unchecked', '', 0\n            elif not uri.startswith(('http:', 'https:')):\n                if uri_re.match(uri):\n                    # non supported URI schemes (ex. ftp)\n                    return 'unchecked', '', 0\n                else:\n                    srcdir = path.dirname(self.env.doc2path(docname))\n                    if path.exists(path.join(srcdir, uri)):\n                        return 'working', '', 0\n                    else:\n                        return 'broken', '', 0\n\n            # need to actually check the URI\n            for _ in range(self.config.linkcheck_retries):\n                status, info, code = check_uri()\n                if status != \"broken\":\n                    break\n\n            return (status, info, code)\n\n        while True:\n            check_request = self.wqueue.get()\n            next_check, hyperlink = check_request\n            if hyperlink is None:\n                break\n\n            uri, docname, lineno = hyperlink\n\n            if uri is None:\n                break\n            netloc = urlparse(uri).netloc\n            try:\n                # Refresh rate limit.\n                # When there are many links in the queue, workers are all stuck waiting\n                # for responses, but the builder keeps queuing. Links in the queue may\n                # have been queued before rate limits were discovered.\n                next_check = self.rate_limits[netloc].next_check\n            except KeyError:\n                pass\n            if next_check > time.time():\n                # Sleep before putting message back in the queue to avoid\n                # waking up other threads.\n                time.sleep(QUEUE_POLL_SECS)\n                self.wqueue.put(CheckRequest(next_check, hyperlink), False)\n                self.wqueue.task_done()\n                continue\n            status, info, code = check(docname)\n            if status == 'rate-limited':\n                logger.info(darkgray('-rate limited-   ') + uri + darkgray(' | sleeping...'))\n            else:\n                self.rqueue.put(CheckResult(uri, docname, lineno, status, info, code))\n            self.wqueue.task_done()",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 14844,
                "end_index": 17804,
                "start_line": 382,
                "end_line": 452,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.7
            },
            {
                "code": "class CheckExternalLinksBuilder(DummyBuilder):",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 3040,
                "end_index": 3086,
                "start_line": 108,
                "end_line": 108,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def process_result(self, result: CheckResult) -> None:\n        filename = self.env.doc2path(result.docname, False)\n\n        linkstat = {\"filename\": filename, \"lineno\": result.lineno,\n                    \"status\": result.status, \"code\": result.code, \"uri\": result.uri,\n                    \"info\": result.message}\n        self.write_linkstat(linkstat)\n\n        if result.status == 'unchecked':\n            return\n        if result.status == 'working' and result.message == 'old':\n            return\n        if result.lineno:\n            logger.info('(%16s: line %4d) ', result.docname, result.lineno, nonl=True)\n        if result.status == 'ignored':\n            if result.message:\n                logger.info(darkgray('-ignored- ') + result.uri + ': ' + result.message)\n            else:\n                logger.info(darkgray('-ignored- ') + result.uri)\n        elif result.status == 'local':\n            logger.info(darkgray('-local-   ') + result.uri)\n            self.write_entry('local', result.docname, filename, result.lineno, result.uri)\n        elif result.status == 'working':\n            logger.info(darkgreen('ok        ') + result.uri + result.message)\n        elif result.status == 'broken':\n            if self.app.quiet or self.app.warningiserror:\n                logger.warning(__('broken link: %s (%s)'), result.uri, result.message,\n                               location=(result.docname, result.lineno))\n            else:\n                logger.info(red('broken    ') + result.uri + red(' - ' + result.message))\n            self.write_entry('broken', result.docname, filename, result.lineno,\n                             result.uri + ': ' + result.message)\n            self.broken_hyperlinks += 1\n        elif result.status == 'redirected':\n            try:\n                text, color = {\n                    301: ('permanently', purple),\n                    302: ('with Found', purple),\n                    303: ('with See Other', purple),\n                    307: ('temporarily', turquoise),\n                    308: ('permanently', purple),\n                }[result.code]\n            except KeyError:\n                text, color = ('with unknown code', purple)\n            linkstat['text'] = text\n            if self.config.linkcheck_allowed_redirects:\n                logger.warning('redirect  ' + result.uri + ' - ' + text + ' to ' +\n                               result.message, location=(result.docname, result.lineno))\n            else:\n                logger.info(color('redirect  ') + result.uri +\n                            color(' - ' + text + ' to ' + result.message))\n            self.write_entry('redirected ' + text, result.docname, filename,\n                             result.lineno, result.uri + ' to ' + result.message)\n        else:\n            raise ValueError(\"Unknown status %s.\" % result.status)",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 3479,
                "end_index": 6320,
                "start_line": 122,
                "end_line": 176,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "class HyperlinkCollector(SphinxPostTransform):\n    builders = ('linkcheck',)\n    default_priority = 800\n\n    def run(self, **kwargs: Any) -> None:\n        builder = cast(CheckExternalLinksBuilder, self.app.builder)\n        hyperlinks = builder.hyperlinks\n\n        def add_uri(uri: str, node: nodes.Element) -> None:\n            newuri = self.app.emit_firstresult('linkcheck-process-uri', uri)\n            if newuri:\n                uri = newuri\n\n            try:\n                lineno = get_node_line(node)\n            except ValueError:\n                lineno = None\n            uri_info = Hyperlink(uri, self.env.docname, lineno)\n            if uri not in hyperlinks:\n                hyperlinks[uri] = uri_info\n\n        # reference nodes\n        for refnode in self.document.findall(nodes.reference):\n            if 'refuri' not in refnode:\n                continue\n            uri = refnode['refuri']\n            add_uri(uri, refnode)\n\n        # image nodes\n        for imgnode in self.document.findall(nodes.image):\n            uri = imgnode['candidates'].get('?')\n            if uri and '://' in uri:\n                add_uri(uri, imgnode)\n\n        # raw nodes\n        for rawnode in self.document.findall(nodes.raw):\n            uri = rawnode.get('source')\n            if uri and '://' in uri:\n                add_uri(uri, rawnode)\n\n\ndef rewrite_github_anchor(app: Sphinx, uri: str) -> str | None:\n    \"\"\"Rewrite anchor name of the hyperlink to github.com\n\n    The hyperlink anchors in github.com are dynamically generated.  This rewrites\n    them before checking and makes them comparable.\n    \"\"\"\n    parsed = urlparse(uri)\n    if parsed.hostname == \"github.com\" and parsed.fragment:\n        prefixed = parsed.fragment.startswith('user-content-')\n        if not prefixed:\n            fragment = f'user-content-{parsed.fragment}'\n            return urlunparse(parsed._replace(fragment=fragment))\n    return None\n\n\ndef compile_linkcheck_allowed_redirects(app: Sphinx, config: Config) -> None:\n    \"\"\"Compile patterns in linkcheck_allowed_redirects to the regexp objects.\"\"\"\n    for url, pattern in list(app.config.linkcheck_allowed_redirects.items()):\n        try:\n            app.config.linkcheck_allowed_redirects[re.compile(url)] = re.compile(pattern)\n        except re.error as exc:\n            logger.warning(__('Failed to compile regex in linkcheck_allowed_redirects: %r %s'),\n                           exc.pattern, exc.msg)\n        finally:\n            # Remove the original regexp-string\n            app.config.linkcheck_allowed_redirects.pop(url)",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 19389,
                "end_index": 21951,
                "start_line": 493,
                "end_line": 559,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"Extension to save typing and prevent hard-coding of base URLs in reST files.\n\nThis adds a new config value called ``extlinks`` that is created like this::\n\n   extlinks = {'exmpl': ('https://example.invalid/%s.html', caption), ...}\n\nNow you can use e.g. :exmpl:`foo` in your documents.  This will create a\nlink to ``https://example.invalid/foo.html``.  The link caption depends on\nthe *caption* value given:\n\n- If it is ``None``, the caption will be the full URL.\n- If it is a string, it must contain ``%s`` exactly once.  In this case the\n  caption will be *caption* with the role content substituted for ``%s``.\n\nYou can also give an explicit caption, e.g. :exmpl:`Foo <foo>`.\n\nBoth, the url string and the caption string must escape ``%`` as ``%%``.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nfrom typing import Any\n\nfrom docutils import nodes, utils\nfrom docutils.nodes import Node, system_message\nfrom docutils.parsers.rst.states import Inliner\n\nimport sphinx\nfrom sphinx.application import Sphinx\nfrom sphinx.locale import __\nfrom sphinx.transforms.post_transforms import SphinxPostTransform\nfrom sphinx.util import logging, rst\nfrom sphinx.util.nodes import split_explicit_title\nfrom sphinx.util.typing import RoleFunction\n\nlogger = logging.getLogger(__name__)\n\n\nclass ExternalLinksChecker(SphinxPostTransform):\n    \"\"\"\n    For each external link, check if it can be replaced by an extlink.\n\n    We treat each ``reference`` node without ``internal`` attribute as an external link.\n    \"\"\"\n\n    default_priority = 500\n\n    def run(self, **kwargs: Any) -> None:\n        if not self.config.extlinks_detect_hardcoded_links:\n            return\n\n        for refnode in self.document.findall(nodes.reference):\n            self.check_uri(refnode)\n\n    def check_uri(self, refnode: nodes.reference) -> None:\n        \"\"\"\n        If the URI in ``refnode`` has a replacement in ``extlinks``,\n        emit a warning with a replacement suggestion.\n        \"\"\"\n        if 'internal' in refnode or 'refuri' not in refnode:\n            return\n\n        uri = refnode['refuri']\n        title = refnode.astext()\n\n        for alias, (base_uri, _caption) in self.app.config.extlinks.items():\n            uri_pattern = re.compile(re.escape(base_uri).replace('%s', '(?P<value>.+)'))\n\n            match = uri_pattern.match(uri)\n            if (\n                match and\n                match.groupdict().get('value') and\n                '/' not in match.groupdict()['value']\n            ):\n                # build a replacement suggestion\n                msg = __('hardcoded link %r could be replaced by an extlink '\n                         '(try using %r instead)')\n                value = match.groupdict().get('value')\n                if uri != title:\n                    replacement = f\":{alias}:`{rst.escape(title)} <{value}>`\"\n                else:\n                    replacement = f\":{alias}:`{value}`\"\n                logger.warning(msg, uri, replacement, location=refnode)",
                "filename": "sphinx/ext/extlinks.py",
                "start_index": 0,
                "end_index": 2976,
                "start_line": 1,
                "end_line": 84,
                "max_line": 120,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"The CheckExternalLinksBuilder class.\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport re\nimport socket\nimport time\nfrom copy import deepcopy\nfrom datetime import datetime, timezone\nfrom email.utils import parsedate_to_datetime\nfrom html.parser import HTMLParser\nfrom os import path\nfrom queue import PriorityQueue, Queue\nfrom threading import Thread\nfrom typing import Any, Generator, NamedTuple, Tuple, Union, cast\nfrom urllib.parse import unquote, urlparse, urlunparse\n\nfrom docutils import nodes\nfrom requests import Response\nfrom requests.exceptions import ConnectionError, HTTPError, TooManyRedirects\n\nfrom sphinx.application import Sphinx\nfrom sphinx.builders.dummy import DummyBuilder\nfrom sphinx.config import Config\nfrom sphinx.environment import BuildEnvironment\nfrom sphinx.locale import __\nfrom sphinx.transforms.post_transforms import SphinxPostTransform\nfrom sphinx.util import encode_uri, logging, requests\nfrom sphinx.util.console import darkgray, darkgreen, purple, red, turquoise  # type: ignore\nfrom sphinx.util.nodes import get_node_line\n\nlogger = logging.getLogger(__name__)\n\nuri_re = re.compile('([a-z]+:)?//')  # matches to foo:// and // (a protocol relative URL)\n\n\nclass Hyperlink(NamedTuple):\n    uri: str\n    docname: str\n    lineno: int | None\n\n\nclass CheckRequest(NamedTuple):\n    next_check: float\n    hyperlink: Hyperlink | None\n\n\nclass CheckResult(NamedTuple):\n    uri: str\n    docname: str\n    lineno: int\n    status: str\n    message: str\n    code: int\n\n\nclass RateLimit(NamedTuple):\n    delay: float\n    next_check: float\n\n\n# Tuple is old styled CheckRequest\nCheckRequestType = Union[CheckRequest, Tuple[float, str, str, int]]\n\nDEFAULT_REQUEST_HEADERS = {\n    'Accept': 'text/html,application/xhtml+xml;q=0.9,*/*;q=0.8',\n}\nCHECK_IMMEDIATELY = 0\nQUEUE_POLL_SECS = 1\nDEFAULT_DELAY = 60.0\n\n\nclass AnchorCheckParser(HTMLParser):\n    \"\"\"Specialized HTML parser that looks for a specific anchor.\"\"\"\n\n    def __init__(self, search_anchor: str) -> None:\n        super().__init__()\n\n        self.search_anchor = search_anchor\n        self.found = False\n\n    def handle_starttag(self, tag: Any, attrs: Any) -> None:\n        for key, value in attrs:\n            if key in ('id', 'name') and value == self.search_anchor:\n                self.found = True\n                break",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 0,
                "end_index": 2310,
                "start_line": 1,
                "end_line": 430,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"Insert links to objects documented in remote Sphinx documentation.\n\nThis works as follows:\n\n* Each Sphinx HTML build creates a file named \"objects.inv\" that contains a\n  mapping from object names to URIs relative to the HTML set's root.\n\n* Projects using the Intersphinx extension can specify links to such mapping\n  files in the `intersphinx_mapping` config value.  The mapping will then be\n  used to resolve otherwise missing references to objects into links to the\n  other documentation.\n\n* By default, the mapping file is assumed to be at the same location as the\n  rest of the documentation; however, the location of the mapping file can\n  also be specified individually, e.g. if the docs should be buildable\n  without Internet access.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport concurrent.futures\nimport functools\nimport posixpath\nimport re\nimport sys\nimport time\nfrom os import path\nfrom typing import IO, TYPE_CHECKING, Any, cast\nfrom urllib.parse import urlsplit, urlunsplit\n\nfrom docutils import nodes\nfrom docutils.utils import relative_path\n\nimport sphinx\nfrom sphinx.addnodes import pending_xref\nfrom sphinx.builders.html import INVENTORY_FILENAME\nfrom sphinx.errors import ExtensionError\nfrom sphinx.locale import _, __\nfrom sphinx.transforms.post_transforms import ReferencesResolver\nfrom sphinx.util import logging, requests\nfrom sphinx.util.docutils import CustomReSTDispatcher, SphinxRole\nfrom sphinx.util.inventory import InventoryFile\n\nif TYPE_CHECKING:\n    from types import ModuleType\n    from typing import Tuple, Union\n\n    from docutils.nodes import Node, TextElement, system_message\n    from docutils.utils import Reporter\n\n    from sphinx.application import Sphinx\n    from sphinx.config import Config\n    from sphinx.domains import Domain\n    from sphinx.environment import BuildEnvironment\n    from sphinx.util.typing import Inventory, InventoryItem, RoleFunction\n\n    InventoryCacheEntry = Tuple[Union[str, None], int, Inventory]\n\nlogger = logging.getLogger(__name__)",
                "filename": "sphinx/ext/intersphinx.py",
                "start_index": 0,
                "end_index": 2005,
                "start_line": 1,
                "end_line": 59,
                "max_line": 725,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "try:\n                if anchor and self.config.linkcheck_anchors:\n                    # Read the whole document and see if #anchor exists\n                    with requests.get(req_url, stream=True, config=self.config, auth=auth_info,\n                                      **kwargs) as response:\n                        response.raise_for_status()\n                        found = check_anchor(response, unquote(anchor))\n\n                    if not found:\n                        raise Exception(__(\"Anchor '%s' not found\") % anchor)\n                else:\n                    try:\n                        # try a HEAD request first, which should be easier on\n                        # the server and the network\n                        with requests.head(req_url, allow_redirects=True, config=self.config,\n                                           auth=auth_info, **kwargs) as response:\n                            response.raise_for_status()\n                    # Servers drop the connection on HEAD requests, causing\n                    # ConnectionError.\n                    except (ConnectionError, HTTPError, TooManyRedirects) as err:\n                        if isinstance(err, HTTPError) and err.response.status_code == 429:\n                            raise\n                        # retry with GET request if that fails, some servers\n                        # don't like HEAD requests.\n                        with requests.get(req_url, stream=True, config=self.config,\n                                          auth=auth_info, **kwargs) as response:\n                            response.raise_for_status()\n            except HTTPError as err:\n                if err.response.status_code == 401:\n                    # We'll take \"Unauthorized\" as working.\n                    return 'working', ' - unauthorized', 0\n                elif err.response.status_code == 429:\n                    next_check = self.limit_rate(err.response)\n                    if next_check is not None:\n                        self.wqueue.put(CheckRequest(next_check, hyperlink), False)\n                        return 'rate-limited', '', 0\n                    return 'broken', str(err), 0\n                elif err.response.status_code == 503:\n                    # We'll take \"Service Unavailable\" as ignored.\n                    return 'ignored', str(err), 0\n                else:\n                    return 'broken', str(err), 0\n            except Exception as err:\n                return 'broken', str(err), 0\n            else:\n                netloc = urlparse(req_url).netloc\n                try:\n                    del self.rate_limits[netloc]\n                except KeyError:\n                    pass",
                "filename": "sphinx/builders/linkcheck.py",
                "start_index": 11520,
                "end_index": 14211,
                "start_line": 156,
                "end_line": 468,
                "max_line": 592,
                "git_instance": "github",
                "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                "sha": "",
                "context_relevance": 0.2
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sphinx/builders/linkcheck.py": [
                {
                    "chunk": {
                        "code": "def allowed_redirect(url: str, new_url: str) -> bool:\n            return any(\n                from_url.match(url) and to_url.match(new_url)\n                for from_url, to_url\n                in self.config.linkcheck_allowed_redirects.items()\n            )\n\n        def check(docname: str) -> tuple[str, str, int]:\n            # check for various conditions without bothering the network\n\n            for doc_matcher in self.documents_exclude:\n                if doc_matcher.match(docname):\n                    info = (\n                        f'{docname} matched {doc_matcher.pattern} from '\n                        'linkcheck_exclude_documents'\n                    )\n                    return 'ignored', info, 0\n\n            if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'tel:')):\n                return 'unchecked', '', 0\n            elif not uri.startswith(('http:', 'https:')):\n                if uri_re.match(uri):\n                    # non supported URI schemes (ex. ftp)\n                    return 'unchecked', '', 0\n                else:\n                    srcdir = path.dirname(self.env.doc2path(docname))\n                    if path.exists(path.join(srcdir, uri)):\n                        return 'working', '', 0\n                    else:\n                        return 'broken', '', 0\n\n            # need to actually check the URI\n            for _ in range(self.config.linkcheck_retries):\n                status, info, code = check_uri()\n                if status != \"broken\":\n                    break\n\n            return (status, info, code)\n\n        while True:\n            check_request = self.wqueue.get()\n            next_check, hyperlink = check_request\n            if hyperlink is None:\n                break\n\n            uri, docname, lineno = hyperlink\n\n            if uri is None:\n                break\n            netloc = urlparse(uri).netloc\n            try:\n                # Refresh rate limit.\n                # When there are many links in the queue, workers are all stuck waiting\n                # for responses, but the builder keeps queuing. Links in the queue may\n                # have been queued before rate limits were discovered.\n                next_check = self.rate_limits[netloc].next_check\n            except KeyError:\n                pass\n            if next_check > time.time():\n                # Sleep before putting message back in the queue to avoid\n                # waking up other threads.\n                time.sleep(QUEUE_POLL_SECS)\n                self.wqueue.put(CheckRequest(next_check, hyperlink), False)\n                self.wqueue.task_done()\n                continue\n            status, info, code = check(docname)\n            if status == 'rate-limited':\n                logger.info(darkgray('-rate limited-   ') + uri + darkgray(' | sleeping...'))\n            else:\n                self.rqueue.put(CheckResult(uri, docname, lineno, status, info, code))\n            self.wqueue.task_done()",
                        "filename": "sphinx/builders/linkcheck.py",
                        "start_index": 14844,
                        "end_index": 17804,
                        "start_line": 382,
                        "end_line": 452,
                        "max_line": 592,
                        "git_instance": "github",
                        "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the logic for checking URIs and determining if they are broken or working. It includes a condition for local URIs, which is directly related to the issue of checking local (internal) links."
                },
                {
                    "chunk": {
                        "code": "def process_result(self, result: CheckResult) -> None:\n        filename = self.env.doc2path(result.docname, False)\n\n        linkstat = {\"filename\": filename, \"lineno\": result.lineno,\n                    \"status\": result.status, \"code\": result.code, \"uri\": result.uri,\n                    \"info\": result.message}\n        self.write_linkstat(linkstat)\n\n        if result.status == 'unchecked':\n            return\n        if result.status == 'working' and result.message == 'old':\n            return\n        if result.lineno:\n            logger.info('(%16s: line %4d) ', result.docname, result.lineno, nonl=True)\n        if result.status == 'ignored':\n            if result.message:\n                logger.info(darkgray('-ignored- ') + result.uri + ': ' + result.message)\n            else:\n                logger.info(darkgray('-ignored- ') + result.uri)\n        elif result.status == 'local':\n            logger.info(darkgray('-local-   ') + result.uri)\n            self.write_entry('local', result.docname, filename, result.lineno, result.uri)\n        elif result.status == 'working':\n            logger.info(darkgreen('ok        ') + result.uri + result.message)\n        elif result.status == 'broken':\n            if self.app.quiet or self.app.warningiserror:\n                logger.warning(__('broken link: %s (%s)'), result.uri, result.message,\n                               location=(result.docname, result.lineno))\n            else:\n                logger.info(red('broken    ') + result.uri + red(' - ' + result.message))\n            self.write_entry('broken', result.docname, filename, result.lineno,\n                             result.uri + ': ' + result.message)\n            self.broken_hyperlinks += 1\n        elif result.status == 'redirected':\n            try:\n                text, color = {\n                    301: ('permanently', purple),\n                    302: ('with Found', purple),\n                    303: ('with See Other', purple),\n                    307: ('temporarily', turquoise),\n                    308: ('permanently', purple),\n                }[result.code]\n            except KeyError:\n                text, color = ('with unknown code', purple)\n            linkstat['text'] = text\n            if self.config.linkcheck_allowed_redirects:\n                logger.warning('redirect  ' + result.uri + ' - ' + text + ' to ' +\n                               result.message, location=(result.docname, result.lineno))\n            else:\n                logger.info(color('redirect  ') + result.uri +\n                            color(' - ' + text + ' to ' + result.message))\n            self.write_entry('redirected ' + text, result.docname, filename,\n                             result.lineno, result.uri + ' to ' + result.message)\n        else:\n            raise ValueError(\"Unknown status %s.\" % result.status)",
                        "filename": "sphinx/builders/linkcheck.py",
                        "start_index": 3479,
                        "end_index": 6320,
                        "start_line": 122,
                        "end_line": 176,
                        "max_line": 592,
                        "git_instance": "github",
                        "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet processes the results of the link checks and logs the status of each link. It handles different statuses including 'local', which is relevant to the issue of checking internal links."
                },
                {
                    "chunk": {
                        "code": "\"\"\"\n    Checks for broken external links.\n    \"\"\"\n    name = 'linkcheck'\n    epilog = __('Look for any errors in the above output or in '\n                '%(outdir)s/output.txt')\n\n    def init(self) -> None:\n        self.broken_hyperlinks = 0\n        self.hyperlinks: dict[str, Hyperlink] = {}\n        # set a timeout for non-responding servers\n        socket.setdefaulttimeout(5.0)",
                        "filename": "sphinx/builders/linkcheck.py",
                        "start_index": 3091,
                        "end_index": 3473,
                        "start_line": 1,
                        "end_line": 120,
                        "max_line": 592,
                        "git_instance": "github",
                        "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet is part of the initialization of the linkcheck builder and sets the context for the issue, although it does not contain the logic for checking local links directly."
                },
                {
                    "chunk": {
                        "code": "def setup(app: Sphinx) -> dict[str, Any]:\n    app.add_builder(CheckExternalLinksBuilder)\n    app.add_post_transform(HyperlinkCollector)\n\n    app.add_config_value('linkcheck_ignore', [], False)\n    app.add_config_value('linkcheck_exclude_documents', [], False)\n    app.add_config_value('linkcheck_allowed_redirects', {}, False)\n    app.add_config_value('linkcheck_auth', [], False)\n    app.add_config_value('linkcheck_request_headers', {}, False)\n    app.add_config_value('linkcheck_retries', 1, False)\n    app.add_config_value('linkcheck_timeout', None, False, [int, float])\n    app.add_config_value('linkcheck_workers', 5, False)\n    app.add_config_value('linkcheck_anchors', True, False)\n    # Anchors starting with ! are ignored since they are\n    # commonly used for dynamic pages\n    app.add_config_value('linkcheck_anchors_ignore', [\"^!\"], False)\n    app.add_config_value('linkcheck_rate_limit_timeout', 300.0, False)\n\n    app.add_event('linkcheck-process-uri')\n\n    app.connect('config-inited', compile_linkcheck_allowed_redirects, priority=800)\n\n    # FIXME: Disable URL rewrite handler for github.com temporarily.\n    # ref: https://github.com/sphinx-doc/sphinx/issues/9435\n    # app.connect('linkcheck-process-uri', rewrite_github_anchor)\n\n    return {\n        'version': 'builtin',\n        'parallel_read_safe': True,\n        'parallel_write_safe': True,\n    }",
                        "filename": "sphinx/builders/linkcheck.py",
                        "start_index": 21954,
                        "end_index": 23325,
                        "start_line": 562,
                        "end_line": 592,
                        "max_line": 592,
                        "git_instance": "github",
                        "repo_name": "testbed/sphinx-doc__sphinx__3.2",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet sets up the linkcheck builder and its configuration values. It may need to be reviewed to ensure that the configuration supports checking local links."
                }
            ]
        },
        "solution_task": "- Add a new function `check_local_link` to handle the checking of local links.\n- Modify the `check` function to call `check_local_link` when a local link is detected.\n- Ensure that `check_local_link` verifies the existence of the local file or directory referenced by the link.\n- Update the `process_result` function to handle the status returned by `check_local_link`.\n- Add unit tests for the new `check_local_link` function to ensure it correctly identifies valid and invalid local links.",
        "bouncer_response": {
            "score": 8,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant hints and solutions that can directly lead to resolving the issues outlined in the PROMPT.",
            "supporting_evidence": "The RESPONSE provides a clear and actionable plan to address the issue of Sphinx not checking local (internal) links. It suggests adding a new function to handle local link checking, modifying the existing check function to call this new function for local links, ensuring the new function verifies the existence of local files or directories, updating the process_result function to handle the new status, and adding unit tests for the new functionality. The RESPONSE also provides relevant code snippets from the Sphinx repository that would likely need to be modified to implement the proposed changes. This indicates a good understanding of the problem and offers a comprehensive approach to solving it.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711703832.53148,
        "result": "- Add a new function `check_local_link` to handle the checking of local links.\n- Modify the `check` function to call `check_local_link` when a local link is detected.\n- Ensure that `check_local_link` verifies the existence of the local file or directory referenced by the link.\n- Update the `process_result` function to handle the status returned by `check_local_link`.\n- Add unit tests for the new `check_local_link` function to ensure it correctly identifies valid and invalid local links.\n\n### Code snippets to check\n\n-  \u2192 [sphinx](https://github.com/testbed/sphinx-doc__sphinx__3.2/tree//sphinx) \u2192 [builders](https://github.com/testbed/sphinx-doc__sphinx__3.2/tree//sphinx/builders)- [Lines 382 - 452](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L382-L452)\n\n This snippet contains the logic for checking URIs and determining if they are broken or working. It includes a condition for local URIs, which is directly related to the issue of checking local (internal) links. \n\n\n   - [Lines 122 - 176](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L122-L176)\n\n This snippet processes the results of the link checks and logs the status of each link. It handles different statuses including 'local', which is relevant to the issue of checking internal links. \n\n\n   - [Lines 1 - 120](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L1-L120)\n\n This snippet is part of the initialization of the linkcheck builder and sets the context for the issue, although it does not contain the logic for checking local links directly. \n\n\n   - [Lines 562 - 592](https://github.com/testbed/sphinx-doc__sphinx__3.2/blob//sphinx/builders/linkcheck.py#L562-L592)\n\n This snippet sets up the linkcheck builder and its configuration values. It may need to be reviewed to ensure that the configuration supports checking local links.",
        "context_relevance": 0.38,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers the PROMPT completely.\nSupporting Evidence: The RESPONSE provides a detailed solution to the problem described in the PROMPT, which is the lack of checking for local (internal) links by the linkcheck feature in Sphinx. It outlines specific steps to add and modify functions to handle local link checking, and it also references relevant code snippets that would be involved in implementing the solution. The RESPONSE is directly addressing the issue raised in the PROMPT and provides a comprehensive answer, fulfilling the criteria for a score of 10."
        },
        "qa_relevance": 1.0
    }
}