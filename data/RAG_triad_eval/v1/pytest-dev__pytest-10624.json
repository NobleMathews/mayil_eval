{
    "id": "pytest-dev__pytest-10624",
    "repo_name": "testbed/pytest-dev__pytest__7.2",
    "task_id": 3662671559393246926,
    "title": "`assert a == approx(b)` when `b` is dict containing zero value results in ZeroDivisionError",
    "body": "Pytest behaves differently when comparing dictionaries containing zero values compared to lists containing same values\r\n\r\npytest==7.2.0\r\nUbuntu 22.04\r\n\r\n```python\r\nimport pytest\r\n\r\ndef test_foo_dict():\r\n    a = {'foo': 42.0}\r\n    b = {'foo': 0.0}\r\n    assert a == pytest.approx(b) # ZeroDivisionError in pytest/python_api.py\r\n\r\ndef test_foo_list():\r\n    a = [42.0]\r\n    b = [0.0]\r\n    assert a == pytest.approx(b) # OK\r\n```\r\n\r\n```python\r\n_____________________ test_foo_dict\r\n\r\n    def test_foo_dict():\r\n        a = {'foo': 42.0}\r\n        b = {'foo': 0.0}\r\n>       assert a == pytest.approx(b)\r\nE       AssertionError: assert {'foo': 42.0} == approx({'foo': 0.0 \u00b1 1.0e-12})\r\nE         (pytest_assertion plugin: representation of details failed: /home/arkanoid/test/venv/lib/python3.10/site-packages/_pytest/python_api.py:274: ZeroDivisionError: float division by zero.\r\nE          Probably an object has a faulty __repr__.)\r\n\r\nextra/test_pytest_issue.py:9: AssertionError\r\n\r\n_____________________ test_foo_list\r\n\r\n    def test_foo_list():\r\n        a = [42.0]\r\n        b = [0.0]\r\n>       assert a == pytest.approx(b)\r\nE       assert [42.0] == approx([0.0 \u00b1 1.0e-12])\r\nE         comparison failed. Mismatched elements: 1 / 1:\r\nE         Max absolute difference: 42.0\r\nE         Max relative difference: 1.0\r\nE         Index | Obtained | Expected     \r\nE         0     | 42.0     | 0.0 \u00b1 1.0e-12\r\n\r\nextra/test_pytest_issue.py:15: AssertionError\r\n```\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/pytest-dev__pytest__7.2.git",
    "requested_commit": "",
    "mayil_response": "- Investigate the `approx` function in the file `/home/arkanoid/test/venv/lib/python3.10/site-packages/_pytest/python_api.py` for potential division by zero when handling dictionaries with zero values.\n- Ensure that the `approx` function has a check to prevent division by zero when calculating relative tolerance for both lists and dictionaries.\n- If the `approx` function uses a formula that involves division by the expected value, add a condition to handle the case when the expected value is zero.\n- For example, if the `approx` function calculates relative tolerance as `rel_tol = rel * abs(expected)`, ensure that there is a guard clause like `if expected == 0: rel_tol = 0` before the division occurs.\n- Add tests in `extra/test_pytest_issue.py` to cover cases where `approx` is used with dictionaries and lists containing zero values to ensure the issue is resolved and does not recur.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.000239,
        "snippet_processor": 0.03833,
        "issue_star_creation": 0.025259999999999998,
        "issue_star_solver": 0.03222,
        "bouncer": 0.02645
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711733684.3555,
        "relevant_snippets": [
            {
                "code": "rtd:\n  project: pytest",
                "filename": ".github/config.yml",
                "start_index": 0,
                "end_index": 22,
                "start_line": 1,
                "end_line": 2,
                "max_line": 2,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.1
            },
            {
                "code": "import pytest\n\n\n@pytest.fixture(scope=\"module\", params=range(966))\ndef foo(request):\n    return request.param\n\n\ndef test_it(foo):\n    pass\n\n\ndef test_it2(foo):\n    pass",
                "filename": "bench/manyparam.py",
                "start_index": 0,
                "end_index": 168,
                "start_line": 1,
                "end_line": 14,
                "max_line": 14,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "blank_issues_enabled: false\ncontact_links:\n  - name: \u2753 Support Question\n    url: https://github.com/pytest-dev/pytest/discussions\n    about: Use GitHub's new Discussions feature for questions",
                "filename": ".github/ISSUE_TEMPLATE/config.yml",
                "start_index": 0,
                "end_index": 191,
                "start_line": 1,
                "end_line": 5,
                "max_line": 5,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "import json\nfrom pathlib import Path\n\nimport requests\n\nissues_url = \"https://api.github.com/repos/pytest-dev/pytest/issues\"\n\n\ndef get_issues():\n    issues = []\n    url = issues_url\n    while 1:\n        get_data = {\"state\": \"all\"}\n        r = requests.get(url, params=get_data)\n        data = r.json()\n        if r.status_code == 403:\n            # API request limit exceeded\n            print(data[\"message\"])\n            exit(1)\n        issues.extend(data)\n\n        # Look for next page\n        links = requests.utils.parse_header_links(r.headers[\"Link\"])\n        another_page = False\n        for link in links:\n            if link[\"rel\"] == \"next\":\n                url = link[\"url\"]\n                another_page = True\n        if not another_page:\n            return issues\n\n\ndef main(args):\n    cachefile = Path(args.cache)\n    if not cachefile.exists() or args.refresh:\n        issues = get_issues()\n        cachefile.write_text(json.dumps(issues), \"utf-8\")\n    else:\n        issues = json.loads(cachefile.read_text(\"utf-8\"))\n\n    open_issues = [x for x in issues if x[\"state\"] == \"open\"]\n\n    open_issues.sort(key=lambda x: x[\"number\"])\n    report(open_issues)\n\n\ndef _get_kind(issue):\n    labels = [label[\"name\"] for label in issue[\"labels\"]]\n    for key in (\"bug\", \"enhancement\", \"proposal\"):\n        if key in labels:\n            return key\n    return \"issue\"\n\n\ndef report(issues):\n    for issue in issues:\n        title = issue[\"title\"]\n        # body = issue[\"body\"]\n        kind = _get_kind(issue)\n        status = issue[\"state\"]\n        number = issue[\"number\"]\n        link = \"https://github.com/pytest-dev/pytest/issues/%s/\" % number\n        print(\"----\")\n        print(status, kind, link)\n        print(title)\n        # print()\n        # lines = body.split(\"\\n\")\n        # print(\"\\n\".join(lines[:3]))\n        # if len(lines) > 3 or len(body) > 240:\n        #    print(\"...\")\n    print(\"\\n\\nFound %s open issues\" % len(issues))\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser(\"process bitbucket issues\")\n    parser.add_argument(\n        \"--refresh\", action=\"store_true\", help=\"invalidate cache, refresh issues\"\n    )\n    parser.add_argument(\n        \"--cache\", action=\"store\", default=\"issues.json\", help=\"cache file\"\n    )\n    args = parser.parse_args()\n    main(args)",
                "filename": "extra/get_issues.py",
                "start_index": 0,
                "end_index": 2321,
                "start_line": 1,
                "end_line": 85,
                "max_line": 85,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "import pytest\n\nSKIP = True\n\n\n@pytest.mark.parametrize(\"x\", range(5000))\ndef test_foo(x):\n    if SKIP:\n        pytest.skip(\"heh\")",
                "filename": "bench/skip.py",
                "start_index": 0,
                "end_index": 128,
                "start_line": 1,
                "end_line": 9,
                "max_line": 9,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "import sys\n\nif __name__ == \"__main__\":\n    import cProfile\n    import pytest  # NOQA\n    import pstats\n\n    script = sys.argv[1:] if len(sys.argv) > 1 else [\"empty.py\"]\n    cProfile.run(\"pytest.cmdline.main(%r)\" % script, \"prof\")\n    p = pstats.Stats(\"prof\")\n    p.strip_dirs()\n    p.sort_stats(\"cumulative\")\n    print(p.print_stats(500))",
                "filename": "bench/bench.py",
                "start_index": 0,
                "end_index": 338,
                "start_line": 1,
                "end_line": 13,
                "max_line": 13,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "# shim for pylib going away\n# if pylib is installed this file will get skipped\n# (`py/__init__.py` has higher precedence)\nimport sys\n\nimport _pytest._py.error as error\nimport _pytest._py.path as path\n\nsys.modules[\"py.error\"] = error\nsys.modules[\"py.path\"] = path",
                "filename": "src/py.py",
                "start_index": 0,
                "end_index": 262,
                "start_line": 1,
                "end_line": 10,
                "max_line": 10,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "import datetime\nimport pathlib\nimport re\nfrom textwrap import dedent\nfrom textwrap import indent\n\nimport packaging.version\nimport platformdirs\nimport tabulate\nimport wcwidth\nfrom requests_cache import CachedResponse\nfrom requests_cache import CachedSession\nfrom requests_cache import OriginalResponse\nfrom requests_cache import SQLiteCache\nfrom tqdm import tqdm\n\n\nFILE_HEAD = r\"\"\"\n.. Note this file is autogenerated by scripts/update-plugin-list.py - usually weekly via github action\n\n.. _plugin-list:\n\nPlugin List\n===========\n\nPyPI projects that match \"pytest-\\*\" are considered plugins and are listed\nautomatically together with a manually-maintained list in `the source\ncode <https://github.com/pytest-dev/pytest/blob/main/scripts/update-plugin-list.py>`_.\nPackages classified as inactive are excluded.\n\n.. The following conditional uses a different format for this list when\n   creating a PDF, because otherwise the table gets far too wide for the\n   page.\n\n\"\"\"\nDEVELOPMENT_STATUS_CLASSIFIERS = (\n    \"Development Status :: 1 - Planning\",\n    \"Development Status :: 2 - Pre-Alpha\",\n    \"Development Status :: 3 - Alpha\",\n    \"Development Status :: 4 - Beta\",\n    \"Development Status :: 5 - Production/Stable\",\n    \"Development Status :: 6 - Mature\",\n    \"Development Status :: 7 - Inactive\",\n)\nADDITIONAL_PROJECTS = {  # set of additional projects to consider as plugins\n    \"logassert\",\n    \"nuts\",\n}\n\n\ndef escape_rst(text: str) -> str:\n    \"\"\"Rudimentary attempt to escape special RST characters to appear as\n    plain text.\"\"\"\n    text = (\n        text.replace(\"*\", \"\\\\*\")\n        .replace(\"<\", \"\\\\<\")\n        .replace(\">\", \"\\\\>\")\n        .replace(\"`\", \"\\\\`\")\n    )\n    text = re.sub(r\"_\\b\", \"\", text)\n    return text\n\n\ndef project_response_with_refresh(\n    session: CachedSession, name: str, last_serial: int\n) -> OriginalResponse | CachedResponse:\n    \"\"\"Get a http cached pypi project\n\n    force refresh in case of last serial mismatch\n    \"\"\"\n\n    response = session.get(f\"https://pypi.org/pypi/{name}/json\")\n    if int(response.headers.get(\"X-PyPI-Last-Serial\", -1)) != last_serial:\n        response = session.get(f\"https://pypi.org/pypi/{name}/json\", refresh=True)\n    return response\n\n\ndef get_session() -> CachedSession:\n    \"\"\"Configures the requests-cache session\"\"\"\n    cache_path = platformdirs.user_cache_path(\"pytest-plugin-list\")\n    cache_path.mkdir(exist_ok=True, parents=True)\n    cache_file = cache_path.joinpath(\"http_cache.sqlite3\")\n    return CachedSession(backend=SQLiteCache(cache_file))\n\n\ndef pytest_plugin_projects_from_pypi(session: CachedSession) -> dict[str, int]:\n    response = session.get(\n        \"https://pypi.org/simple\",\n        headers={\"Accept\": \"application/vnd.pypi.simple.v1+json\"},\n        refresh=True,\n    )\n    return {\n        name: p[\"_last-serial\"]\n        for p in response.json()[\"projects\"]\n        if (name := p[\"name\"]).startswith(\"pytest-\") or name in ADDITIONAL_PROJECTS\n    }",
                "filename": "scripts/update-plugin-list.py",
                "start_index": 0,
                "end_index": 2939,
                "start_line": 1,
                "end_line": 155,
                "max_line": 195,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "# 10000 iterations, just for relative comparison\n#                      2.7.5     3.3.2\n# FilesCompleter       75.1109   69.2116\n# FastFilesCompleter    0.7383    1.0760\nimport timeit\n\nimports = [\n    \"from argcomplete.completers import FilesCompleter as completer\",\n    \"from _pytest._argcomplete import FastFilesCompleter as completer\",\n]\n\ncount = 1000  # only a few seconds\nsetup = \"%s\\nfc = completer()\"\nrun = 'fc(\"/d\")'\n\n\nif __name__ == \"__main__\":\n    print(timeit.timeit(run, setup=setup % imports[0], number=count))\n    print(timeit.timeit(run, setup=setup % imports[1], number=count))",
                "filename": "bench/bench_argcomplete.py",
                "start_index": 0,
                "end_index": 593,
                "start_line": 1,
                "end_line": 19,
                "max_line": 19,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "# info:\n# * https://help.github.com/en/articles/displaying-a-sponsor-button-in-your-repository\n# * https://tidelift.com/subscription/how-to-connect-tidelift-with-github\ntidelift: pypi/pytest\nopen_collective: pytest",
                "filename": ".github/FUNDING.yml",
                "start_index": 0,
                "end_index": 214,
                "start_line": 1,
                "end_line": 5,
                "max_line": 5,
                "git_instance": "github",
                "repo_name": "testbed/pytest-dev__pytest__7.2",
                "sha": "",
                "context_relevance": 0.0
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {},
        "solution_task": "- Investigate the `approx` function in the file `/home/arkanoid/test/venv/lib/python3.10/site-packages/_pytest/python_api.py` for potential division by zero when handling dictionaries with zero values.\n- Ensure that the `approx` function has a check to prevent division by zero when calculating relative tolerance for both lists and dictionaries.\n- If the `approx` function uses a formula that involves division by the expected value, add a condition to handle the case when the expected value is zero.\n- For example, if the `approx` function calculates relative tolerance as `rel_tol = rel * abs(expected)`, ensure that there is a guard clause like `if expected == 0: rel_tol = 0` before the division occurs.\n- Add tests in `extra/test_pytest_issue.py` to cover cases where `approx` is used with dictionaries and lists containing zero values to ensure the issue is resolved and does not recur.",
        "bouncer_response": {
            "score": 8,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant hints and solutions that can directly lead to resolving the issues outlined in the PROMPT.",
            "supporting_evidence": "The RESPONSE provides a clear and actionable set of steps to investigate and potentially resolve the ZeroDivisionError encountered when using pytest's `approx` function with dictionaries containing zero values. It suggests looking into the `approx` function for division by zero issues, adding checks to prevent such errors, and modifying the function to handle zero values appropriately. Additionally, it recommends adding tests to cover these cases, which is a good practice for ensuring the bug is fixed and does not reappear. The RESPONSE is directly addressing the issue described in the PROMPT and provides a comprehensive approach to fixing the bug.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711734373.630553,
        "result": "- Investigate the `approx` function in the file `/home/arkanoid/test/venv/lib/python3.10/site-packages/_pytest/python_api.py` for potential division by zero when handling dictionaries with zero values.\n- Ensure that the `approx` function has a check to prevent division by zero when calculating relative tolerance for both lists and dictionaries.\n- If the `approx` function uses a formula that involves division by the expected value, add a condition to handle the case when the expected value is zero.\n- For example, if the `approx` function calculates relative tolerance as `rel_tol = rel * abs(expected)`, ensure that there is a guard clause like `if expected == 0: rel_tol = 0` before the division occurs.\n- Add tests in `extra/test_pytest_issue.py` to cover cases where `approx` is used with dictionaries and lists containing zero values to ensure the issue is resolved and does not recur.",
        "context_relevance": 0.05,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE must be relevant to the entire PROMPT to get a score of 9 or 10. The RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 10.\nSupporting Evidence: The RESPONSE addresses the issue described in the PROMPT by suggesting an investigation into the `approx` function for potential division by zero errors when handling dictionaries with zero values. It also provides a solution to ensure that the `approx` function has a check to prevent division by zero for both lists and dictionaries, which is directly relevant to the problem described in the test cases. The RESPONSE further advises adding a condition to handle cases when the expected value is zero, which is pertinent to the ZeroDivisionError encountered. Lastly, it recommends adding tests to cover the cases and ensure the issue does not recur, which is a direct response to the test output provided in the PROMPT. The RESPONSE is comprehensive and addresses the entire PROMPT, thus meriting a score of 10."
        },
        "qa_relevance": 1.0
    }
}