{
    "id": "scikit-learn__scikit-learn-13554",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
    "task_id": 4599102104008444367,
    "title": "Numerical precision of euclidean_distances with float32",
    "body": "<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\r\n\r\n#### Description\r\nI noticed that sklearn.metrics.pairwise.pairwise_distances function agrees with np.linalg.norm when using np.float64 arrays, but disagrees when using np.float32 arrays. See the code snippet below.\r\n\r\n#### Steps/Code to Reproduce\r\n\r\n```python\r\nimport numpy as np\r\nimport scipy\r\nimport sklearn.metrics.pairwise\r\n\r\n# create 64-bit vectors a and b that are very similar to each other\r\na_64 = np.array([61.221637725830078125, 71.60662841796875,    -65.7512664794921875],  dtype=np.float64)\r\nb_64 = np.array([61.221637725830078125, 71.60894012451171875, -65.72847747802734375], dtype=np.float64)\r\n\r\n# create 32-bit versions of a and b\r\na_32 = a_64.astype(np.float32)\r\nb_32 = b_64.astype(np.float32)\r\n\r\n# compute the distance from a to b using numpy, for both 64-bit and 32-bit\r\ndist_64_np = np.array([np.linalg.norm(a_64 - b_64)], dtype=np.float64)\r\ndist_32_np = np.array([np.linalg.norm(a_32 - b_32)], dtype=np.float32)\r\n\r\n# compute the distance from a to b using sklearn, for both 64-bit and 32-bit\r\ndist_64_sklearn = sklearn.metrics.pairwise.pairwise_distances([a_64], [b_64])\r\ndist_32_sklearn = sklearn.metrics.pairwise.pairwise_distances([a_32], [b_32])\r\n\r\n# note that the 64-bit sklearn results agree exactly with numpy, but the 32-bit results disagree\r\nnp.set_printoptions(precision=200)\r\n\r\nprint(dist_64_np)\r\nprint(dist_32_np)\r\nprint(dist_64_sklearn)\r\nprint(dist_32_sklearn)\r\n```\r\n\r\n#### Expected Results\r\nI expect that the results from sklearn.metrics.pairwise.pairwise_distances would agree with np.linalg.norm for both 64-bit and 32-bit. In other words, I expect the following output:\r\n```\r\n[ 0.0229059506440019884643266578905240749008953571319580078125]\r\n[ 0.02290595136582851409912109375]\r\n[[ 0.0229059506440019884643266578905240749008953571319580078125]]\r\n[[ 0.02290595136582851409912109375]]\r\n```\r\n\r\n#### Actual Results\r\nThe code snippet above produces the following output for me:\r\n```\r\n[ 0.0229059506440019884643266578905240749008953571319580078125]\r\n[ 0.02290595136582851409912109375]\r\n[[ 0.0229059506440019884643266578905240749008953571319580078125]]\r\n[[ 0.03125]]\r\n```\r\n\r\n#### Versions\r\n```\r\nDarwin-16.6.0-x86_64-i386-64bit\r\n('Python', '2.7.11 | 64-bit | (default, Jun 11 2016, 03:41:56) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]')\r\n('NumPy', '1.11.3')\r\n('SciPy', '0.19.0')\r\n('Scikit-Learn', '0.18.1')\r\n```\n[WIP] Stable and fast float32 implementation of euclidean_distances\n#### Reference Issues/PRs\r\nFixes #9354\r\nSuperseds PR #10069\r\n\r\n#### What does this implement/fix? Explain your changes.\r\nThese commits implement a block-wise casting to float64 and uses the older code to compute the euclidean distance matrix on the blocks. This is done useing only a fixed amount of additional (temporary) memory.\r\n\r\n#### Any other comments?\r\nThis code implements several optimizations:\r\n\r\n* since the distance matrix is symmetric when `X is Y`, copy the blocks of the upper triangle to the lower triangle;\r\n* compute the optimal block size that would use most of the allowed additional memory;\r\n* cast blocks of `{X,Y}_norm_squared` to float64;\r\n* precompute blocks of `X_norm_squared` if not given so it gets reused through the iterations over `Y`;\r\n* swap `X` and `Y` when `X_norm_squared` is given, but not `Y_norm_squared`.\r\n\r\nNote that all the optimizations listed here have proven useful in a benchmark. The hardcoded amount of additional memory of 10MB is also derived from a benchmark.\r\n\r\nAs a side bonus, this implementation should also support float16 out of the box, should scikit-learn support it at some point.\nAdd a test for numeric precision (see #9354)\nSurprisingly bad precision, isn't it?\r\n\r\nNote that the traditional computation sqrt(sum((x-y)**2)) gets the results exact.\r\n\r\n<!--\r\nThanks for contributing a pull request! Please ensure you have taken a look at\r\nthe contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist\r\n-->\r\n\r\n#### Reference Issues/PRs\r\n<!--\r\nExample: Fixes #1234. See also #3456.\r\nPlease use keywords (e.g., Fixes) to create link to the issues or pull requests\r\nyou resolved, so that they will automatically be closed when your pull request\r\nis merged. See https://github.com/blog/1506-closing-issues-via-pull-requests\r\n-->\r\n\r\n\r\n#### What does this implement/fix? Explain your changes.\r\n\r\n\r\n#### Any other comments?\r\n\r\n\r\n<!--\r\nPlease be aware that we are a loose team of volunteers so patience is\r\nnecessary; assistance handling other issues is very welcome. We value\r\nall user contributions, no matter how minor they are. If we are slow to\r\nreview, either the pull request needs some benchmarking, tinkering,\r\nconvincing, etc. or more likely the reviewers are simply busy. In either\r\ncase, we ask for your understanding during the review process.\r\nFor more information, see our FAQ on this topic:\r\nhttp://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.\r\n\r\nThanks for contributing!\r\n-->\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.21.git",
    "requested_commit": "",
    "mayil_response": "- Update the `_euclidean_distances` function in `sklearn/metrics/pairwise.py` to ensure that when `X_norm_squared` or `Y_norm_squared` is passed as `float32`, it is cast to `float64` before being used in distance calculations.\n- Modify the `if X.dtype == np.float32:` block in `_euclidean_distances` to cast `X_norm_squared` and `Y_norm_squared` to `float64` if they are not `None` and have `dtype` of `float32`.\n- Ensure that the casting to `float64` is done before the distance computation to avoid precision loss in `float32`.\n- The updated code block in `_euclidean_distances` should look like this:\n\n```python\nif X.dtype == np.float32:\n    # Cast X_norm_squared and Y_norm_squared to float64 if they are not None\n    if X_norm_squared is not None and X_norm_squared.dtype == np.float32:\n        XX = X_norm_squared.astype(np.float64).reshape(-1, 1)\n    else:\n        XX = None\n    if Y_norm_squared is not None and Y_norm_squared.dtype == np.float32:\n        YY = Y_norm_squared.astype(np.float64).reshape(1, -1)\n    else:\n        YY = None\n\n    # Compute the distance matrix on chunks of X and Y upcast to float64\n    distances = _euclidean_distances_upcast(X, XX, Y, YY)\nelse:\n    # if dtype is already float64, no need to chunk and upcast\n    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)\n    distances += XX\n    distances += YY\nnp.maximum(distances, 0, out=distances)\n\n# Ensure that distances between vectors and themselves are set to 0.0.\nif X is Y:\n    np.fill_diagonal(distances, 0)\n\nreturn distances if squared else np.sqrt(distances, out=distances)\n```\n- No changes are required in the `_euclidean_distances_upcast` function as it already handles the upcasting of `X` and `Y` to `float64`.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn) \u2192 [metrics](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn/metrics)- [Lines 350 - 398](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/metrics/pairwise.py#L350-L398)\n\n This snippet contains the implementation of '_euclidean_distances' which is directly related to the issue of numerical precision with float32. \n\n\n   - [Lines 533 - 1320](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/metrics/pairwise.py#L533-L1320)\n\n This snippet contains the implementation of '_euclidean_distances_upcast' which handles the upcasting of float32 to float64 to minimize precision issues, relevant to the issue. \n\n\n   - [Lines 1 - 69](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/metrics/pairwise.py#L1-L69)\n\n This snippet includes the utility function '_return_float_dtype' which determines the dtype for distance calculations and may need to be reviewed for the issue.\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn/utils)- [Lines 1 - 85](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/utils/extmath.py#L1-L85)\n\n This snippet contains the 'row_norms' function which is used in the computation of the euclidean distances and may be relevant to the precision issue.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0008225,
        "snippet_processor": 0.051160000000000004,
        "issue_star_creation": 0.035809999999999995,
        "issue_star_solver": 0.07194,
        "bouncer": 0.02488
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711740446.602416,
        "relevant_snippets": [
            {
                "code": "# Authors: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n#          Mathieu Blondel <mathieu@mblondel.org>\n#          Robert Layton <robertlayton@gmail.com>\n#          Andreas Mueller <amueller@ais.uni-bonn.de>\n#          Philippe Gervais <philippe.gervais@inria.fr>\n#          Lars Buitinck\n#          Joel Nothman <joel.nothman@gmail.com>\n# License: BSD 3 clause\n\nimport itertools\nimport warnings\nfrom functools import partial\nfrom numbers import Integral, Real\n\nimport numpy as np\nfrom joblib import effective_n_jobs\nfrom scipy.sparse import csr_matrix, issparse\nfrom scipy.spatial import distance\n\nfrom .. import config_context\nfrom ..exceptions import DataConversionWarning\nfrom ..preprocessing import normalize\nfrom ..utils import (\n    check_array,\n    gen_batches,\n    gen_even_slices,\n    get_chunk_n_rows,\n    is_scalar_nan,\n)\nfrom ..utils._mask import _get_mask\nfrom ..utils._param_validation import (\n    Hidden,\n    Interval,\n    MissingValues,\n    Options,\n    StrOptions,\n    validate_params,\n)\nfrom ..utils.extmath import row_norms, safe_sparse_dot\nfrom ..utils.fixes import parse_version, sp_base_version\nfrom ..utils.parallel import Parallel, delayed\nfrom ..utils.validation import _num_samples, check_non_negative\nfrom ._pairwise_distances_reduction import ArgKmin\nfrom ._pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n\n\n# Utility Functions\ndef _return_float_dtype(X, Y):\n    \"\"\"\n    1. If dtype of X and Y is float32, then dtype float32 is returned.\n    2. Else dtype float is returned.\n    \"\"\"\n    if not issparse(X) and not isinstance(X, np.ndarray):\n        X = np.asarray(X)\n\n    if Y is None:\n        Y_dtype = X.dtype\n    elif not issparse(Y) and not isinstance(Y, np.ndarray):\n        Y = np.asarray(Y)\n        Y_dtype = Y.dtype\n    else:\n        Y_dtype = Y.dtype\n\n    if X.dtype == Y_dtype == np.float32:\n        dtype = np.float32\n    else:\n        dtype = float\n\n    return X, Y, dtype",
                "filename": "sklearn/metrics/pairwise.py",
                "start_index": 0,
                "end_index": 1930,
                "start_line": 1,
                "end_line": 69,
                "max_line": 2425,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "def _euclidean_distances(X, Y, X_norm_squared=None, Y_norm_squared=None, squared=False):\n    \"\"\"Computational part of euclidean_distances\n\n    Assumes inputs are already checked.\n\n    If norms are passed as float32, they are unused. If arrays are passed as\n    float32, norms needs to be recomputed on upcast chunks.\n    TODO: use a float64 accumulator in row_norms to avoid the latter.\n    \"\"\"\n    if X_norm_squared is not None:\n        if X_norm_squared.dtype == np.float32:\n            XX = None\n        else:\n            XX = X_norm_squared.reshape(-1, 1)\n    elif X.dtype == np.float32:\n        XX = None\n    else:\n        XX = row_norms(X, squared=True)[:, np.newaxis]\n\n    if Y is X:\n        YY = None if XX is None else XX.T\n    else:\n        if Y_norm_squared is not None:\n            if Y_norm_squared.dtype == np.float32:\n                YY = None\n            else:\n                YY = Y_norm_squared.reshape(1, -1)\n        elif Y.dtype == np.float32:\n            YY = None\n        else:\n            YY = row_norms(Y, squared=True)[np.newaxis, :]\n\n    if X.dtype == np.float32:\n        # To minimize precision issues with float32, we compute the distance\n        # matrix on chunks of X and Y upcast to float64\n        distances = _euclidean_distances_upcast(X, XX, Y, YY)\n    else:\n        # if dtype is already float64, no need to chunk and upcast\n        distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)\n        distances += XX\n        distances += YY\n    np.maximum(distances, 0, out=distances)\n\n    # Ensure that distances between vectors and themselves are set to 0.0.\n    # This may not be the case due to floating point rounding errors.\n    if X is Y:\n        np.fill_diagonal(distances, 0)\n\n    return distances if squared else np.sqrt(distances, out=distances)",
                "filename": "sklearn/metrics/pairwise.py",
                "start_index": 11874,
                "end_index": 13667,
                "start_line": 350,
                "end_line": 398,
                "max_line": 2425,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "def _euclidean_distances_upcast(X, XX=None, Y=None, YY=None, batch_size=None):\n    \"\"\"Euclidean distances between X and Y.\n\n    Assumes X and Y have float32 dtype.\n    Assumes XX and YY have float64 dtype or are None.\n\n    X and Y are upcast to float64 by chunks, which size is chosen to limit\n    memory increase by approximately 10% (at least 10MiB).\n    \"\"\"\n    n_samples_X = X.shape[0]\n    n_samples_Y = Y.shape[0]\n    n_features = X.shape[1]\n\n    distances = np.empty((n_samples_X, n_samples_Y), dtype=np.float32)\n\n    if batch_size is None:\n        x_density = X.nnz / np.prod(X.shape) if issparse(X) else 1\n        y_density = Y.nnz / np.prod(Y.shape) if issparse(Y) else 1\n\n        # Allow 10% more memory than X, Y and the distance matrix take (at\n        # least 10MiB)\n        maxmem = max(\n            (\n                (x_density * n_samples_X + y_density * n_samples_Y) * n_features\n                + (x_density * n_samples_X * y_density * n_samples_Y)\n            )\n            / 10,\n            10 * 2**17,\n        )\n\n        # The increase amount of memory in 8-byte blocks is:\n        # - x_density * batch_size * n_features (copy of chunk of X)\n        # - y_density * batch_size * n_features (copy of chunk of Y)\n        # - batch_size * batch_size (chunk of distance matrix)\n        # Hence x\u00b2 + (xd+yd)kx = M, where x=batch_size, k=n_features, M=maxmem\n        #                                 xd=x_density and yd=y_density\n        tmp = (x_density + y_density) * n_features\n        batch_size = (-tmp + np.sqrt(tmp**2 + 4 * maxmem)) / 2\n        batch_size = max(int(batch_size), 1)\n\n    x_batches = gen_batches(n_samples_X, batch_size)\n\n    for i, x_slice in enumerate(x_batches):\n        X_chunk = X[x_slice].astype(np.float64)\n        if XX is None:\n            XX_chunk = row_norms(X_chunk, squared=True)[:, np.newaxis]\n        else:\n            XX_chunk = XX[x_slice]\n\n        y_batches = gen_batches(n_samples_Y, batch_size)\n\n        for j, y_slice in enumerate(y_batches):\n            if X is Y and j < i:\n                # when X is Y the distance matrix is symmetric so we only need\n                # to compute half of it.\n                d = distances[y_slice, x_slice].T\n\n            else:\n                Y_chunk = Y[y_slice].astype(np.float64)\n                if YY is None:\n                    YY_chunk = row_norms(Y_chunk, squared=True)[np.newaxis, :]\n                else:\n                    YY_chunk = YY[:, y_slice]\n\n                d = -2 * safe_sparse_dot(X_chunk, Y_chunk.T, dense_output=True)\n                d += XX_chunk\n                d += YY_chunk\n\n            distances[x_slice, y_slice] = d.astype(np.float32, copy=False)\n\n    return distances",
                "filename": "sklearn/metrics/pairwise.py",
                "start_index": 17860,
                "end_index": 20557,
                "start_line": 533,
                "end_line": 1320,
                "max_line": 2425,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "# combinations of dense and sparse inputs on float32 and float64 datasets, except\n# the sparse-dense and dense-sparse combinations for the Euclidean and Squared\n# Euclidean Distance metrics.\n# A detailed list of the impacted estimators can be found in the\n# :ref:`changelog <changes_1_2>`.",
                "filename": "examples/release_highlights/plot_release_highlights_1_2_0.py",
                "start_index": 5985,
                "end_index": 6274,
                "start_line": 162,
                "end_line": 166,
                "max_line": 166,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "\"metrics._pairwise_distances_reduction\": [\n        {\n            \"sources\": [\"_datasets_pair.pyx.tp\", \"_datasets_pair.pxd.tp\"],\n            \"language\": \"c++\",\n            \"include_np\": True,\n            \"extra_compile_args\": [\"-std=c++11\"],\n        },\n        {\n            \"sources\": [\"_middle_term_computer.pyx.tp\", \"_middle_term_computer.pxd.tp\"],\n            \"language\": \"c++\",\n            \"extra_compile_args\": [\"-std=c++11\"],\n        },\n        {\n            \"sources\": [\"_base.pyx.tp\", \"_base.pxd.tp\"],\n            \"language\": \"c++\",\n            \"include_np\": True,\n            \"extra_compile_args\": [\"-std=c++11\"],\n        },\n        {\n            \"sources\": [\"_argkmin.pyx.tp\", \"_argkmin.pxd.tp\"],\n            \"language\": \"c++\",\n            \"include_np\": True,\n            \"extra_compile_args\": [\"-std=c++11\"],\n        },\n        {\n            \"sources\": [\"_argkmin_classmode.pyx.tp\"],\n            \"language\": \"c++\",\n            \"include_np\": True,\n            \"extra_compile_args\": [\"-std=c++11\"],\n        },\n        {\n            \"sources\": [\"_radius_neighbors.pyx.tp\", \"_radius_neighbors.pxd.tp\"],\n            \"language\": \"c++\",\n            \"include_np\": True,\n            \"extra_compile_args\": [\"-std=c++11\"],\n        },\n    ],\n    \"preprocessing\": [\n        {\"sources\": [\"_csr_polynomial_expansion.pyx\"]},\n        {\n            \"sources\": [\"_target_encoder_fast.pyx\"],\n            \"include_np\": True,\n            \"language\": \"c++\",\n            \"extra_compile_args\": [\"-std=c++11\"],\n        },\n    ],\n    \"neighbors\": [\n        {\"sources\": [\"_ball_tree.pyx\"], \"include_np\": True},\n        {\"sources\": [\"_kd_tree.pyx\"], \"include_np\": True},\n        {\"sources\": [\"_partition_nodes.pyx\"], \"language\": \"c++\", \"include_np\": True},\n        {\"sources\": [\"_quad_tree.pyx\"], \"include_np\": True},\n    ],",
                "filename": "setup.py",
                "start_index": 9151,
                "end_index": 10957,
                "start_line": 262,
                "end_line": 592,
                "max_line": 626,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.1
            },
            {
                "code": "if X.dtype == Y.dtype == np.float64:\n            return RadiusNeighbors64.compute(\n                X=X,\n                Y=Y,\n                radius=radius,\n                metric=metric,\n                chunk_size=chunk_size,\n                metric_kwargs=metric_kwargs,\n                strategy=strategy,\n                sort_results=sort_results,\n                return_distance=return_distance,\n            )\n\n        if X.dtype == Y.dtype == np.float32:\n            return RadiusNeighbors32.compute(\n                X=X,\n                Y=Y,\n                radius=radius,\n                metric=metric,\n                chunk_size=chunk_size,\n                metric_kwargs=metric_kwargs,\n                strategy=strategy,\n                sort_results=sort_results,\n                return_distance=return_distance,\n            )\n\n        raise ValueError(\n            \"Only float64 or float32 datasets pairs are supported at this time, \"\n            f\"got: X.dtype={X.dtype} and Y.dtype={Y.dtype}.\"\n        )",
                "filename": "sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py",
                "start_index": 14633,
                "end_index": 15645,
                "start_line": 258,
                "end_line": 615,
                "max_line": 615,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "\"\"\"\nExtended math utilities.\n\"\"\"\n# Authors: Gael Varoquaux\n#          Alexandre Gramfort\n#          Alexandre T. Passos\n#          Olivier Grisel\n#          Lars Buitinck\n#          Stefan van der Walt\n#          Kyle Kastner\n#          Giorgio Patrini\n# License: BSD 3 clause\n\nimport warnings\nfrom functools import partial\nfrom numbers import Integral\n\nimport numpy as np\nfrom scipy import linalg, sparse\n\nfrom ..utils._param_validation import Interval, StrOptions, validate_params\nfrom . import check_random_state\nfrom ._array_api import _is_numpy_namespace, device, get_namespace\nfrom ._logistic_sigmoid import _log_logistic_sigmoid\nfrom .sparsefuncs_fast import csr_row_norms\nfrom .validation import check_array\n\n\ndef squared_norm(x):\n    \"\"\"Squared Euclidean or Frobenius norm of x.\n\n    Faster than norm(x) ** 2.\n\n    Parameters\n    ----------\n    x : array-like\n        The input array which could be either be a vector or a 2 dimensional array.\n\n    Returns\n    -------\n    float\n        The Euclidean norm when x is a vector, the Frobenius norm when x\n        is a matrix (2-d array).\n    \"\"\"\n    x = np.ravel(x, order=\"K\")\n    if np.issubdtype(x.dtype, np.integer):\n        warnings.warn(\n            (\n                \"Array type is integer, np.dot may overflow. \"\n                \"Data should be float type to avoid this issue\"\n            ),\n            UserWarning,\n        )\n    return np.dot(x, x)\n\n\ndef row_norms(X, squared=False):\n    \"\"\"Row-wise (squared) Euclidean norm of X.\n\n    Equivalent to np.sqrt((X * X).sum(axis=1)), but also supports sparse\n    matrices and does not create an X.shape-sized temporary.\n\n    Performs no input validation.\n\n    Parameters\n    ----------\n    X : array-like\n        The input array.\n    squared : bool, default=False\n        If True, return squared norms.\n\n    Returns\n    -------\n    array-like\n        The row-wise (squared) Euclidean norm of X.\n    \"\"\"\n    if sparse.issparse(X):\n        X = X.tocsr()\n        norms = csr_row_norms(X)\n    else:\n        norms = np.einsum(\"ij,ij->i\", X, X)\n\n    if not squared:\n        np.sqrt(norms, norms)\n    return norms",
                "filename": "sklearn/utils/extmath.py",
                "start_index": 0,
                "end_index": 2117,
                "start_line": 1,
                "end_line": 85,
                "max_line": 1271,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "distances = euclidean_distances(X, Y, squared=True)\n\n    # Adjust distances for missing values\n    XX = X * X\n    YY = Y * Y\n    distances -= np.dot(XX, missing_Y.T)\n    distances -= np.dot(missing_X, YY.T)\n\n    np.clip(distances, 0, None, out=distances)\n\n    if X is Y:\n        # Ensure that distances between vectors and themselves are set to 0.0.\n        # This may not be the case due to floating point rounding errors.\n        np.fill_diagonal(distances, 0.0)\n\n    present_X = 1 - missing_X\n    present_Y = present_X if Y is X else ~missing_Y\n    present_count = np.dot(present_X, present_Y.T)\n    distances[present_count == 0] = np.nan\n    # avoid divide by zero\n    np.maximum(1, present_count, out=present_count)\n    distances /= present_count\n    distances *= X.shape[1]\n\n    if not squared:\n        np.sqrt(distances, out=distances)\n\n    return distances",
                "filename": "sklearn/metrics/pairwise.py",
                "start_index": 16993,
                "end_index": 17857,
                "start_line": 503,
                "end_line": 1320,
                "max_line": 2425,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "if metric == \"precomputed\":\n        error_msg = ValueError(\n            \"The precomputed distance matrix contains non-zero \"\n            \"elements on the diagonal. Use np.fill_diagonal(X, 0).\"\n        )\n        if X.dtype.kind == \"f\":\n            atol = np.finfo(X.dtype).eps * 100\n            if np.any(np.abs(X.diagonal()) > atol):\n                raise error_msg\n        elif np.any(X.diagonal() != 0):  # integral dtype\n            raise error_msg\n\n    le = LabelEncoder()\n    labels = le.fit_transform(labels)\n    n_samples = len(labels)\n    label_freqs = np.bincount(labels)\n    check_number_of_labels(len(le.classes_), n_samples)\n\n    kwds[\"metric\"] = metric\n    reduce_func = functools.partial(\n        _silhouette_reduce, labels=labels, label_freqs=label_freqs\n    )\n    results = zip(*pairwise_distances_chunked(X, reduce_func=reduce_func, **kwds))\n    intra_clust_dists, inter_clust_dists = results\n    intra_clust_dists = np.concatenate(intra_clust_dists)\n    inter_clust_dists = np.concatenate(inter_clust_dists)\n\n    denom = (label_freqs - 1).take(labels, mode=\"clip\")\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        intra_clust_dists /= denom\n\n    sil_samples = inter_clust_dists - intra_clust_dists\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n    # nan values are for clusters of size 1, and should be 0\n    return np.nan_to_num(sil_samples)",
                "filename": "sklearn/metrics/cluster/_unsupervised.py",
                "start_index": 10370,
                "end_index": 11829,
                "start_line": 126,
                "end_line": 295,
                "max_line": 425,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 0.1
            },
            {
                "code": "# Pairwise Distances Reductions\n# =============================\n#\n#    Author: Julien Jerphanion <git@jjerphan.xyz>\n#\n# Overview\n# --------\n#\n#    This module provides routines to compute pairwise distances between a set\n#    of row vectors of X and another set of row vectors of Y and apply a\n#    reduction on top. The canonical example is the brute-force computation\n#    of the top k nearest neighbors by leveraging the arg-k-min reduction.\n#\n#    The reduction takes a matrix of pairwise distances between rows of X and Y\n#    as input and outputs an aggregate data-structure for each row of X. The\n#    aggregate values are typically smaller than the number of rows in Y, hence\n#    the term reduction.\n#\n#    For computational reasons, the reduction are performed on the fly on chunks\n#    of rows of X and Y so as to keep intermediate data-structures in CPU cache\n#    and avoid unnecessary round trips of large distance arrays with the RAM\n#    that would otherwise severely degrade the speed by making the overall\n#    processing memory-bound.\n#\n#    Finally, the routines follow a generic parallelization template to process\n#    chunks of data with OpenMP loops (via Cython prange), either on rows of X\n#    or rows of Y depending on their respective sizes.\n#\n#\n# Dispatching to specialized implementations\n# ------------------------------------------\n#\n#    Dispatchers are meant to be used in the Python code. Under the hood, a\n#    dispatcher must only define the logic to choose at runtime to the correct\n#    dtype-specialized :class:`BaseDistancesReductionDispatcher` implementation based\n#    on the dtype of X and of Y.\n#\n#\n# High-level diagram\n# ------------------\n#\n#    Legend:\n#\n#      A ---\u22b3 B: A inherits from B\n#      A ---x B: A dispatches to B\n#\n#\n#                               (base dispatcher)\n#                         BaseDistancesReductionDispatcher\n#                                       \u2206\n#                                       |\n#                                       |\n#               +-----------------------+----------------------+\n#               |                                              |\n#          (dispatcher)                                   (dispatcher)\n#            ArgKmin                                     RadiusNeighbors\n#               |                                              |\n#               |                                              |\n#               |              (float{32,64} implem.)          |\n#               |           BaseDistancesReduction{32,64}      |\n#               |                       \u2206                      |\n#               |                       |                      |\n#               |                       |                      |\n#               |     +-----------------+-----------------+    |\n#               |     |                                   |    |\n#               |     |                                   |    |\n#",
                "filename": "sklearn/metrics/_pairwise_distances_reduction/__init__.py",
                "start_index": 0,
                "end_index": 2937,
                "start_line": 1,
                "end_line": 86,
                "max_line": 103,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                "sha": "",
                "context_relevance": 1.0
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sklearn/metrics/pairwise.py": [
                {
                    "chunk": {
                        "code": "def _euclidean_distances(X, Y, X_norm_squared=None, Y_norm_squared=None, squared=False):\n    \"\"\"Computational part of euclidean_distances\n\n    Assumes inputs are already checked.\n\n    If norms are passed as float32, they are unused. If arrays are passed as\n    float32, norms needs to be recomputed on upcast chunks.\n    TODO: use a float64 accumulator in row_norms to avoid the latter.\n    \"\"\"\n    if X_norm_squared is not None:\n        if X_norm_squared.dtype == np.float32:\n            XX = None\n        else:\n            XX = X_norm_squared.reshape(-1, 1)\n    elif X.dtype == np.float32:\n        XX = None\n    else:\n        XX = row_norms(X, squared=True)[:, np.newaxis]\n\n    if Y is X:\n        YY = None if XX is None else XX.T\n    else:\n        if Y_norm_squared is not None:\n            if Y_norm_squared.dtype == np.float32:\n                YY = None\n            else:\n                YY = Y_norm_squared.reshape(1, -1)\n        elif Y.dtype == np.float32:\n            YY = None\n        else:\n            YY = row_norms(Y, squared=True)[np.newaxis, :]\n\n    if X.dtype == np.float32:\n        # To minimize precision issues with float32, we compute the distance\n        # matrix on chunks of X and Y upcast to float64\n        distances = _euclidean_distances_upcast(X, XX, Y, YY)\n    else:\n        # if dtype is already float64, no need to chunk and upcast\n        distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)\n        distances += XX\n        distances += YY\n    np.maximum(distances, 0, out=distances)\n\n    # Ensure that distances between vectors and themselves are set to 0.0.\n    # This may not be the case due to floating point rounding errors.\n    if X is Y:\n        np.fill_diagonal(distances, 0)\n\n    return distances if squared else np.sqrt(distances, out=distances)",
                        "filename": "sklearn/metrics/pairwise.py",
                        "start_index": 11874,
                        "end_index": 13667,
                        "start_line": 350,
                        "end_line": 398,
                        "max_line": 2425,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the implementation of '_euclidean_distances' which is directly related to the issue of numerical precision with float32."
                },
                {
                    "chunk": {
                        "code": "def _euclidean_distances_upcast(X, XX=None, Y=None, YY=None, batch_size=None):\n    \"\"\"Euclidean distances between X and Y.\n\n    Assumes X and Y have float32 dtype.\n    Assumes XX and YY have float64 dtype or are None.\n\n    X and Y are upcast to float64 by chunks, which size is chosen to limit\n    memory increase by approximately 10% (at least 10MiB).\n    \"\"\"\n    n_samples_X = X.shape[0]\n    n_samples_Y = Y.shape[0]\n    n_features = X.shape[1]\n\n    distances = np.empty((n_samples_X, n_samples_Y), dtype=np.float32)\n\n    if batch_size is None:\n        x_density = X.nnz / np.prod(X.shape) if issparse(X) else 1\n        y_density = Y.nnz / np.prod(Y.shape) if issparse(Y) else 1\n\n        # Allow 10% more memory than X, Y and the distance matrix take (at\n        # least 10MiB)\n        maxmem = max(\n            (\n                (x_density * n_samples_X + y_density * n_samples_Y) * n_features\n                + (x_density * n_samples_X * y_density * n_samples_Y)\n            )\n            / 10,\n            10 * 2**17,\n        )\n\n        # The increase amount of memory in 8-byte blocks is:\n        # - x_density * batch_size * n_features (copy of chunk of X)\n        # - y_density * batch_size * n_features (copy of chunk of Y)\n        # - batch_size * batch_size (chunk of distance matrix)\n        # Hence x\u00b2 + (xd+yd)kx = M, where x=batch_size, k=n_features, M=maxmem\n        #                                 xd=x_density and yd=y_density\n        tmp = (x_density + y_density) * n_features\n        batch_size = (-tmp + np.sqrt(tmp**2 + 4 * maxmem)) / 2\n        batch_size = max(int(batch_size), 1)\n\n    x_batches = gen_batches(n_samples_X, batch_size)\n\n    for i, x_slice in enumerate(x_batches):\n        X_chunk = X[x_slice].astype(np.float64)\n        if XX is None:\n            XX_chunk = row_norms(X_chunk, squared=True)[:, np.newaxis]\n        else:\n            XX_chunk = XX[x_slice]\n\n        y_batches = gen_batches(n_samples_Y, batch_size)\n\n        for j, y_slice in enumerate(y_batches):\n            if X is Y and j < i:\n                # when X is Y the distance matrix is symmetric so we only need\n                # to compute half of it.\n                d = distances[y_slice, x_slice].T\n\n            else:\n                Y_chunk = Y[y_slice].astype(np.float64)\n                if YY is None:\n                    YY_chunk = row_norms(Y_chunk, squared=True)[np.newaxis, :]\n                else:\n                    YY_chunk = YY[:, y_slice]\n\n                d = -2 * safe_sparse_dot(X_chunk, Y_chunk.T, dense_output=True)\n                d += XX_chunk\n                d += YY_chunk\n\n            distances[x_slice, y_slice] = d.astype(np.float32, copy=False)\n\n    return distances",
                        "filename": "sklearn/metrics/pairwise.py",
                        "start_index": 17860,
                        "end_index": 20557,
                        "start_line": 533,
                        "end_line": 1320,
                        "max_line": 2425,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the implementation of '_euclidean_distances_upcast' which handles the upcasting of float32 to float64 to minimize precision issues, relevant to the issue."
                },
                {
                    "chunk": {
                        "code": "# Authors: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n#          Mathieu Blondel <mathieu@mblondel.org>\n#          Robert Layton <robertlayton@gmail.com>\n#          Andreas Mueller <amueller@ais.uni-bonn.de>\n#          Philippe Gervais <philippe.gervais@inria.fr>\n#          Lars Buitinck\n#          Joel Nothman <joel.nothman@gmail.com>\n# License: BSD 3 clause\n\nimport itertools\nimport warnings\nfrom functools import partial\nfrom numbers import Integral, Real\n\nimport numpy as np\nfrom joblib import effective_n_jobs\nfrom scipy.sparse import csr_matrix, issparse\nfrom scipy.spatial import distance\n\nfrom .. import config_context\nfrom ..exceptions import DataConversionWarning\nfrom ..preprocessing import normalize\nfrom ..utils import (\n    check_array,\n    gen_batches,\n    gen_even_slices,\n    get_chunk_n_rows,\n    is_scalar_nan,\n)\nfrom ..utils._mask import _get_mask\nfrom ..utils._param_validation import (\n    Hidden,\n    Interval,\n    MissingValues,\n    Options,\n    StrOptions,\n    validate_params,\n)\nfrom ..utils.extmath import row_norms, safe_sparse_dot\nfrom ..utils.fixes import parse_version, sp_base_version\nfrom ..utils.parallel import Parallel, delayed\nfrom ..utils.validation import _num_samples, check_non_negative\nfrom ._pairwise_distances_reduction import ArgKmin\nfrom ._pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n\n\n# Utility Functions\ndef _return_float_dtype(X, Y):\n    \"\"\"\n    1. If dtype of X and Y is float32, then dtype float32 is returned.\n    2. Else dtype float is returned.\n    \"\"\"\n    if not issparse(X) and not isinstance(X, np.ndarray):\n        X = np.asarray(X)\n\n    if Y is None:\n        Y_dtype = X.dtype\n    elif not issparse(Y) and not isinstance(Y, np.ndarray):\n        Y = np.asarray(Y)\n        Y_dtype = Y.dtype\n    else:\n        Y_dtype = Y.dtype\n\n    if X.dtype == Y_dtype == np.float32:\n        dtype = np.float32\n    else:\n        dtype = float\n\n    return X, Y, dtype",
                        "filename": "sklearn/metrics/pairwise.py",
                        "start_index": 0,
                        "end_index": 1930,
                        "start_line": 1,
                        "end_line": 69,
                        "max_line": 2425,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet includes the utility function '_return_float_dtype' which determines the dtype for distance calculations and may need to be reviewed for the issue."
                }
            ],
            "sklearn/utils/extmath.py": [
                {
                    "chunk": {
                        "code": "\"\"\"\nExtended math utilities.\n\"\"\"\n# Authors: Gael Varoquaux\n#          Alexandre Gramfort\n#          Alexandre T. Passos\n#          Olivier Grisel\n#          Lars Buitinck\n#          Stefan van der Walt\n#          Kyle Kastner\n#          Giorgio Patrini\n# License: BSD 3 clause\n\nimport warnings\nfrom functools import partial\nfrom numbers import Integral\n\nimport numpy as np\nfrom scipy import linalg, sparse\n\nfrom ..utils._param_validation import Interval, StrOptions, validate_params\nfrom . import check_random_state\nfrom ._array_api import _is_numpy_namespace, device, get_namespace\nfrom ._logistic_sigmoid import _log_logistic_sigmoid\nfrom .sparsefuncs_fast import csr_row_norms\nfrom .validation import check_array\n\n\ndef squared_norm(x):\n    \"\"\"Squared Euclidean or Frobenius norm of x.\n\n    Faster than norm(x) ** 2.\n\n    Parameters\n    ----------\n    x : array-like\n        The input array which could be either be a vector or a 2 dimensional array.\n\n    Returns\n    -------\n    float\n        The Euclidean norm when x is a vector, the Frobenius norm when x\n        is a matrix (2-d array).\n    \"\"\"\n    x = np.ravel(x, order=\"K\")\n    if np.issubdtype(x.dtype, np.integer):\n        warnings.warn(\n            (\n                \"Array type is integer, np.dot may overflow. \"\n                \"Data should be float type to avoid this issue\"\n            ),\n            UserWarning,\n        )\n    return np.dot(x, x)\n\n\ndef row_norms(X, squared=False):\n    \"\"\"Row-wise (squared) Euclidean norm of X.\n\n    Equivalent to np.sqrt((X * X).sum(axis=1)), but also supports sparse\n    matrices and does not create an X.shape-sized temporary.\n\n    Performs no input validation.\n\n    Parameters\n    ----------\n    X : array-like\n        The input array.\n    squared : bool, default=False\n        If True, return squared norms.\n\n    Returns\n    -------\n    array-like\n        The row-wise (squared) Euclidean norm of X.\n    \"\"\"\n    if sparse.issparse(X):\n        X = X.tocsr()\n        norms = csr_row_norms(X)\n    else:\n        norms = np.einsum(\"ij,ij->i\", X, X)\n\n    if not squared:\n        np.sqrt(norms, norms)\n    return norms",
                        "filename": "sklearn/utils/extmath.py",
                        "start_index": 0,
                        "end_index": 2117,
                        "start_line": 1,
                        "end_line": 85,
                        "max_line": 1271,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.21",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the 'row_norms' function which is used in the computation of the euclidean distances and may be relevant to the precision issue."
                }
            ]
        },
        "solution_task": "- Update the `_euclidean_distances` function in `sklearn/metrics/pairwise.py` to ensure that when `X_norm_squared` or `Y_norm_squared` is passed as `float32`, it is cast to `float64` before being used in distance calculations.\n- Modify the `if X.dtype == np.float32:` block in `_euclidean_distances` to cast `X_norm_squared` and `Y_norm_squared` to `float64` if they are not `None` and have `dtype` of `float32`.\n- Ensure that the casting to `float64` is done before the distance computation to avoid precision loss in `float32`.\n- The updated code block in `_euclidean_distances` should look like this:\n\n```python\nif X.dtype == np.float32:\n    # Cast X_norm_squared and Y_norm_squared to float64 if they are not None\n    if X_norm_squared is not None and X_norm_squared.dtype == np.float32:\n        XX = X_norm_squared.astype(np.float64).reshape(-1, 1)\n    else:\n        XX = None\n    if Y_norm_squared is not None and Y_norm_squared.dtype == np.float32:\n        YY = Y_norm_squared.astype(np.float64).reshape(1, -1)\n    else:\n        YY = None\n\n    # Compute the distance matrix on chunks of X and Y upcast to float64\n    distances = _euclidean_distances_upcast(X, XX, Y, YY)\nelse:\n    # if dtype is already float64, no need to chunk and upcast\n    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)\n    distances += XX\n    distances += YY\nnp.maximum(distances, 0, out=distances)\n\n# Ensure that distances between vectors and themselves are set to 0.0.\nif X is Y:\n    np.fill_diagonal(distances, 0)\n\nreturn distances if squared else np.sqrt(distances, out=distances)\n```\n- No changes are required in the `_euclidean_distances_upcast` function as it already handles the upcasting of `X` and `Y` to `float64`.",
        "bouncer_response": {
            "score": 9,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant hints and solutions that can directly lead to resolving the issues outlined in the PROMPT.",
            "supporting_evidence": "The RESPONSE provides a detailed and actionable solution to the numerical precision issue described in the PROMPT. It suggests updating the '_euclidean_distances' function to cast 'X_norm_squared' and 'Y_norm_squared' to 'float64' if they are 'float32', which is a direct response to the problem of precision loss when using 'float32' arrays. The RESPONSE also includes a code snippet that demonstrates how to implement the proposed changes, which is highly relevant and useful for fixing the bug. Additionally, the RESPONSE provides links to specific code snippets in the scikit-learn repository that are related to the issue, which can help developers locate the relevant sections of code quickly.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711740716.239977,
        "result": "- Update the `_euclidean_distances` function in `sklearn/metrics/pairwise.py` to ensure that when `X_norm_squared` or `Y_norm_squared` is passed as `float32`, it is cast to `float64` before being used in distance calculations.\n- Modify the `if X.dtype == np.float32:` block in `_euclidean_distances` to cast `X_norm_squared` and `Y_norm_squared` to `float64` if they are not `None` and have `dtype` of `float32`.\n- Ensure that the casting to `float64` is done before the distance computation to avoid precision loss in `float32`.\n- The updated code block in `_euclidean_distances` should look like this:\n\n```python\nif X.dtype == np.float32:\n    # Cast X_norm_squared and Y_norm_squared to float64 if they are not None\n    if X_norm_squared is not None and X_norm_squared.dtype == np.float32:\n        XX = X_norm_squared.astype(np.float64).reshape(-1, 1)\n    else:\n        XX = None\n    if Y_norm_squared is not None and Y_norm_squared.dtype == np.float32:\n        YY = Y_norm_squared.astype(np.float64).reshape(1, -1)\n    else:\n        YY = None\n\n    # Compute the distance matrix on chunks of X and Y upcast to float64\n    distances = _euclidean_distances_upcast(X, XX, Y, YY)\nelse:\n    # if dtype is already float64, no need to chunk and upcast\n    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)\n    distances += XX\n    distances += YY\nnp.maximum(distances, 0, out=distances)\n\n# Ensure that distances between vectors and themselves are set to 0.0.\nif X is Y:\n    np.fill_diagonal(distances, 0)\n\nreturn distances if squared else np.sqrt(distances, out=distances)\n```\n- No changes are required in the `_euclidean_distances_upcast` function as it already handles the upcasting of `X` and `Y` to `float64`.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn) \u2192 [metrics](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn/metrics)- [Lines 350 - 398](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/metrics/pairwise.py#L350-L398)\n\n This snippet contains the implementation of '_euclidean_distances' which is directly related to the issue of numerical precision with float32. \n\n\n   - [Lines 533 - 1320](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/metrics/pairwise.py#L533-L1320)\n\n This snippet contains the implementation of '_euclidean_distances_upcast' which handles the upcasting of float32 to float64 to minimize precision issues, relevant to the issue. \n\n\n   - [Lines 1 - 69](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/metrics/pairwise.py#L1-L69)\n\n This snippet includes the utility function '_return_float_dtype' which determines the dtype for distance calculations and may need to be reviewed for the issue.\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.21/tree//sklearn/utils)- [Lines 1 - 85](https://github.com/testbed/scikit-learn__scikit-learn__0.21/blob//sklearn/utils/extmath.py#L1-L85)\n\n This snippet contains the 'row_norms' function which is used in the computation of the euclidean distances and may be relevant to the precision issue.",
        "context_relevance": 0.74,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE must be relevant to the entire PROMPT to get a score of 10.\nSupporting Evidence: The RESPONSE provides a detailed explanation and a solution to the issue described in the PROMPT regarding the numerical precision of `euclidean_distances` with `float32`. It addresses the problem by suggesting code changes to ensure that `X_norm_squared` and `Y_norm_squared` are cast to `float64` before being used in distance calculations when they are `float32`, which is directly related to the issue reported. The RESPONSE also includes a code snippet that reflects the proposed changes, which is relevant to the entire PROMPT. Additionally, the RESPONSE provides links to the relevant sections of the code in the scikit-learn repository, which supports the explanation and the proposed solution. The RESPONSE is comprehensive and answers the entire PROMPT completely, thus deserving a score of 10."
        },
        "qa_relevance": 1.0
    }
}