{
    "id": "scikit-learn__scikit-learn-14430",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
    "task_id": 4803106536837164090,
    "title": "Pickling Tokenizers fails due to use of lambdas",
    "body": "#### Description\r\nCannot pickle a `CountVectorizer` using the builtin python `pickle` module, likely due to the use of lambdas in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py \r\n\r\n#### Steps/Code to Reproduce\r\n\r\nExample:\r\n```python\r\nimport pickle\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\nraw_texts = [\"this is a text\", \"oh look, here's another\", \"including my full model vocab is...well, a lot\"]\r\nvectorizer = CountVectorizer(max_features=20000, token_pattern=r\"\\b\\w+\\b\")\r\nvectorizer.fit(raw_texts)\r\ntokenizer = vectorizer.build_tokenizer()\r\noutput_file = 'foo.pkl'\r\nwith open(output_file, 'wb') as out:\r\n    pickle.dump(tokenizer, out)\r\nwith open(output_file, 'rb') as infile:\r\n    pickle.load(infile)\r\n```\r\n\r\n#### Expected Results\r\n\r\nProgram runs without error\r\n\r\n#### Actual Results\r\n\r\nTraceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"tst.py\", line 14, in <module>\r\n    pickle.dump(tokenizer, out)\r\nAttributeError: Can't pickle local object 'VectorizerMixin.build_tokenizer.<locals>.<lambda>'\r\n```\r\n\r\n#### Workaround:\r\n\r\nInstead of the builtin `pickle`, use `cloudpickle`, which can capture the `lambda` expression.\r\n\r\n#### Versions\r\n<!--\r\nPlease run the following snippet and paste the output below.\r\nFor scikit-learn >= 0.20:\r\nimport sklearn; sklearn.show_versions()\r\nFor scikit-learn < 0.20:\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport numpy; print(\"NumPy\", numpy.__version__)\r\nimport scipy; print(\"SciPy\", scipy.__version__)\r\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\r\n-->\r\n\r\nVersion information:\r\n\r\n```python\r\n>>> import sklearn\r\n>>> print(sklearn.show_versions())\r\n/home/jay/Documents/projects/evidence-inference/venv/lib/python3.6/site-packages/numpy/distutils/system_info.py:625: UserWarning:\r\n    Atlas (http://math-atlas.sourceforge.net/) libraries not found.\r\n    Directories to search for the libraries can be specified in the\r\n    numpy/distutils/site.cfg file (section [atlas]) or by setting\r\n    the ATLAS environment variable.\r\n  self.calc_info()\r\n/usr/bin/ld: cannot find -lcblas\r\ncollect2: error: ld returned 1 exit status\r\n/usr/bin/ld: cannot find -lcblas\r\ncollect2: error: ld returned 1 exit status\r\n\r\nSystem:\r\n    python: 3.6.5 (default, Apr  1 2018, 05:46:30)  [GCC 7.3.0]\r\nexecutable: /home/jay/Documents/projects/evidence-inference/venv/bin/python\r\n   machine: Linux-4.15.0-39-generic-x86_64-with-Ubuntu-18.04-bionic\r\n\r\nBLAS:\r\n    macros: NO_ATLAS_INFO=1, HAVE_CBLAS=None\r\n  lib_dirs: /usr/lib/x86_64-linux-gnu\r\ncblas_libs: cblas\r\n\r\nPython deps:\r\n       pip: 18.1\r\nsetuptools: 39.1.0\r\n   sklearn: 0.20.2\r\n     numpy: 1.15.1\r\n     scipy: 1.1.0\r\n    Cython: None\r\n    pandas: 0.23.4\r\nNone\r\n```\r\n\r\n#### Similar Issues\r\n\r\nI think this is similar to issues:\r\n* https://github.com/scikit-learn/scikit-learn/issues/10807 \r\n* https://github.com/scikit-learn/scikit-learn/issues/9467 (looking at the stackoverflow thread at https://stackoverflow.com/questions/25348532/can-python-pickle-lambda-functions/25353243#25353243 , it suggests using `dill` which also seems to work for the toy example)\r\n\r\n#### Proposed fix\r\n \r\nNaively, I would make one of the two changes below, but I am not familiar with the scikit-learn codebase, so they might not be appropriate:\r\n1. Update the FAQ to direct people to other serialization libraries (perhaps I missed this recommendation?), e.g. `cloudpickle` at https://github.com/cloudpipe/cloudpickle or `dill`\r\n2. Remove the use of the lambdas in the vectorizer and replace them with locally def'd functions. I suspect that this solution is flawed because it doesn't account for other uses of lambdas elsewhere in the codebase, and the only complete solution would be to stop using lambdas, but these are a useful language feature. \r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.22.git",
    "requested_commit": "",
    "mayil_response": "- Replace the use of the `pickle` module with `cloudpickle` or `dill` for serializing the `tokenizer` object which contains a `lambda` expression.\n- Install `cloudpickle` or `dill` if not already installed.\n- Change the import statement from `import pickle` to `import cloudpickle as pickle` or `import dill as pickle`.\n- Ensure that the rest of the code remains unchanged, as `cloudpickle` and `dill` are drop-in replacements for `pickle` in most cases.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn/utils)- [Lines 181 - 2113](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/estimator_checks.py#L181-L2113)\n\n This snippet contains the 'check_estimators_pickle' function which is used to test if estimators can be pickled. Since the issue is related to pickling a tokenizer, this function may need to be updated to handle the lambda pickling issue.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0009725,
        "snippet_processor": 0.08512000000000002,
        "issue_star_creation": 0.049199999999999994,
        "issue_star_solver": 0.054560000000000004,
        "bouncer": 0.02766
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711739001.0745752,
        "relevant_snippets": [
            {
                "code": "\"\"\"\n===========================================\nFeatureHasher and DictVectorizer Comparison\n===========================================\n\nIn this example we illustrate text vectorization, which is the process of\nrepresenting non-numerical input data (such as dictionaries or text documents)\nas vectors of real numbers.\n\nWe first compare :func:`~sklearn.feature_extraction.FeatureHasher` and\n:func:`~sklearn.feature_extraction.DictVectorizer` by using both methods to\nvectorize text documents that are preprocessed (tokenized) with the help of a\ncustom Python function.\n\nLater we introduce and analyze the text-specific vectorizers\n:func:`~sklearn.feature_extraction.text.HashingVectorizer`,\n:func:`~sklearn.feature_extraction.text.CountVectorizer` and\n:func:`~sklearn.feature_extraction.text.TfidfVectorizer` that handle both the\ntokenization and the assembling of the feature matrix within a single class.\n\nThe objective of the example is to demonstrate the usage of text vectorization\nAPI and to compare their processing time. See the example scripts\n:ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\nand :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py` for actual\nlearning on text documents.\n\n\"\"\"\n\n# Author: Lars Buitinck\n#         Olivier Grisel <olivier.grisel@ensta.org>\n#         Arturo Amor <david-arturo.amor-quiroz@inria.fr>\n# License: BSD 3 clause\n\n# %%\n# Load Data\n# ---------\n#\n# We load data from :ref:`20newsgroups_dataset`, which comprises around\n# 18000 newsgroups posts on 20 topics split in two subsets: one for training and\n# one for testing. For the sake of simplicity and reducing the computational\n# cost, we select a subset of 7 topics and use the training set only.\n\nfrom sklearn.datasets import fetch_20newsgroups\n\ncategories = [\n    \"alt.atheism\",\n    \"comp.graphics\",\n    \"comp.sys.ibm.pc.hardware\",\n    \"misc.forsale\",\n    \"rec.autos\",\n    \"sci.space\",\n    \"talk.religion.misc\",\n]\n\nprint(\"Loading 20 newsgroups training data\")\nraw_data, _ = fetch_20newsgroups(subset=\"train\", categories=categories, return_X_y=True)\ndata_size_mb = sum(len(s.encode(\"utf-8\")) for s in raw_data) / 1e6\nprint(f\"{len(raw_data)} documents - {data_size_mb:.3f}MB\")\n\n# %%\n# Define preprocessing functions\n# ------------------------------\n#\n# A token may be a word, part of a word or anything comprised between spaces or\n# symbols in a string. Here we define a function that extracts the tokens using\n# a simple regular expression (regex) that matches Unicode word characters. This\n# includes most characters that can be part of a word in any language, as well\n# as numbers and the underscore:\n\nimport re\n\n\ndef tokenize(doc):\n    \"\"\"Extract tokens from doc.\n\n    This uses a simple regex that matches word characters to break strings\n    into tokens. For a more principled approach, see CountVectorizer or\n    TfidfVectorizer.\n    \"\"\"\n    return (tok.lower() for tok in re.findall(r\"\\w+\", doc))\n\n\nlist(tokenize(\"This is a simple example, isn't it?\"))",
                "filename": "examples/text/plot_hashing_vs_dict_vectorizer.py",
                "start_index": 0,
                "end_index": 2997,
                "start_line": 1,
                "end_line": 83,
                "max_line": 385,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "t_count_vectorizers[\"speed\"].append(data_size_mb / duration)\nprint(f\"done in {duration:.3f} s at {data_size_mb / duration:.1f} MB/s\")\n\n# %%\n# We can observe that this is the fastest text tokenization strategy so far,\n# assuming that the downstream machine learning task can tolerate a few\n# collisions.\n#\n# TfidfVectorizer\n# ---------------\n#\n# In a large text corpus, some words appear with higher frequency (e.g. \u201cthe\u201d,\n# \u201ca\u201d, \u201cis\u201d in English) and do not carry meaningful information about the actual\n# contents of a document. If we were to feed the word count data directly to a\n# classifier, those very common terms would shadow the frequencies of rarer yet\n# more informative terms. In order to re-weight the count features into floating\n# point values suitable for usage by a classifier it is very common to use the\n# tf\u2013idf transform as implemented by the\n# :func:`~sklearn.feature_extraction.text.TfidfTransformer`. TF stands for\n# \"term-frequency\" while \"tf\u2013idf\" means term-frequency times inverse\n# document-frequency.\n#\n# We now benchmark the :func:`~sklearn.feature_extraction.text.TfidfVectorizer`,\n# which is equivalent to combining the tokenization and occurrence counting of\n# the :func:`~sklearn.feature_extraction.text.CountVectorizer` along with the\n# normalizing and weighting from a\n# :func:`~sklearn.feature_extraction.text.TfidfTransformer`.\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nt0 = time()\nvectorizer = TfidfVectorizer()\nvectorizer.fit_transform(raw_data)\nduration = time() - t0\ndict_count_vectorizers[\"vectorizer\"].append(vectorizer.__class__.__name__)\ndict_count_vectorizers[\"speed\"].append(data_size_mb / duration)\nprint(f\"done in {duration:.3f} s at {data_size_mb / duration:.1f} MB/s\")\nprint(f\"Found {len(vectorizer.get_feature_names_out())} unique terms\")\n\n# %%\n# Summary\n# -------\n# Let's conclude this notebook by summarizing all the recorded processing speeds\n# in a single plot:\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\ny_pos = np.arange(len(dict_count_vectorizers[\"vectorizer\"]))\nax.barh(y_pos, dict_count_vectorizers[\"speed\"], align=\"center\")\nax.set_yticks(y_pos)\nax.set_yticklabels(dict_count_vectorizers[\"vectorizer\"])\nax.invert_yaxis()\n_ = ax.set_xlabel(\"speed (MB/s)\")\n\n# %%\n# Notice from the plot that\n# :func:`~sklearn.feature_extraction.text.TfidfVectorizer` is slightly slower\n# than :func:`~sklearn.feature_extraction.text.CountVectorizer` because of the\n# extra operation induced by the\n# :func:`~sklearn.feature_extraction.text.TfidfTransformer`.\n#\n# Also notice that, by setting the number of features `n_features = 2**18`, the\n# :func:`~sklearn.feature_extraction.text.HashingVectorizer` performs better\n# than the :func:`~sklearn.feature_extraction.text.CountVectorizer` at the\n# expense of inversibility of the transformation due to hash collisions.\n#\n# We highlight that :func:`~sklearn.feature_extraction.text.CountVectorizer` and\n# :func:`~sklearn.f",
                "filename": "examples/text/plot_hashing_vs_dict_vectorizer.py",
                "start_index": 11837,
                "end_index": 14766,
                "start_line": 133,
                "end_line": 383,
                "max_line": 385,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "ax.set_yticks(y_pos)\nax.set_yticklabels(dict_count_vectorizers[\"vectorizer\"])\nax.invert_yaxis()\n_ = ax.set_xlabel(\"speed (MB/s)\")\n\n# %%\n# In both cases :func:`~sklearn.feature_extraction.FeatureHasher` is\n# approximately twice as fast as\n# :func:`~sklearn.feature_extraction.DictVectorizer`. This is handy when dealing\n# with large amounts of data, with the downside of losing the invertibility of\n# the transformation, which in turn makes the interpretation of a model a more\n# complex task.\n#\n# The `FeatureHeasher` with `input_type=\"string\"` is slightly faster than the\n# variant that works on frequency dict because it does not count repeated\n# tokens: each token is implicitly counted once, even if it was repeated.\n# Depending on the downstream machine learning task, it can be a limitation or\n# not.\n#\n# Comparison with special purpose text vectorizers\n# ------------------------------------------------\n#\n# :func:`~sklearn.feature_extraction.text.CountVectorizer` accepts raw data as\n# it internally implements tokenization and occurrence counting. It is similar\n# to the :func:`~sklearn.feature_extraction.DictVectorizer` when used along with\n# the customized function `token_freqs` as done in the previous section. The\n# difference being that :func:`~sklearn.feature_extraction.text.CountVectorizer`\n# is more flexible. In particular it accepts various regex patterns through the\n# `token_pattern` parameter.\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nt0 = time()\nvectorizer = CountVectorizer()\nvectorizer.fit_transform(raw_data)\nduration = time() - t0\ndict_count_vectorizers[\"vectorizer\"].append(vectorizer.__class__.__name__)\ndict_count_vectorizers[\"speed\"].append(data_size_mb / duration)\nprint(f\"done in {duration:.3f} s at {data_size_mb / duration:.1f} MB/s\")\nprint(f\"Found {len(vectorizer.get_feature_names_out())} unique terms\")\n\n# %%\n# We see that using the :func:`~sklearn.feature_extraction.text.CountVectorizer`\n# implementation is approximately twice as fast as using the\n# :func:`~sklearn.feature_extraction.DictVectorizer` along with the simple\n# function we defined for mapping the tokens. The reason is that\n# :func:`~sklearn.feature_extraction.text.CountVectorizer` is optimized by\n# reusing a compiled regular expression for the full training set instead of\n# creating one per document as done in our naive tokenize function.\n#\n# Now we make a similar experiment with the\n# :func:`~sklearn.feature_extraction.text.HashingVectorizer`, which is\n# equivalent to combining the \u201chashing trick\u201d implemented by the\n# :func:`~sklearn.feature_extraction.FeatureHasher` class and the text\n# preprocessing and tokenization of the\n# :func:`~sklearn.feature_extraction.text.CountVectorizer`.\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\nt0 = time()\nvectorizer = HashingVectorizer(n_features=2**18)\nvectorizer.fit_transform(raw_data)\nduration = time() - t0\ndict_count_vectorizers[\"vectorizer\"].append(vectorizer.__class__.__name__)\ndic",
                "filename": "examples/text/plot_hashing_vs_dict_vectorizer.py",
                "start_index": 8850,
                "end_index": 11837,
                "start_line": 250,
                "end_line": 364,
                "max_line": 385,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "\"\"\"\n\nTo run this benchmark, you will need,\n\n * scikit-learn\n * pandas\n * memory_profiler\n * psutil (optional, but recommended)\n\n\"\"\"\nimport itertools\nimport timeit\n\nimport numpy as np\nimport pandas as pd\nfrom memory_profiler import memory_usage\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import (\n    CountVectorizer,\n    HashingVectorizer,\n    TfidfVectorizer,\n)\n\nn_repeat = 3\n\n\ndef run_vectorizer(Vectorizer, X, **params):\n    def f():\n        vect = Vectorizer(**params)\n        vect.fit_transform(X)\n\n    return f\n\n\ntext = fetch_20newsgroups(subset=\"train\").data[:1000]\n\nprint(\"=\" * 80 + \"\\n#\" + \"    Text vectorizers benchmark\" + \"\\n\" + \"=\" * 80 + \"\\n\")\nprint(\"Using a subset of the 20 newsgroups dataset ({} documents).\".format(len(text)))\nprint(\"This benchmarks runs in ~1 min ...\")\n\nres = []\n\nfor Vectorizer, (analyzer, ngram_range) in itertools.product(\n    [CountVectorizer, TfidfVectorizer, HashingVectorizer],\n    [(\"word\", (1, 1)), (\"word\", (1, 2)), (\"char\", (4, 4)), (\"char_wb\", (4, 4))],\n):\n    bench = {\"vectorizer\": Vectorizer.__name__}\n    params = {\"analyzer\": analyzer, \"ngram_range\": ngram_range}\n    bench.update(params)\n    dt = timeit.repeat(\n        run_vectorizer(Vectorizer, text, **params), number=1, repeat=n_repeat\n    )\n    bench[\"time\"] = \"{:.3f} (+-{:.3f})\".format(np.mean(dt), np.std(dt))\n\n    mem_usage = memory_usage(run_vectorizer(Vectorizer, text, **params))\n\n    bench[\"memory\"] = \"{:.1f}\".format(np.max(mem_usage))\n\n    res.append(bench)\n\n\ndf = pd.DataFrame(res).set_index([\"analyzer\", \"ngram_range\", \"vectorizer\"])\n\nprint(\"\\n========== Run time performance (sec) ===========\\n\")\nprint(\n    \"Computing the mean and the standard deviation \"\n    \"of the run time over {} runs...\\n\".format(n_repeat)\n)\nprint(df[\"time\"].unstack(level=-1))\n\nprint(\"\\n=============== Memory usage (MB) ===============\\n\")\nprint(df[\"memory\"].unstack(level=-1))",
                "filename": "benchmarks/bench_text_vectorizers.py",
                "start_index": 0,
                "end_index": 1918,
                "start_line": 1,
                "end_line": 73,
                "max_line": 73,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "@ignore_warnings\ndef check_nonsquare_error(name, estimator_orig):\n    \"\"\"Test that error is thrown when non-square data provided.\"\"\"\n\n    X, y = make_blobs(n_samples=20, n_features=10)\n    estimator = clone(estimator_orig)\n\n    with raises(\n        ValueError,\n        err_msg=(\n            f\"The pairwise estimator {name} does not raise an error on non-square data\"\n        ),\n    ):\n        estimator.fit(X, y)\n\n\n@ignore_warnings\ndef check_estimators_pickle(name, estimator_orig, readonly_memmap=False):\n    \"\"\"Test that we can pickle all estimators.\"\"\"\n    check_methods = [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]\n\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n\n    X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n\n    tags = _safe_tags(estimator_orig)\n    # include NaN values when the estimator should deal with them\n    if tags[\"allow_nan\"]:\n        # set randomly 10 elements to np.nan\n        rng = np.random.RandomState(42)\n        mask = rng.choice(X.size, 10, replace=False)\n        X.reshape(-1)[mask] = np.nan\n\n    estimator = clone(estimator_orig)\n\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    set_random_state(estimator)\n    estimator.fit(X, y)\n\n    if readonly_memmap:\n        unpickled_estimator = create_memmap_backed_data(estimator)\n    else:\n        # pickle and unpickle!\n        pickled_estimator = pickle.dumps(estimator)\n        module_name = estimator.__module__\n        if module_name.startswith(\"sklearn.\") and not (\n            \"test_\" in module_name or module_name.endswith(\"_testing\")\n        ):\n            # strict check for sklearn estimators that are not implemented in test\n            # modules.\n            assert b\"version\" in pickled_estimator\n        unpickled_estimator = pickle.loads(pickled_estimator)\n\n    result = dict()\n    for method in check_methods:\n        if hasattr(estimator, method):\n            result[method] = getattr(estimator, method)(X)\n\n    for method in result:\n        unpickled_result = getattr(unpickled_estimator, method)(X)\n        assert_allclose_dense_sparse(result[method], unpickled_result)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 70115,
                "end_index": 72342,
                "start_line": 181,
                "end_line": 2113,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "# Here we slice the pipeline to include all the steps but the last one. The output\n# feature names of this pipeline slice are the features put into logistic\n# regression. These names correspond directly to the coefficients in the logistic\n# regression:\nimport pandas as pd\n\nlog_reg_input_features = log_reg[:-1].get_feature_names_out()\npd.Series(log_reg[-1].coef_.ravel(), index=log_reg_input_features).plot.bar()\nplt.tight_layout()\n\n\n# %%\n# Grouping infrequent categories in :class:`~preprocessing.OneHotEncoder`\n# -----------------------------------------------------------------------\n# :class:`~preprocessing.OneHotEncoder` supports aggregating infrequent\n# categories into a single output for each feature. The parameters to enable\n# the gathering of infrequent categories are `min_frequency` and\n# `max_categories`. See the :ref:`User Guide <encoder_infrequent_categories>`\n# for more details.\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\nX = np.array(\n    [[\"dog\"] * 5 + [\"cat\"] * 20 + [\"rabbit\"] * 10 + [\"snake\"] * 3], dtype=object\n).T\nenc = OneHotEncoder(min_frequency=6, sparse_output=False).fit(X)\nenc.infrequent_categories_\n\n# %%\n# Since dog and snake are infrequent categories, they are grouped together when\n# transformed:\nencoded = enc.transform(np.array([[\"dog\"], [\"snake\"], [\"cat\"], [\"rabbit\"]]))\npd.DataFrame(encoded, columns=enc.get_feature_names_out())\n\n# %%\n# Performance improvements\n# ------------------------\n# Reductions on pairwise distances for dense float64 datasets has been refactored\n# to better take advantage of non-blocking thread parallelism. For example,\n# :meth:`neighbors.NearestNeighbors.kneighbors` and\n# :meth:`neighbors.NearestNeighbors.radius_neighbors` can respectively be up to \u00d720 and\n# \u00d75 faster than previously. In summary, the following functions and estimators\n# now benefit from improved performance:\n#\n# - :func:`metrics.pairwise_distances_argmin`\n# - :func:`metrics.pairwise_distances_argmin_min`\n# - :class:`cluster.AffinityPropagation`\n# - :class:`cluster.Birch`\n# - :class:`cluster.MeanShift`\n# - :class:`cluster.OPTICS`\n# - :class:`cluster.SpectralClustering`\n# - :func:`feature_selection.mutual_info_regression`\n# - :class:`neighbors.KNeighborsClassifier`\n# - :class:`neighbors.KNeighborsRegressor`\n# - :class:`neighbors.RadiusNeighborsClassifier`\n# - :class:`neighbors.RadiusNeighborsRegressor`\n# - :class:`neighbors.LocalOutlierFactor`\n# - :class:`neighbors.NearestNeighbors`\n# - :class:`manifold.Isomap`\n# - :class:`manifold.LocallyLinearEmbedding`\n# - :class:`manifold.TSNE`\n# - :func:`manifold.trustworthiness`\n# - :class:`semi_supervised.LabelPropagation`\n# - :class:`semi_supervised.LabelSpreading`\n#\n# To know more about the technical details of this work, you can read\n# `this suite of blog posts <https://blog.scikit-learn.org/technical/performances/>`_.\n#\n# Moreover, the computation of loss functions has been refactored using\n# Cython resulting in performance improvements for the following estimators:\n#\n#",
                "filename": "examples/release_highlights/plot_release_highlights_1_1_0.py",
                "start_index": 2955,
                "end_index": 5955,
                "start_line": 92,
                "end_line": 210,
                "max_line": 229,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "# %%\n# We define an additional function that counts the (frequency of) occurrence of\n# each token in a given document. It returns a frequency dictionary to be used\n# by the vectorizers.\n\nfrom collections import defaultdict\n\n\ndef token_freqs(doc):\n    \"\"\"Extract a dict mapping tokens from doc to their occurrences.\"\"\"\n\n    freq = defaultdict(int)\n    for tok in tokenize(doc):\n        freq[tok] += 1\n    return freq\n\n\ntoken_freqs(\"That is one example, but this is another one\")\n\n# %%\n# Observe in particular that the repeated token `\"is\"` is counted twice for\n# instance.\n#\n# Breaking a text document into word tokens, potentially losing the order\n# information between the words in a sentence is often called a `Bag of Words\n# representation <https://en.wikipedia.org/wiki/Bag-of-words_model>`_.\n\n# %%\n# DictVectorizer\n# --------------\n#\n# First we benchmark the :func:`~sklearn.feature_extraction.DictVectorizer`,\n# then we compare it to :func:`~sklearn.feature_extraction.FeatureHasher` as\n# both of them receive dictionaries as input.\n\nfrom time import time\n\nfrom sklearn.feature_extraction import DictVectorizer\n\ndict_count_vectorizers = defaultdict(list)\n\nt0 = time()\nvectorizer = DictVectorizer()\nvectorizer.fit_transform(token_freqs(d) for d in raw_data)\nduration = time() - t0\ndict_count_vectorizers[\"vectorizer\"].append(\n    vectorizer.__class__.__name__ + \"\\non freq dicts\"\n)\ndict_count_vectorizers[\"speed\"].append(data_size_mb / duration)\nprint(f\"done in {duration:.3f} s at {data_size_mb / duration:.1f} MB/s\")\nprint(f\"Found {len(vectorizer.get_feature_names_out())} unique terms\")\n\n# %%\n# The actual mapping from text token to column index is explicitly stored in\n# the `.vocabulary_` attribute which is a potentially very large Python\n# dictionary:\ntype(vectorizer.vocabulary_)\n\n# %%\nlen(vectorizer.vocabulary_)\n\n# %%\nvectorizer.vocabulary_[\"example\"]\n\n# %%\n# FeatureHasher\n# -------------\n#\n# Dictionaries take up a large amount of storage space and grow in size as the\n# training set grows. Instead of growing the vectors along with a dictionary,\n# feature hashing builds a vector of pre-defined length by applying a hash\n# function `h` to the features (e.g., tokens), then using the hash values\n# directly as feature indices and updating the resulting vector at those\n# indices. When the feature space is not large enough, hashing functions tend to\n# map distinct values to the same hash code (hash collisions). As a result, it\n# is impossible to determine what object generated any particular hash code.\n#\n# Because of the above it is impossible to recover the original tokens from the\n# feature matrix and the best approach to estimate the number of unique terms in\n# the original dictionary is to count the number of active columns in the\n# encoded feature matrix. For such a purpose we define the following function:\n\nimport numpy as np",
                "filename": "examples/text/plot_hashing_vs_dict_vectorizer.py",
                "start_index": 2999,
                "end_index": 5857,
                "start_line": 34,
                "end_line": 167,
                "max_line": 385,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "- type: textarea\n  attributes:\n    label: Actual Results\n    description: |\n      Please paste or describe the results you observe instead of the expected results. If you observe an error, please paste the error message including the **full traceback** of the exception. For instance the code above raises the following exception:\n\n      ```python-traceback\n      ---------------------------------------------------------------------------\n      TypeError                                 Traceback (most recent call last)\n      <ipython-input-1-a674e682c281> in <module>\n            4 vectorizer = CountVectorizer(input=docs, analyzer='word')\n            5 lda_features = vectorizer.fit_transform(docs)\n      ----> 6 lda_model = LatentDirichletAllocation(\n            7     n_topics=10,\n            8     learning_method='online',\n\n      TypeError: __init__() got an unexpected keyword argument 'n_topics'\n      ```\n    placeholder: >\n      Please paste or specifically describe the actual output or traceback.\n  validations:\n    required: true\n- type: textarea\n  attributes:\n    label: Versions\n    render: shell\n    description: |\n      Please run the following and paste the output below.\n      ```python\n      import sklearn; sklearn.show_versions()\n      ```\n  validations:\n    required: true\n- type: markdown\n  attributes:\n    value: >\n      Thanks for contributing \ud83c\udf89!",
                "filename": ".github/ISSUE_TEMPLATE/bug_report.yml",
                "start_index": 2813,
                "end_index": 4187,
                "start_line": 11,
                "end_line": 95,
                "max_line": 95,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 1.0
            },
            {
                "code": "from sklearn.pipeline import make_pipeline\n\nX, y = make_classification(random_state=0)\n\nwith TemporaryDirectory(prefix=\"sklearn_cache_\") as tmpdir:\n    estimator = make_pipeline(\n        KNeighborsTransformer(n_neighbors=10, mode=\"distance\"),\n        Isomap(n_neighbors=10, metric=\"precomputed\"),\n        memory=tmpdir,\n    )\n    estimator.fit(X)\n\n    # We can decrease the number of neighbors and the graph will not be\n    # recomputed.\n    estimator.set_params(isomap__n_neighbors=5)\n    estimator.fit(X)\n\n# %%\n# KNN Based Imputation\n# ------------------------------------\n# We now support imputation for completing missing values using k-Nearest\n# Neighbors.\n#\n# Each sample's missing values are imputed using the mean value from\n# ``n_neighbors`` nearest neighbors found in the training set. Two samples are\n# close if the features that neither is missing are close.\n# By default, a euclidean distance metric\n# that supports missing values,\n# :func:`~sklearn.metrics.pairwise.nan_euclidean_distances`, is used to find the nearest\n# neighbors.\n#\n# Read more in the :ref:`User Guide <knnimpute>`.\n\nfrom sklearn.impute import KNNImputer\n\nX = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\nimputer = KNNImputer(n_neighbors=2)\nprint(imputer.fit_transform(X))\n\n# %%\n# Tree pruning\n# ------------\n#\n# It is now possible to prune most tree-based estimators once the trees are\n# built. The pruning is based on minimal cost-complexity. Read more in the\n# :ref:`User Guide <minimal_cost_complexity_pruning>` for details.\n\nX, y = make_classification(random_state=0)\n\nrf = RandomForestClassifier(random_state=0, ccp_alpha=0).fit(X, y)\nprint(\n    \"Average number of nodes without pruning {:.1f}\".format(\n        np.mean([e.tree_.node_count for e in rf.estimators_])\n    )\n)\n\nrf = RandomForestClassifier(random_state=0, ccp_alpha=0.05).fit(X, y)\nprint(\n    \"Average number of nodes with pruning {:.1f}\".format(\n        np.mean([e.tree_.node_count for e in rf.estimators_])\n    )\n)\n\n# %%\n# Retrieve dataframes from OpenML\n# -------------------------------\n# :func:`datasets.fetch_openml` can now return pandas dataframe and thus\n# properly handle datasets with heterogeneous data:\n\nfrom sklearn.datasets import fetch_openml\n\ntitanic = fetch_openml(\"titanic\", version=1, as_frame=True, parser=\"pandas\")\nprint(titanic.data.head()[[\"pclass\", \"embarked\"]])\n\n# %%\n# Checking scikit-learn compatibility of an estimator\n# ---------------------------------------------------\n# Developers can check the compatibility of their scikit-learn compatible\n# estimators using :func:`~utils.estimator_checks.check_estimator`. For\n# instance, the ``check_estimator(LinearSVC())`` passes.\n#\n# We now provide a ``pytest`` specific decorator which allows ``pytest``\n# to run all checks independently and report the checks that are failing.\n#\n# ..note::\n#   This entry was slightly updated in version 0.24, where passing classes\n#   isn't supported anymore: pass instances instead.",
                "filename": "examples/release_highlights/plot_release_highlights_0_22_0.py",
                "start_index": 5945,
                "end_index": 8900,
                "start_line": 85,
                "end_line": 248,
                "max_line": 282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "- type: markdown\n  attributes:\n    value: >\n      #### Before submitting a bug, please make sure the issue hasn't been already\n      addressed by searching through [the past issues](https://github.com/scikit-learn/scikit-learn/issues).\n- type: textarea\n  attributes:\n    label: Describe the bug\n    description: >\n      A clear and concise description of what the bug is.\n  validations:\n    required: true\n- type: textarea\n  attributes:\n    label: Steps/Code to Reproduce\n    description: |\n      Please add a [minimal code example](https://scikit-learn.org/dev/developers/minimal_reproducer.html) that can reproduce the error when running it. Be as succinct as possible, **do not depend on external data files**: instead you can generate synthetic data using `numpy.random`, [sklearn.datasets.make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html), [sklearn.datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) or a few lines of Python code. Example:\n\n      ```python\n      from sklearn.feature_extraction.text import CountVectorizer\n      from sklearn.decomposition import LatentDirichletAllocation\n      docs = [\"Help I have a bug\" for i in range(1000)]\n      vectorizer = CountVectorizer(input=docs, analyzer='word')\n      lda_features = vectorizer.fit_transform(docs)\n      lda_model = LatentDirichletAllocation(\n          n_topics=10,\n          learning_method='online',\n          evaluate_every=10,\n          n_jobs=4,\n      )\n      model = lda_model.fit(lda_features)\n      ```\n\n      If the code is too long, feel free to put it in a public gist and link it in the issue: https://gist.github.com.\n\n      In short, **we are going to copy-paste your code** to run it and we expect to get the same result as you.\n\n      We acknowledge that crafting a [minimal reproducible code example](https://scikit-learn.org/dev/developers/minimal_reproducer.html) requires some effort on your side but it really helps the maintainers quickly reproduce the problem and analyze its cause without any ambiguity. Ambiguous bug reports tend to be slower to fix because they will require more effort and back and forth discussion between the maintainers and the reporter to pin-point the precise conditions necessary to reproduce the problem.\n    placeholder: |\n      ```\n      Sample code to reproduce the problem\n      ```\n  validations:\n    required: true\n- type: textarea\n  attributes:\n    label: Expected Results\n    description: >\n      Please paste or describe the expected results.\n    placeholder: >\n      Example: No error is thrown.\n  validations:\n    required: true",
                "filename": ".github/ISSUE_TEMPLATE/bug_report.yml",
                "start_index": 126,
                "end_index": 2812,
                "start_line": 6,
                "end_line": 91,
                "max_line": 95,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": "",
                "context_relevance": 1.0
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sklearn/utils/estimator_checks.py": [
                {
                    "chunk": {
                        "code": "@ignore_warnings\ndef check_nonsquare_error(name, estimator_orig):\n    \"\"\"Test that error is thrown when non-square data provided.\"\"\"\n\n    X, y = make_blobs(n_samples=20, n_features=10)\n    estimator = clone(estimator_orig)\n\n    with raises(\n        ValueError,\n        err_msg=(\n            f\"The pairwise estimator {name} does not raise an error on non-square data\"\n        ),\n    ):\n        estimator.fit(X, y)\n\n\n@ignore_warnings\ndef check_estimators_pickle(name, estimator_orig, readonly_memmap=False):\n    \"\"\"Test that we can pickle all estimators.\"\"\"\n    check_methods = [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]\n\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n\n    X = _enforce_estimator_tags_X(estimator_orig, X, kernel=rbf_kernel)\n\n    tags = _safe_tags(estimator_orig)\n    # include NaN values when the estimator should deal with them\n    if tags[\"allow_nan\"]:\n        # set randomly 10 elements to np.nan\n        rng = np.random.RandomState(42)\n        mask = rng.choice(X.size, 10, replace=False)\n        X.reshape(-1)[mask] = np.nan\n\n    estimator = clone(estimator_orig)\n\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    set_random_state(estimator)\n    estimator.fit(X, y)\n\n    if readonly_memmap:\n        unpickled_estimator = create_memmap_backed_data(estimator)\n    else:\n        # pickle and unpickle!\n        pickled_estimator = pickle.dumps(estimator)\n        module_name = estimator.__module__\n        if module_name.startswith(\"sklearn.\") and not (\n            \"test_\" in module_name or module_name.endswith(\"_testing\")\n        ):\n            # strict check for sklearn estimators that are not implemented in test\n            # modules.\n            assert b\"version\" in pickled_estimator\n        unpickled_estimator = pickle.loads(pickled_estimator)\n\n    result = dict()\n    for method in check_methods:\n        if hasattr(estimator, method):\n            result[method] = getattr(estimator, method)(X)\n\n    for method in result:\n        unpickled_result = getattr(unpickled_estimator, method)(X)\n        assert_allclose_dense_sparse(result[method], unpickled_result)",
                        "filename": "sklearn/utils/estimator_checks.py",
                        "start_index": 70115,
                        "end_index": 72342,
                        "start_line": 181,
                        "end_line": 2113,
                        "max_line": 4639,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the 'check_estimators_pickle' function which is used to test if estimators can be pickled. Since the issue is related to pickling a tokenizer, this function may need to be updated to handle the lambda pickling issue."
                }
            ]
        },
        "solution_task": "- Replace the use of the `pickle` module with `cloudpickle` or `dill` for serializing the `tokenizer` object which contains a `lambda` expression.\n- Install `cloudpickle` or `dill` if not already installed.\n- Change the import statement from `import pickle` to `import cloudpickle as pickle` or `import dill as pickle`.\n- Ensure that the rest of the code remains unchanged, as `cloudpickle` and `dill` are drop-in replacements for `pickle` in most cases.",
        "bouncer_response": {
            "score": 8,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant hints and solutions that can directly lead to resolving the issues outlined in the PROMPT.",
            "supporting_evidence": "The RESPONSE provides a direct solution to the problem described in the PROMPT by suggesting the use of `cloudpickle` or `dill` as alternatives to the `pickle` module for serializing objects that contain `lambda` expressions. This advice is actionable and relevant, as it addresses the specific issue of the inability to pickle the `tokenizer` object due to the presence of a `lambda`. The RESPONSE also includes instructions to install `cloudpickle` or `dill` if they are not already installed and to change the import statement accordingly, which is practical advice for someone encountering this issue. Additionally, the RESPONSE provides a link to a code snippet related to pickling estimators, which could be useful for further investigation or for understanding related pickling issues in the scikit-learn codebase. However, the RESPONSE does not address the proposed fixes mentioned in the PROMPT, such as updating the FAQ or removing the use of lambdas, which could be considered for a more comprehensive solution.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711739203.451689,
        "result": "- Replace the use of the `pickle` module with `cloudpickle` or `dill` for serializing the `tokenizer` object which contains a `lambda` expression.\n- Install `cloudpickle` or `dill` if not already installed.\n- Change the import statement from `import pickle` to `import cloudpickle as pickle` or `import dill as pickle`.\n- Ensure that the rest of the code remains unchanged, as `cloudpickle` and `dill` are drop-in replacements for `pickle` in most cases.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn/utils)- [Lines 181 - 2113](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/estimator_checks.py#L181-L2113)\n\n This snippet contains the 'check_estimators_pickle' function which is used to test if estimators can be pickled. Since the issue is related to pickling a tokenizer, this function may need to be updated to handle the lambda pickling issue.",
        "context_relevance": 0.36000000000000004,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE must be relevant to the entire PROMPT to get a score of 9 or 10. The RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 10.\nSupporting Evidence: The RESPONSE directly addresses the issue described in the PROMPT by suggesting the use of `cloudpickle` or `dill` as a solution to the pickling problem caused by lambdas in the `CountVectorizer`. It provides a clear workaround that is relevant to the problem and also includes steps to implement the solution, which aligns with the \"Workaround\" section of the PROMPT. Additionally, the RESPONSE provides a link to a code snippet that may need to be updated in relation to the issue, showing relevance to the \"Proposed fix\" section of the PROMPT. The RESPONSE is relevant to the entire PROMPT and answers it completely, thus meriting a score of 10."
        },
        "qa_relevance": 1.0
    }
}