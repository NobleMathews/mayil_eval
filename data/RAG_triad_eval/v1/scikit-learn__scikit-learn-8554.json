{
    "id": "scikit-learn__scikit-learn-8554",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
    "task_id": 1341859939992342538,
    "title": "Isomap and LocallyLinearEmbedding do not accept sparse matrix input (contrary to documentation)",
    "body": "The [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.locally_linear_embedding.html) mentions that `sklearn.manifold.LocallyLinearEmbedding` should support sparse matrix.\r\n\r\nThe error comes from the 5 [occurences](https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/manifold/locally_linear.py#L629) of `check_array` from `sklearn.utils.validation`.\r\n\r\nIf documentation is correct `check_array` should be called with `accept_sparse=True`\r\n[`Check array input`](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py#L269)\r\n\r\nI can submit a PR.\r\n\r\n`Isomap` also accepts sparse matrix according to documentation on `fit` and `fit_transform` methods.\r\nGiven that `SpectralEmbedding` also uses the arpack solver, I guess that it also should accept sparse matrices.\r\n\r\n* Check of check_array calls in the manifold subfolder\r\n```bash\r\n/usr/lib/python3.6/site-packages/sklearn/manifold  $  grep 'check_array' *.py -n\r\nisomap.py:9:from ..utils import check_array\r\nisomap.py:103:        X = check_array(X)\r\nisomap.py:202:        X = check_array(X)\r\nlocally_linear.py:11:from ..utils import check_random_state, check_array\r\nlocally_linear.py:42:    X = check_array(X, dtype=FLOAT_DTYPES)\r\nlocally_linear.py:43:    Z = check_array(Z, dtype=FLOAT_DTYPES, allow_nd=True)\r\nlocally_linear.py:629:        X = check_array(X, dtype=float)\r\nlocally_linear.py:688:        X = check_array(X)\r\nmds.py:14:from ..utils import check_random_state, check_array, check_symmetric\r\nmds.py:229:    similarities = check_array(similarities)\r\nmds.py:394:        X = check_array(X)\r\nspectral_embedding_.py:14:from ..utils import check_random_state, check_array, check_symmetric\r\nspectral_embedding_.py:280:        laplacian = check_array(laplacian, dtype=np.float64,\r\nspectral_embedding_.py:283:        ml = smoothed_aggregation_solver(check_array(laplacian, 'csr'))\r\nspectral_embedding_.py:295:        laplacian = check_array(laplacian, dtype=np.float64,\r\nspectral_embedding_.py:472:        X = check_array(X, ensure_min_samples=2, estimator=self)\r\nt_sne.py:18:from ..utils import check_array\r\nt_sne.py:706:            X = check_array(X, accept_sparse=['csr', 'csc', 'coo'],\r\n```\r\n\r\n* For reference, my backtrace\r\n```python\r\nInput training data has shape:  (49352, 15)\r\nInput test data has shape:      (74659, 14)\r\n....\r\n....\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 108, in <module>\r\n    X, X_test, y, tr_pipeline, select_feat, cache_file)\r\n  File \"/home/ml/machinelearning_projects/Kaggle_Compet/Renthop_Apartment_interest/src/preprocessing.py\", line 13, in preprocessing\r\n    x_trn, x_val, x_test = feat_selection(select_feat, x_trn, x_val, X_test)\r\n  File \"/home/ml/machinelearning_projects/Kaggle_Compet/Renthop_Apartment_interest/src/star_command.py\", line 61, in feat_selection\r\n    trn, val, tst = zip_with(_concat_col, tuples_trn_val_test)\r\n  File \"/home/ml/machinelearning_projects/Kaggle_Compet/Renthop_Apartment_interest/src/star_command.py\", line 23, in zip_with\r\n    return starmap(f, zip(*list_of_tuple))\r\n  File \"/home/ml/machinelearning_projects/Kaggle_Compet/Renthop_Apartment_interest/src/star_command.py\", line 76, in _feat_transfo\r\n    trn = Transformer.fit_transform(train[sCol])\r\n  File \"/usr/lib/python3.6/site-packages/sklearn/pipeline.py\", line 303, in fit_transform\r\n    return last_step.fit_transform(Xt, y, **fit_params)\r\n  File \"/usr/lib/python3.6/site-packages/sklearn/manifold/locally_linear.py\", line 666, in fit_transform\r\n    self._fit_transform(X)\r\n  File \"/usr/lib/python3.6/site-packages/sklearn/manifold/locally_linear.py\", line 629, in _fit_transform\r\n    X = check_array(X, dtype=float)\r\n  File \"/usr/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 380, in check_array\r\n    force_all_finite)\r\n  File \"/usr/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 243, in _ensure_sparse_format\r\n    raise TypeError('A sparse matrix was passed, but dense '\r\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\r\n```\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.20.git",
    "requested_commit": "",
    "mayil_response": "- Review the usage of `check_array` in `sklearn/manifold/locally_linear.py` and `sklearn/manifold/isomap.py`.\n- Ensure that `check_array` is called with `accept_sparse='csr'` or `accept_sparse=True` if the documentation states that `LocallyLinearEmbedding` and `Isomap` support sparse matrices.\n- Modify the calls to `check_array` in the `fit` and `fit_transform` methods of `LocallyLinearEmbedding` and `Isomap` to include `accept_sparse='csr'` as an argument if sparse input is indeed supported.\n- Example modification if sparse matrices are supported:\n  ```python\n  # In sklearn/manifold/locally_linear.py\n  def _fit_transform(self, X):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n\n  # In sklearn/manifold/isomap.py\n  def fit(self, X, y=None):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n\n  def fit_transform(self, X, y=None):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n  ```\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/utils)- [Lines 647 - 2272](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L647-L2272)\n\n This snippet contains the definition of the check_array function, which is central to the issue as it needs to be called with accept_sparse=True according to the issue description. \n\n\n   - [Lines 882 - 2278](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L882-L2278)\n\n This snippet shows the usage of check_array with a sparse matrix, which is relevant to the issue as it needs to ensure that the function is called correctly for sparse matrices. \n\n\n   - [Lines 460 - 2272](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L460-L2272)\n\n This snippet defines the _ensure_sparse_format function, which is called by check_array when a sparse matrix is passed. It is relevant to understand how sparse matrices are being handled. \n\n\n   - [Lines 534 - 581](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L534-L581)\n\n This snippet is part of the check_array function's logic for handling sparse matrices and is relevant to the issue as it includes the error message that is raised when a sparse matrix is not accepted.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.000208,
        "snippet_processor": 0.03336,
        "issue_star_creation": 0.03149,
        "issue_star_solver": 0.07856,
        "bouncer": 0.03409
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711742632.499061,
        "relevant_snippets": [
            {
                "code": "def check_array_api_input_and_values(\n    name,\n    estimator_orig,\n    array_namespace,\n    device=None,\n    dtype=\"float64\",\n):\n    return check_array_api_input(\n        name,\n        estimator_orig,\n        array_namespace=array_namespace,\n        device=device,\n        dtype=dtype,\n        check_values=True,\n    )\n\n\ndef check_estimator_sparse_data(name, estimator_orig):\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(40, 3))\n    X[X < 0.8] = 0\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    X_csr = sparse.csr_matrix(X)\n    y = (4 * rng.uniform(size=40)).astype(int)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n    tags = _safe_tags(estimator_orig)\n    for matrix_format, X in _generate_sparse_matrix(X_csr):\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n            if name in [\"Scaler\", \"StandardScaler\"]:\n                estimator.set_params(with_mean=False)\n        # fit and predict\n        if \"64\" in matrix_format:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to support {matrix_format} \"\n                \"matrix, and is not failing gracefully, e.g. by using \"\n                \"check_array(X, accept_large_sparse=False)\"\n            )\n        else:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to fail gracefully on sparse \"\n                \"data: error message should state explicitly that sparse \"\n                \"input is not supported if this is not the case.\"\n            )\n        with raises(\n            (TypeError, ValueError),\n            match=[\"sparse\", \"Sparse\"],\n            may_pass=True,\n            err_msg=err_msg,\n        ):\n            with ignore_warnings(category=FutureWarning):\n                estimator.fit(X, y)\n            if hasattr(estimator, \"predict\"):\n                pred = estimator.predict(X)\n                if tags[\"multioutput_only\"]:\n                    assert pred.shape == (X.shape[0], 1)\n                else:\n                    assert pred.shape == (X.shape[0],)\n            if hasattr(estimator, \"predict_proba\"):\n                probs = estimator.predict_proba(X)\n                if tags[\"binary_only\"]:\n                    expected_probs_shape = (X.shape[0], 2)\n                else:\n                    expected_probs_shape = (X.shape[0], 4)\n                assert probs.shape == expected_probs_shape",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 36016,
                "end_index": 38577,
                "start_line": 1025,
                "end_line": 1093,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "if accept_sparse is False:\n        raise TypeError(\n            \"A sparse matrix was passed, but dense \"\n            \"data is required. Use X.toarray() to \"\n            \"convert to a dense numpy array.\"\n        )\n    elif isinstance(accept_sparse, (list, tuple)):\n        if len(accept_sparse) == 0:\n            raise ValueError(\n                \"When providing 'accept_sparse' \"\n                \"as a tuple or list, it must contain at \"\n                \"least one string value.\"\n            )\n        # ensure correct sparse format\n        if spmatrix.format not in accept_sparse:\n            # create new with correct sparse\n            spmatrix = spmatrix.asformat(accept_sparse[0])\n            changed_format = True\n    elif accept_sparse is not True:\n        # any other type\n        raise ValueError(\n            \"Parameter 'accept_sparse' should be a string, \"\n            \"boolean or list of strings. You provided \"\n            \"'accept_sparse={}'.\".format(accept_sparse)\n        )\n\n    if dtype != spmatrix.dtype:\n        # convert dtype\n        spmatrix = spmatrix.astype(dtype)\n    elif copy and not changed_format:\n        # force copy\n        spmatrix = spmatrix.copy()\n\n    if force_all_finite:\n        if not hasattr(spmatrix, \"data\"):\n            warnings.warn(\n                \"Can't check %s sparse matrix for nan or inf.\" % spmatrix.format,\n                stacklevel=2,\n            )\n        else:\n            _assert_all_finite(\n                spmatrix.data,\n                allow_nan=force_all_finite == \"allow-nan\",\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n\n    return spmatrix",
                "filename": "sklearn/utils/validation.py",
                "start_index": 17856,
                "end_index": 19516,
                "start_line": 534,
                "end_line": 581,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "if sp.issparse(array):\n        _ensure_no_complex_data(array)\n        array = _ensure_sparse_format(\n            array,\n            accept_sparse=accept_sparse,\n            dtype=dtype,\n            copy=copy,\n            force_all_finite=force_all_finite,\n            accept_large_sparse=accept_large_sparse,\n            estimator_name=estimator_name,\n            input_name=input_name,\n        )",
                "filename": "sklearn/utils/validation.py",
                "start_index": 30833,
                "end_index": 31229,
                "start_line": 882,
                "end_line": 2278,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.8
            },
            {
                "code": "assert array(\"i\").itemsize == 4, (\n            \"sizeof(int) != 4 on your platform; please report this at\"\n            \" https://github.com/scikit-learn/scikit-learn/issues and\"\n            \" include the output from platform.platform() in your bug report\"\n        )\n\n        dtype = self.dtype\n        if fitting:\n            feature_names = []\n            vocab = {}\n        else:\n            feature_names = self.feature_names_\n            vocab = self.vocabulary_\n\n        transforming = True\n\n        # Process everything as sparse regardless of setting\n        X = [X] if isinstance(X, Mapping) else X\n\n        indices = array(\"i\")\n        indptr = [0]\n        # XXX we could change values to an array.array as well, but it\n        # would require (heuristic) conversion of dtype to typecode...\n        values = []\n\n        # collect all the possible feature names and build sparse matrix at\n        # same time\n        for x in X:\n            for f, v in x.items():\n                if isinstance(v, str):\n                    feature_name = \"%s%s%s\" % (f, self.separator, v)\n                    v = 1\n                elif isinstance(v, Number) or (v is None):\n                    feature_name = f\n                elif not isinstance(v, Mapping) and isinstance(v, Iterable):\n                    feature_name = None\n                    self._add_iterable_element(\n                        f,\n                        v,\n                        feature_names,\n                        vocab,\n                        fitting=fitting,\n                        transforming=transforming,\n                        indices=indices,\n                        values=values,\n                    )\n                else:\n                    raise TypeError(\n                        f\"Unsupported value Type {type(v)} \"\n                        f\"for {f}: {v}.\\n\"\n                        f\"{type(v)} objects are not supported.\"\n                    )\n\n                if feature_name is not None:\n                    if fitting and feature_name not in vocab:\n                        vocab[feature_name] = len(feature_names)\n                        feature_names.append(feature_name)\n\n                    if feature_name in vocab:\n                        indices.append(vocab[feature_name])\n                        values.append(self.dtype(v))\n\n            indptr.append(len(indices))\n\n        if len(indptr) == 1:\n            raise ValueError(\"Sample sequence X is empty.\")\n\n        indices = np.frombuffer(indices, dtype=np.intc)\n        shape = (len(indptr) - 1, len(vocab))\n\n        result_matrix = sp.csr_matrix(\n            (values, indices, indptr), shape=shape, dtype=dtype\n        )\n\n        # Sort everything if asked",
                "filename": "sklearn/feature_extraction/_dict_vectorizer.py",
                "start_index": 6855,
                "end_index": 9563,
                "start_line": 195,
                "end_line": 269,
                "max_line": 444,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.0
            },
            {
                "code": "def check_array(\n    array,\n    accept_sparse=False,\n    *,\n    accept_large_sparse=True,\n    dtype=\"numeric\",\n    order=None,\n    copy=False,\n    force_all_finite=True,\n    ensure_2d=True,\n    allow_nd=False,\n    ensure_min_samples=1,\n    ensure_min_features=1,\n    estimator=None,\n    input_name=\"\",\n):",
                "filename": "sklearn/utils/validation.py",
                "start_index": 21517,
                "end_index": 21821,
                "start_line": 647,
                "end_line": 2272,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.4
            },
            {
                "code": "def _ensure_sparse_format(\n    spmatrix,\n    accept_sparse,\n    dtype,\n    copy,\n    force_all_finite,\n    accept_large_sparse,\n    estimator_name=None,\n    input_name=\"\",\n):",
                "filename": "sklearn/utils/validation.py",
                "start_index": 15534,
                "end_index": 15708,
                "start_line": 460,
                "end_line": 2272,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "def _check_large_sparse(X, accept_large_sparse=False):\n    \"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\n    if not accept_large_sparse:\n        supported_indices = [\"int32\"]\n        if X.getformat() == \"coo\":\n            index_keys = [\"col\", \"row\"]\n        elif X.getformat() in [\"csr\", \"csc\", \"bsr\"]:\n            index_keys = [\"indices\", \"indptr\"]\n        else:\n            return\n        for key in index_keys:\n            indices_datatype = getattr(X, key).dtype\n            if indices_datatype not in supported_indices:\n                raise ValueError(\n                    \"Only sparse matrices with 32-bit integer indices are accepted.\"\n                    f\" Got {indices_datatype} indices. Please do report a minimal\"\n                    \" reproducer on scikit-learn issue tracker so that support for\"\n                    \" your use-case can be studied by maintainers. See:\"\n                    \" https://scikit-learn.org/dev/developers/minimal_reproducer.html\"\n                )",
                "filename": "sklearn/utils/validation.py",
                "start_index": 35996,
                "end_index": 37016,
                "start_line": 1001,
                "end_line": 2214,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "# Authors: Manoj Kumar <manojkumarsivaraj334@gmail.com>\n#          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#          Joel Nothman <joel.nothman@gmail.com>\n# License: BSD 3 clause\n\nimport warnings\nfrom math import sqrt\nfrom numbers import Integral, Real\n\nimport numpy as np\nfrom scipy import sparse\n\nfrom .._config import config_context\nfrom ..base import (\n    BaseEstimator,\n    ClassNamePrefixFeaturesOutMixin,\n    ClusterMixin,\n    TransformerMixin,\n    _fit_context,\n)\nfrom ..exceptions import ConvergenceWarning\nfrom ..metrics import pairwise_distances_argmin\nfrom ..metrics.pairwise import euclidean_distances\nfrom ..utils._param_validation import Interval\nfrom ..utils.extmath import row_norms\nfrom ..utils.validation import check_is_fitted\nfrom . import AgglomerativeClustering\n\n\ndef _iterate_sparse_X(X):\n    \"\"\"This little hack returns a densified row when iterating over a sparse\n    matrix, instead of constructing a sparse matrix for every row that is\n    expensive.\n    \"\"\"\n    n_samples = X.shape[0]\n    X_indices = X.indices\n    X_data = X.data\n    X_indptr = X.indptr\n\n    for i in range(n_samples):\n        row = np.zeros(X.shape[1])\n        startptr, endptr = X_indptr[i], X_indptr[i + 1]\n        nonzero_indices = X_indices[startptr:endptr]\n        row[nonzero_indices] = X_data[startptr:endptr]\n        yield row",
                "filename": "sklearn/cluster/_birch.py",
                "start_index": 0,
                "end_index": 1355,
                "start_line": 1,
                "end_line": 45,
                "max_line": 741,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.1
            },
            {
                "code": "@ignore_warnings\ndef check_fit2d_1feature(name, estimator_orig):\n    # check fitting a 2d array with only 1 feature either works or returns\n    # informative message\n    rnd = np.random.RandomState(0)\n    X = 3 * rnd.uniform(size=(10, 1))\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = X[:, 0].astype(int)\n    estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    if hasattr(estimator, \"n_components\"):\n        estimator.n_components = 1\n    if hasattr(estimator, \"n_clusters\"):\n        estimator.n_clusters = 1\n    # ensure two labels in subsample for RandomizedLogisticRegression\n    if name == \"RandomizedLogisticRegression\":\n        estimator.sample_fraction = 1\n    # ensure non skipped trials for RANSACRegressor\n    if name == \"RANSACRegressor\":\n        estimator.residual_threshold = 0.5\n\n    y = _enforce_estimator_tags_y(estimator, y)\n    set_random_state(estimator, 1)\n\n    msgs = [r\"1 feature\\(s\\)\", \"n_features = 1\", \"n_features=1\"]\n\n    with raises(ValueError, match=msgs, may_pass=True):\n        estimator.fit(X, y)\n\n\n@ignore_warnings\ndef check_fit1d(name, estimator_orig):\n    # check fitting 1d X array raises a ValueError\n    rnd = np.random.RandomState(0)\n    X = 3 * rnd.uniform(size=(20))\n    y = X.astype(int)\n    estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    if hasattr(estimator, \"n_components\"):\n        estimator.n_components = 1\n    if hasattr(estimator, \"n_clusters\"):\n        estimator.n_clusters = 1\n\n    set_random_state(estimator, 1)\n    with raises(ValueError):\n        estimator.fit(X, y)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformer_general(name, transformer, readonly_memmap=False):\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer, X)\n\n    if readonly_memmap:\n        X, y = create_memmap_backed_data([X, y])\n\n    _check_transformer(name, transformer, X, y)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformer_data_not_an_array(name, transformer):\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer, X)\n    this_X = _NotAnArray(X)\n    this_y = _NotAnArray(np.asarray(y))\n    _check_transformer(name, transformer, this_X, this_y)\n    # try the same with some list\n    _check_transformer(name, transformer, X.tolist(), y.tolist())",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 55999,
                "end_index": 58685,
                "start_line": 181,
                "end_line": 1729,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            },
            {
                "code": "# Authors: Lars Buitinck\n#          Dan Blanchard <dblanchard@ets.org>\n# License: BSD 3 clause\n\nfrom array import array\nfrom collections.abc import Iterable, Mapping\nfrom numbers import Number\nfrom operator import itemgetter\n\nimport numpy as np\nimport scipy.sparse as sp\n\nfrom ..base import BaseEstimator, TransformerMixin, _fit_context\nfrom ..utils import check_array\nfrom ..utils.validation import check_is_fitted",
                "filename": "sklearn/feature_extraction/_dict_vectorizer.py",
                "start_index": 0,
                "end_index": 415,
                "start_line": 1,
                "end_line": 15,
                "max_line": 444,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": "",
                "context_relevance": 0.2
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sklearn/utils/validation.py": [
                {
                    "chunk": {
                        "code": "def check_array(\n    array,\n    accept_sparse=False,\n    *,\n    accept_large_sparse=True,\n    dtype=\"numeric\",\n    order=None,\n    copy=False,\n    force_all_finite=True,\n    ensure_2d=True,\n    allow_nd=False,\n    ensure_min_samples=1,\n    ensure_min_features=1,\n    estimator=None,\n    input_name=\"\",\n):",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 21517,
                        "end_index": 21821,
                        "start_line": 647,
                        "end_line": 2272,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the definition of the check_array function, which is central to the issue as it needs to be called with accept_sparse=True according to the issue description."
                },
                {
                    "chunk": {
                        "code": "if sp.issparse(array):\n        _ensure_no_complex_data(array)\n        array = _ensure_sparse_format(\n            array,\n            accept_sparse=accept_sparse,\n            dtype=dtype,\n            copy=copy,\n            force_all_finite=force_all_finite,\n            accept_large_sparse=accept_large_sparse,\n            estimator_name=estimator_name,\n            input_name=input_name,\n        )",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 30833,
                        "end_index": 31229,
                        "start_line": 882,
                        "end_line": 2278,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet shows the usage of check_array with a sparse matrix, which is relevant to the issue as it needs to ensure that the function is called correctly for sparse matrices."
                },
                {
                    "chunk": {
                        "code": "def _ensure_sparse_format(\n    spmatrix,\n    accept_sparse,\n    dtype,\n    copy,\n    force_all_finite,\n    accept_large_sparse,\n    estimator_name=None,\n    input_name=\"\",\n):",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 15534,
                        "end_index": 15708,
                        "start_line": 460,
                        "end_line": 2272,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet defines the _ensure_sparse_format function, which is called by check_array when a sparse matrix is passed. It is relevant to understand how sparse matrices are being handled."
                },
                {
                    "chunk": {
                        "code": "if accept_sparse is False:\n        raise TypeError(\n            \"A sparse matrix was passed, but dense \"\n            \"data is required. Use X.toarray() to \"\n            \"convert to a dense numpy array.\"\n        )\n    elif isinstance(accept_sparse, (list, tuple)):\n        if len(accept_sparse) == 0:\n            raise ValueError(\n                \"When providing 'accept_sparse' \"\n                \"as a tuple or list, it must contain at \"\n                \"least one string value.\"\n            )\n        # ensure correct sparse format\n        if spmatrix.format not in accept_sparse:\n            # create new with correct sparse\n            spmatrix = spmatrix.asformat(accept_sparse[0])\n            changed_format = True\n    elif accept_sparse is not True:\n        # any other type\n        raise ValueError(\n            \"Parameter 'accept_sparse' should be a string, \"\n            \"boolean or list of strings. You provided \"\n            \"'accept_sparse={}'.\".format(accept_sparse)\n        )\n\n    if dtype != spmatrix.dtype:\n        # convert dtype\n        spmatrix = spmatrix.astype(dtype)\n    elif copy and not changed_format:\n        # force copy\n        spmatrix = spmatrix.copy()\n\n    if force_all_finite:\n        if not hasattr(spmatrix, \"data\"):\n            warnings.warn(\n                \"Can't check %s sparse matrix for nan or inf.\" % spmatrix.format,\n                stacklevel=2,\n            )\n        else:\n            _assert_all_finite(\n                spmatrix.data,\n                allow_nan=force_all_finite == \"allow-nan\",\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n\n    return spmatrix",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 17856,
                        "end_index": 19516,
                        "start_line": 534,
                        "end_line": 581,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet is part of the check_array function's logic for handling sparse matrices and is relevant to the issue as it includes the error message that is raised when a sparse matrix is not accepted."
                }
            ]
        },
        "solution_task": "- Review the usage of `check_array` in `sklearn/manifold/locally_linear.py` and `sklearn/manifold/isomap.py`.\n- Ensure that `check_array` is called with `accept_sparse='csr'` or `accept_sparse=True` if the documentation states that `LocallyLinearEmbedding` and `Isomap` support sparse matrices.\n- Modify the calls to `check_array` in the `fit` and `fit_transform` methods of `LocallyLinearEmbedding` and `Isomap` to include `accept_sparse='csr'` as an argument if sparse input is indeed supported.\n- Example modification if sparse matrices are supported:\n  ```python\n  # In sklearn/manifold/locally_linear.py\n  def _fit_transform(self, X):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n\n  # In sklearn/manifold/isomap.py\n  def fit(self, X, y=None):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n\n  def fit_transform(self, X, y=None):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n  ```",
        "bouncer_response": {
            "score": 9,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant hints and solutions that can directly lead to resolving the issues outlined in the PROMPT.",
            "supporting_evidence": "The RESPONSE provides a clear and actionable plan for addressing the issue with `LocallyLinearEmbedding` and `Isomap` not accepting sparse matrix input despite the documentation stating otherwise. It correctly identifies the need to review the usage of `check_array` in the relevant files and suggests the exact changes needed to the function calls, including the correct parameter `accept_sparse='csr'`. The RESPONSE also provides example modifications to the code, which are directly applicable and would likely resolve the issue if the documentation is correct. Additionally, the RESPONSE includes references to the relevant code snippets in the sklearn repository, which would be useful for the person addressing the bug. The only reason for not giving a score of 10 is that the RESPONSE does not explicitly mention the need to verify the documentation's accuracy or the implications for `SpectralEmbedding`, which the PROMPT hints at by mentioning the arpack solver.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711742733.874399,
        "result": "- Review the usage of `check_array` in `sklearn/manifold/locally_linear.py` and `sklearn/manifold/isomap.py`.\n- Ensure that `check_array` is called with `accept_sparse='csr'` or `accept_sparse=True` if the documentation states that `LocallyLinearEmbedding` and `Isomap` support sparse matrices.\n- Modify the calls to `check_array` in the `fit` and `fit_transform` methods of `LocallyLinearEmbedding` and `Isomap` to include `accept_sparse='csr'` as an argument if sparse input is indeed supported.\n- Example modification if sparse matrices are supported:\n  ```python\n  # In sklearn/manifold/locally_linear.py\n  def _fit_transform(self, X):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n\n  # In sklearn/manifold/isomap.py\n  def fit(self, X, y=None):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n\n  def fit_transform(self, X, y=None):\n      X = check_array(X, accept_sparse='csr', dtype=np.float64)\n      # ...\n  ```\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/utils)- [Lines 647 - 2272](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L647-L2272)\n\n This snippet contains the definition of the check_array function, which is central to the issue as it needs to be called with accept_sparse=True according to the issue description. \n\n\n   - [Lines 882 - 2278](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L882-L2278)\n\n This snippet shows the usage of check_array with a sparse matrix, which is relevant to the issue as it needs to ensure that the function is called correctly for sparse matrices. \n\n\n   - [Lines 460 - 2272](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L460-L2272)\n\n This snippet defines the _ensure_sparse_format function, which is called by check_array when a sparse matrix is passed. It is relevant to understand how sparse matrices are being handled. \n\n\n   - [Lines 534 - 581](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L534-L581)\n\n This snippet is part of the check_array function's logic for handling sparse matrices and is relevant to the issue as it includes the error message that is raised when a sparse matrix is not accepted.",
        "context_relevance": 0.2500000000000001,
        "hypotheses": [],
        "groundedness_score": 1.0,
        "qa_relevance_reasons": {
            "reason": "Criteria: The RESPONSE is relevant to the entire PROMPT and answers it completely.\nSupporting Evidence: The RESPONSE directly addresses the issue raised in the PROMPT regarding the incorrect handling of sparse matrices by `Isomap` and `LocallyLinearEmbedding` in scikit-learn, despite the documentation stating otherwise. It provides a clear course of action to review and correct the usage of `check_array` in the relevant files, ensuring that the code aligns with the documentation. The RESPONSE also includes example code modifications that would allow the methods to accept sparse matrices, which is the core of the issue described in the PROMPT. Additionally, the RESPONSE provides links to the relevant code snippets that would need to be checked, which is directly related to the traceback and error message provided in the PROMPT. The RESPONSE is comprehensive and provides all the necessary steps to resolve the issue, making it highly relevant and deserving of the highest score."
        },
        "qa_relevance": 1.0
    }
}