{
    "id": "astropy__astropy-13417",
    "repo_name": "testbed/astropy__astropy__5.0",
    "task_id": 3222241795802086215,
    "title": "FITS problem reading binary table with variable length columns",
    "body": "I want to read a certain FITS file ([P190mm-PAFBE-FEBEPAR.fits.zip](https://github.com/astropy/astropy/files/2370673/P190mm-PAFBE-FEBEPAR.fits.zip)), which is part of a Multi-Beam-FITS measurement set ([MBFITS](http://www.mpifr-bonn.mpg.de/staff/dmuders/APEX/MBFITS/APEX-MPI-ICD-0002-R1_65.pdf)) as used by several radio observatories around the world. The file has a binary table extension with variable length columns. Usually this works fine, but this particular example has some columns with a \"1PJ(1)\" type (and one row only), which seems to lead to problems when reading with astropy.io.fits:\r\n\r\n```python\r\nimport astropy\r\nastropy.__version__\r\n# '3.0.4'\r\n```\r\n\r\n```python\r\nfrom astropy.io import fits\r\ndata = fits.getdata('P190mm-PAFBE-FEBEPAR.fits', 1)\r\ndata\r\n# FITS_rec([(1, 1)],\r\n#          dtype=(numpy.record, {'names':['USEBAND','NUSEFEED','USEFEED','BESECTS','FEEDTYPE','FEEDOFFX','FEEDOFFY','REFFEED','POLTY','POLA','APEREFF','BEAMEFF','ETAFSS','HPBW','ANTGAIN','TCAL','BOLCALFC','BEGAIN','BOLDCOFF','FLATFIEL','GAINIMAG','GAINELE1','GAINELE2'], 'formats':['>i4','>i4',('>i4', (1, 1)),('>i4', (1, 1)),('>i4', (1, 1)),'>f8','>f8','>i4','S1','>f4',('>f4', (1, 1)),('>f4', (1, 1)),('>f4', (1, 1)),('>f4', (1, 1)),('>f4', (1, 1)),('>f4', (1, 1)),'>f4','>f4',('>f4', (1, 1)),('>f4', (1, 1)),('>f4', (1, 1)),'>f4','>f4'], 'offsets':[0,4,8,16,24,32,40,48,52,53,57,61,65,69,73,77,81,85,89,93,97,101,105], 'itemsize':109}))\r\n```\r\nHere it appears already, that the content of the record (\"(1, 1)\"] is smaller than the 'itemsize' (109). In fact, accessing the first two columns works, but all var-length columns raise an error:\r\n\r\n```python\r\ndata['USEBAND']\r\n# array([1], dtype=int32)\r\n\r\ndata['NUSEFEED']\r\n# array([1], dtype=int32)\r\n\r\ndata['USEFEED']\r\n# IndexError                                Traceback (most recent call last)\r\n# ...\r\n# site-packages/astropy/io/fits/fitsrec.py in _convert_p(self, column, field, recformat)\r\n#     792 \r\n#     793         for idx in range(len(self)):\r\n# --> 794             offset = field[idx, 1] + self._heapoffset\r\n#     795             count = field[idx, 0]\r\n#     796 \r\n\r\n# IndexError: index 1 is out of bounds for axis 1 with size 1\r\n```\r\n\r\nI checked the file with [fitsverify](https://fits.gsfc.nasa.gov/fits_verify.html), which results in zero warnings and errors.\r\n\r\nThanks a lot for your help!\nMulti-dimensional arrays in variable-length array columns of a FITS binary table cause file corruption\n### Description\r\n`io.fits` may create corrupted files when writing a `BinTableHDU` to a file, if that table contains a variable-length array (VLA) column with arrays that have two (or more) dimensions. No warnings or errors are raised while writing, yet the resulting file may be unreadable to `io.fits`.\r\n\r\n### Expected behavior\r\nBeing able to write any n-dimensional arrays to a VLA column, writing that to a file and then successfully reading the column (round-trip).\r\n\r\n### Actual behavior\r\nThe resulting file is partially or even completely corrupted.\r\n\r\n### Steps to Reproduce\r\n\r\n\r\n1. Create a two-dimensional `numpy` array and place it on a `numpy` array with `dtype=object`\r\n2. Create a VLA column with that array\r\n3. Create a `BinTableHDU` from that column and write it to a file\r\n4. Read the file back\r\n\r\n```python\r\narray = np.array([np.ones((8, 50))], dtype=object)\r\ncol = fits.Column(name='test', format='PD()', array=array)\r\nfits.BinTableHDU.from_columns([col]).writeto('bug.fits', overwrite=True)\r\n\r\nwith fits.open('bug.fits') as hdus:\r\n    print(hdus)\r\n\r\n```\r\n\r\nProduces the following error:\r\n\r\n```\r\nWARNING: non-ASCII characters are present in the FITS file header and have been replaced by \"?\" characters [astropy.io.fits.util]\r\nWARNING: Header block contains null bytes instead of spaces for padding, and is not FITS-compliant. Nulls may be replaced with spaces upon writing. [astropy.io.fits.header]\r\nTraceback (most recent call last):\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\hdu\\base.py\", line 417, in _readfrom_internal\r\n    header_str, header = _BasicHeader.fromfile(data)\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\header.py\", line 2075, in fromfile\r\n    header_str, cards = parse_header(fileobj)\r\n  File \"astropy\\io\\fits\\_utils.pyx\", line 38, in astropy.io.fits._utils.parse_header\r\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 1: ordinal not in range(128)\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  (...)\r\n  File \"[path]/bugtest.py\", line 9, in <module>\r\n    print(hdus)\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\", line 258, in __repr__\r\n    self.readall()\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\", line 795, in readall\r\n    while self._read_next_hdu():\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\", line 1200, in _read_next_hdu\r\n    hdu = _BaseHDU.readfrom(fileobj, **kwargs)\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\hdu\\base.py\", line 332, in readfrom\r\n    hdu = cls._readfrom_internal(fileobj, checksum=checksum,\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\hdu\\base.py\", line 424, in _readfrom_internal\r\n    header = Header.fromfile(data,\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\header.py\", line 523, in fromfile\r\n    return cls._from_blocks(block_iter, is_binary, sep, endcard,\r\n  File \"[path]\\venv\\lib\\site-packages\\astropy\\io\\fits\\header.py\", line 610, in _from_blocks\r\n    raise OSError('Header missing END card.')\r\nOSError: Header missing END card.\r\n\r\n```\r\n______\r\nPlaying around with it a bit more, I could produce some other weird behaviors.\r\n\r\n```python\r\na = np.ones((5, 2))\r\nb = np.full((10,), 5)\r\nx = [a, b]\r\n\r\narray = np.empty(len(x), dtype=object)\r\narray[:] = x\r\n\r\ncol = fits.Column(name='test', format='PD()', array=array)\r\nfits.BinTableHDU.from_columns([col]).writeto('bug.fits', overwrite=True)\r\n\r\nwith fits.open('bug.fits') as hdus:\r\n    print(hdus[1].data['test'])\r\n\r\n```\r\nOutputs the following:\r\n```python\r\n[array([1., 1., 1., 1., 1.])\r\n array([1., 1., 1., 1., 1., 5., 5., 5., 5., 5.])]\r\n```\r\n\r\nwhile the expected result would be:\r\n```python\r\n[array([[1., 1.],\r\n       [1., 1.],\r\n       [1., 1.],\r\n       [1., 1.],\r\n       [1., 1.]]), array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])]\r\n```\r\n\r\nSo it seems that everything that doesn't fit in the first dimension is going out of bounds and writing over the next array. This explains why it can also heavily corrupt the file.\r\n\r\n____\r\n\r\nReading the FITS standard, I get the impression that multi-dimensional VLAs should be possible, so this seems like an unexpected behavior. At the very least, if multi-dimensional VLAs aren't meant to be supported, `io.fits` should be throwing errors. Right now it's simply failing silently.\r\n\r\n### System Details\r\nWindows-10-10.0.19044-SP0\r\nPython 3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)]\r\nNumpy 1.22.2\r\npyerfa 2.0.0.1\r\nastropy 5.0.1\r\nScipy 1.7.1\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/astropy__astropy__5.0.git",
    "requested_commit": "",
    "mayil_response": "Doesn't seem like we have fully grasped all the specifics of this ticket \ud83d\ude15.                   But we've outlined some ideas that might help you get started:\n\nBased on the provided information, the following solutions address the reported issues:\n\n- `IndexError: index 1 is out of bounds for axis 1 with size 1`:\n  - Check the code where the FITS data is being accessed by index. Ensure that the index is within the bounds of the data array's shape.\n  - If using variable-length arrays (VLAs), ensure that the correct lengths are being used when accessing the data.\n\n- `UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 1: ordinal not in range(128)`:\n  - When opening FITS files with `fits.open`, use the `encoding='utf-8'` parameter to handle non-ASCII characters in the header.\n  - If the error occurs during file reading, ensure that the correct encoding is specified when reading text data.\n\n- `OSError: Header missing END card.`:\n  - Verify that the FITS file is not corrupted and contains a valid header with an `END` card.\n  - If creating or modifying a FITS header, ensure that the `END` card is properly written.\n\n- For handling variable-length array columns in FITS binary tables:\n  - When creating columns with variable-length arrays, use the correct `format` specifier, such as `'1PJ(1)'` for a 1-dimensional array of variable length.\n  - Ensure that the `fits.Column` objects are created with the correct `dtype` and `format` that match the data being written.\n\n- For issues related to writing and reading n-dimensional arrays in VLA columns:\n  - Ensure that the `format` specified in `fits.Column` is correct for the dimensionality of the array. For example, use `'1PJ(n)'` where `n` is the size of the array dimension.\n  - When reading the data back, ensure that the correct shape is reconstructed from the VLA data.\n\n- General advice for reading and writing FITS files with `astropy.io.fits`:\n  - Always check the version of Astropy to ensure compatibility with FITS standards, especially for advanced features like VLAs.\n  - Use `fits.verify` to check the compliance of FITS files with the standard.\n  - When encountering errors, use `fits.open` with the `ignore_missing_end=True` parameter to attempt to open files with missing `END` cards.\n\n- For the specific error messages and code snippets provided:\n  - Check the usage of `fits.BinTableHDU.from_columns` to ensure that the columns are defined with the correct formats and data types.\n  - If using `np.array`, `np.ones`, or `np.full` to create data arrays, ensure that the resulting arrays have the correct shape and data type before inserting them into FITS columns.\n  - When writing data with `writeto`, use `overwrite=True` to avoid issues with existing files.\n  - If the FITS file structure includes binary table extensions with variable length columns, ensure that the FITS standard for multi-dimensional VLAs is followed.\n\n### Code snippets to check\n\n-  \u2192 [astropy](https://github.com/testbed/astropy__astropy__5.0/tree//astropy) \u2192 [io](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io) \u2192 [fits](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits) \u2192 [hdu](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits/hdu)- [Lines 917 - 1510](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/hdu/table.py#L917-L1510)\n\n This snippet from 'astropy/io/fits/hdu/table.py' contains code that handles variable length array (VLA) columns in FITS binary tables, which is directly related to the issue of reading binary tables with variable length columns. \n\n\n   - [Lines 1 - 55](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/hdu/table.py#L1-L55)\n\n This snippet from 'astropy/io/fits/hdu/table.py' includes imports and references to utilities for handling table and column-related operations in FITS files, which may be relevant to the issue of handling variable length array columns.\n-  \u2192 [astropy](https://github.com/testbed/astropy__astropy__5.0/tree//astropy) \u2192 [io](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io) \u2192 [fits](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits)- [Lines 1 - 2756](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/column.py#L1-L2756)\n\n The snippet from 'astropy/io/fits/column.py' defines mappings and conversions between FITS column formats and numpy data types, which is relevant to the issue since the problem involves reading FITS columns with specific data types that are causing errors.\n-  \u2192 [astropy](https://github.com/testbed/astropy__astropy__5.0/tree//astropy) \u2192 [io](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io) \u2192 [fits](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits) \u2192 [hdu](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits/hdu)- [Lines 1 - 1661](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/hdu/base.py#L1-L1661)\n\n The snippet from 'astropy/io/fits/hdu/base.py' includes code for handling HDUs (Header Data Units), which could be relevant when investigating issues related to reading and interpreting FITS file structures, including binary tables with variable length columns.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0020169999999999997,
        "snippet_processor": 0.10021000000000001,
        "issue_star_creation": 0.02848,
        "issue_star_solver": 0.06717000000000001,
        "bouncer": 0.03083
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711736378.970183,
        "relevant_snippets": [
            {
                "code": "data = hdu.data\n        for idx, length in enumerate(vla_lengths):\n            if length is not None:\n                arr = data.columns._arrays[idx]\n                dt = recformats[idx][len(str(length)) :]\n\n                # NOTE: FormatQ not supported here; it's hard to determine\n                # whether or not it will be necessary to use a wider descriptor\n                # type. The function documentation will have to serve as a\n                # warning that this is not supported.\n                recformats[idx] = _FormatP(dt, max=length)\n                data.columns._recformats[idx] = recformats[idx]\n                name = data.columns.names[idx]\n                data._cache_field(name, _makep(arr, arr, recformats[idx]))\n\n        def format_value(col, val):\n            # Special formatting for a couple particular data types\n            if recformats[col] == FITS2NUMPY[\"L\"]:\n                return bool(int(val))\n            elif recformats[col] == FITS2NUMPY[\"M\"]:\n                # For some reason, in arrays/fields where numpy expects a\n                # complex it's not happy to take a string representation\n                # (though it's happy to do that in other contexts), so we have\n                # to convert the string representation for it:\n                return complex(val)\n            else:\n                return val\n\n        # Jump back to the start of the data and create a new line reader\n        fileobj.seek(initialpos)\n        linereader = csv.reader(fileobj, dialect=FITSTableDumpDialect)\n        for row, line in enumerate(linereader):\n            col = 0\n            idx = 0\n            while idx < len(line):\n                if line[idx] == \"VLA_Length=\":\n                    vla_len = vla_lengths[col]\n                    idx += 2\n                    slice_ = slice(idx, idx + vla_len)\n                    data[row][col][:] = line[idx : idx + vla_len]\n                    idx += vla_len\n                elif dtype[col].shape:\n                    # This is an array column\n                    array_size = int(np.multiply.reduce(dtype[col].shape))\n                    slice_ = slice(idx, idx + array_size)\n                    idx += array_size\n                else:\n                    slice_ = None\n\n                if slice_ is None:\n                    # This is a scalar row element\n                    data[row][col] = format_value(col, line[idx])\n                    idx += 1\n                else:\n                    data[row][col].flat[:] = [\n                        format_value(col, val) for val in line[slice_]\n                    ]\n\n                col += 1\n\n        if close_file:\n            fileobj.close()\n\n        return data",
                "filename": "astropy/io/fits/hdu/table.py",
                "start_index": 56804,
                "end_index": 59493,
                "start_line": 917,
                "end_line": 1510,
                "max_line": 1612,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "# most systems by seeking past the end of the file and writing a single byte,\n# like so:\n\nwith open('large.fits', 'rb+') as fobj:\n    # Seek past the length of the header, plus the length of the\n    # Data we want to write.\n    # 8 is the number of bytes per value, i.e. abs(header['BITPIX'])/8\n    # (this example is assuming a 64-bit float)\n    # The -1 is to account for the final byte that we are about to\n    # write:\n    fobj.seek(len(header.tostring()) + (40000 * 40000 * 8) - 1)\n    fobj.write(b'\\0')\n\n##############################################################################\n# More generally, this can be written:\n\nshape = tuple(header[f'NAXIS{ii}'] for ii in range(1, header['NAXIS']+1))\nwith open('large.fits', 'rb+') as fobj:\n    fobj.seek(len(header.tostring()) + (np.prod(shape) * np.abs(header['BITPIX']//8)) - 1)\n    fobj.write(b'\\0')\n\n##############################################################################\n# On modern operating systems this will cause the file (past the header) to be\n# filled with zeros out to the ~12GB needed to hold a 40000 x 40000 image. On\n# filesystems that support sparse file creation (most Linux filesystems, but not\n# the HFS+ filesystem used by most Macs) this is a very fast, efficient\n# operation. On other systems your mileage may vary.\n#\n# This isn't the only way to build up a large file, but probably one of the\n# safest. This method can also be used to create large multi-extension FITS\n# files, with a little care.\n\n##############################################################################\n# Finally, we'll remove the file we created:\n\nos.remove('large.fits')",
                "filename": "examples/io/skip_create-large-fits.py",
                "start_index": 2977,
                "end_index": 4608,
                "start_line": 77,
                "end_line": 112,
                "max_line": 112,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "name: Bug report\ndescription: Create a report describing unexpected or incorrect behavior in astropy.\nlabels: Bug\nbody:\n  - type: markdown\n    attributes:\n      value: >-\n        Thanks for taking the time to fill out this bug report!\n        Please have a search on our GitHub repository to see if a similar\n        issue has already been posted. If a similar issue is closed, have a\n        quick look to see if you are satisfied by the resolution.\n        If not please go ahead and open an issue!\n        Please check that the\n        [development version](https://docs.astropy.org/en/latest/development/workflow/get_devel_version.html)\n        still produces the same bug.\n  - type: textarea\n    attributes:\n      label: Description\n      description: >-\n        A clear and concise description of what the bug is.\n  - type: textarea\n    attributes:\n      label: Expected behavior\n      description: >-\n        A clear and concise description of what you expected to happen.\n  - type: textarea\n    attributes:\n      label: How to Reproduce\n      description: >-\n        A clear and concise description of what actually happened instead.\n        Was the output confusing or poorly described? Please provide steps to reproduce this bug.\n      value: |\n        1. Get package from '...'\n        2. Then run '...'\n        3. An error occurs.\n\n        ```python\n        # Put your Python code snippet here.\n        ```\n  - type: textarea\n    attributes:\n      label: Versions\n      description: Version of relevant packages.\n      value: |\n        import platform; print(platform.platform())\n        import sys; print(\"Python\", sys.version)\n        import astropy; print(\"astropy\", astropy.__version__)\n        import numpy; print(\"Numpy\", numpy.__version__)\n        import erfa; print(\"pyerfa\", erfa.__version__)\n        import scipy; print(\"Scipy\", scipy.__version__)\n        import matplotlib; print(\"Matplotlib\", matplotlib.__version__)",
                "filename": ".github/ISSUE_TEMPLATE/bug_report.yaml",
                "start_index": 0,
                "end_index": 1940,
                "start_line": 1,
                "end_line": 51,
                "max_line": 51,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "if isinstance(tarray, np.ma.MaskedArray):\n        # Fill masked values carefully:\n        # float column's default mask value needs to be Nan and\n        # string column's default mask should be an empty string.\n        # Note: getting the fill value for the structured array is\n        # more reliable than for individual columns for string entries.\n        # (no 'N/A' for a single-element string, where it should be 'N').\n        default_fill_value = np.ma.default_fill_value(tarray.dtype)\n        for colname, (coldtype, _) in tarray.dtype.fields.items():\n            if np.all(tarray.fill_value[colname] == default_fill_value[colname]):\n                # Since multi-element columns with dtypes such as '2f8' have\n                # a subdtype, we should look up the type of column on that.\n                coltype = (\n                    coldtype.subdtype[0].type if coldtype.subdtype else coldtype.type\n                )\n                if issubclass(coltype, np.complexfloating):\n                    tarray.fill_value[colname] = complex(np.nan, np.nan)\n                elif issubclass(coltype, np.inexact):\n                    tarray.fill_value[colname] = np.nan\n                elif issubclass(coltype, np.character):\n                    tarray.fill_value[colname] = \"\"\n\n        # TODO: it might be better to construct the FITS table directly from\n        # the Table columns, rather than go via a structured array.\n        table_hdu = BinTableHDU.from_columns(\n            tarray.filled(), header=hdr, character_as_bytes=character_as_bytes\n        )\n        for col in table_hdu.columns:\n            # Binary FITS tables support TNULL *only* for integer data columns\n            # TODO: Determine a schema for handling non-integer masked columns\n            # with non-default fill values in FITS (if at all possible).\n            int_formats = (\"B\", \"I\", \"J\", \"K\")\n            if not (col.format in int_formats or col.format.p_format in int_formats):\n                continue\n\n            fill_value = tarray[col.name].fill_value\n            col.null = fill_value.astype(int)\n    else:\n        table_hdu = BinTableHDU.from_columns(\n            tarray, header=hdr, character_as_bytes=character_as_bytes\n        )\n\n    # Set units and format display for output HDU",
                "filename": "astropy/io/fits/convenience.py",
                "start_index": 16569,
                "end_index": 18841,
                "start_line": 513,
                "end_line": 555,
                "max_line": 1172,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\n\nimport datetime\nimport numbers\nimport os\nimport sys\nimport warnings\nfrom contextlib import suppress\nfrom inspect import Parameter, signature\n\nimport numpy as np\n\nfrom astropy.io.fits import conf\nfrom astropy.io.fits.file import _File\nfrom astropy.io.fits.header import Header, _BasicHeader, _DelayedHeader, _pad_length\nfrom astropy.io.fits.util import (\n    _extract_number,\n    _free_space_check,\n    _get_array_mmap,\n    _is_int,\n    _is_pseudo_integer,\n    _pseudo_zero,\n    decode_ascii,\n    first,\n    itersubclasses,\n)\nfrom astropy.io.fits.verify import _ErrList, _Verify\nfrom astropy.utils import lazyproperty\nfrom astropy.utils.exceptions import AstropyUserWarning\n\n__all__ = [\n    \"DELAYED\",\n    # classes\n    \"InvalidHDUException\",\n    \"ExtensionHDU\",\n    \"NonstandardExtHDU\",\n]\n\n\nclass _Delayed:\n    pass\n\n\nDELAYED = _Delayed()\n\n\nBITPIX2DTYPE = {\n    8: \"uint8\",\n    16: \"int16\",\n    32: \"int32\",\n    64: \"int64\",\n    -32: \"float32\",\n    -64: \"float64\",\n}\n\"\"\"Maps FITS BITPIX values to Numpy dtype names.\"\"\"\n\nDTYPE2BITPIX = {\n    \"int8\": 8,\n    \"uint8\": 8,\n    \"int16\": 16,\n    \"uint16\": 16,\n    \"int32\": 32,\n    \"uint32\": 32,\n    \"int64\": 64,\n    \"uint64\": 64,\n    \"float32\": -32,\n    \"float64\": -64,\n}\n\"\"\"\nMaps Numpy dtype names to FITS BITPIX values (this includes unsigned\nintegers, with the assumption that the pseudo-unsigned integer convention\nwill be used in this case.\n\"\"\"\n\n\nclass InvalidHDUException(Exception):\n    \"\"\"\n    A custom exception class used mainly to signal to _BaseHDU.__new__ that\n    an HDU cannot possibly be considered valid, and must be assumed to be\n    corrupted.\n    \"\"\"",
                "filename": "astropy/io/fits/hdu/base.py",
                "start_index": 0,
                "end_index": 1678,
                "start_line": 1,
                "end_line": 1661,
                "max_line": 1666,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "\"\"\"\n==========================================\nCreate a very large FITS file from scratch\n==========================================\n\nThis example demonstrates how to create a large file (larger than will fit in\nmemory) from scratch using `astropy.io.fits`.\n\n\n*By: Erik Bray*\n\n*License: BSD*\n\n\"\"\"\n\n##############################################################################\n#  Normally to create a single image FITS file one would do something like:\n\nimport os\n\nimport numpy as np\n\nfrom astropy.io import fits\n\ndata = np.zeros((40000, 40000), dtype=np.float64)\nhdu = fits.PrimaryHDU(data=data)\n\n##############################################################################\n# Then use the `astropy.io.fits.writeto()` method to write out the new\n# file to disk\n\nhdu.writeto('large.fits')\n\n##############################################################################\n# However, a 40000 x 40000 array of doubles is nearly twelve gigabytes! Most\n# systems won't be able to create that in memory just to write out to disk. In\n# order to create such a large file efficiently requires a little extra work,\n# and a few assumptions.\n#\n# First, it is helpful to anticipate about how large (as in, how many keywords)\n# the header will have in it. FITS headers must be written in 2880 byte\n# blocks, large enough for 36 keywords per block (including the END keyword in\n# the final block). Typical headers have somewhere between 1 and 4 blocks,\n# though sometimes more.\n#\n# Since the first thing we write to a FITS file is the header, we want to write\n# enough header blocks so that there is plenty of padding in which to add new\n# keywords without having to resize the whole file. Say you want the header to\n# use 4 blocks by default. Then, excluding the END card which Astropy will add\n# automatically, create the header and pad it out to 36 * 4 cards.\n#\n# Create a stub array to initialize the HDU; its\n# exact size is irrelevant, as long as it has the desired number of\n# dimensions\n\ndata = np.zeros((100, 100), dtype=np.float64)\nhdu = fits.PrimaryHDU(data=data)\nheader = hdu.header\nwhile len(header) < (36 * 4 - 1):\n    header.append()  # Adds a blank card to the end\n\n##############################################################################\n# Now adjust the NAXISn keywords to the desired size of the array, and write\n# only the header out to a file. Using the ``hdu.writeto()`` method will cause\n# astropy to \"helpfully\" reset the NAXISn keywords to match the size of the\n# dummy array. That is because it works hard to ensure that only valid FITS\n# files are written. Instead, we can write just the header to a file using the\n# `astropy.io.fits.Header.tofile` method:\n\nheader['NAXIS1'] = 40000\nheader['NAXIS2'] = 40000\nheader.tofile('large.fits')\n\n##############################################################################\n# Finally, grow out the end of the file to match the length of the\n# data (plus the length of the header). This can be done very efficiently on",
                "filename": "examples/io/skip_create-large-fits.py",
                "start_index": 0,
                "end_index": 2976,
                "start_line": 1,
                "end_line": 76,
                "max_line": 112,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "int fits_read_wcstab(\n  fitsfile   *fptr,\n  int  nwtb,\n  wtbarr *wtb,\n  int  *status)\n\n{\n  int  anynul, colnum, hdunum, iwtb, m, naxis, nostat;\n  long *naxes = 0, nelem;\n  wtbarr *wtbp;\n\n\n  if (*status) return *status;\n\n  if (fptr == 0) {\n    return (*status = NULL_INPUT_PTR);\n  }\n\n  if (nwtb == 0) return 0;\n\n  // Zero the array pointers.\n  wtbp = wtb;\n  for (iwtb = 0; iwtb < nwtb; iwtb++, wtbp++) {\n    *wtbp->arrayp = 0x0;\n  }\n\n  // Save HDU number so that we can move back to it later.\n  fits_get_hdu_num(fptr, &hdunum);\n\n  wtbp = wtb;\n  for (iwtb = 0; iwtb < nwtb; iwtb++, wtbp++) {\n    // Move to the required binary table extension.\n    if (fits_movnam_hdu(fptr, BINARY_TBL, (char *)(wtbp->extnam),\n        wtbp->extver, status)) {\n      goto cleanup;\n    }\n\n    // Locate the table column.\n    if (fits_get_colnum(fptr, CASEINSEN, (char *)(wtbp->ttype), &colnum,\n        status)) {\n      goto cleanup;\n    }\n\n    // Get the array dimensions and check for consistency.\n    if (wtbp->ndim < 1) {\n      *status = NEG_AXIS;\n      goto cleanup;\n    }\n\n    if (!(naxes = calloc(wtbp->ndim, sizeof(long)))) {\n      *status = MEMORY_ALLOCATION;\n      goto cleanup;\n    }\n\n    if (fits_read_tdim(fptr, colnum, wtbp->ndim, &naxis, naxes, status)) {\n      goto cleanup;\n    }\n\n    if (naxis != wtbp->ndim) {\n      if (wtbp->kind == 'c' && wtbp->ndim == 2) {\n        // Allow TDIMn to be omitted for degenerate coordinate arrays.\n        naxis = 2;\n        naxes[1] = naxes[0];\n        naxes[0] = 1;\n      } else {\n        *status = BAD_TDIM;\n        goto cleanup;\n      }\n    }\n\n    if (wtbp->kind == 'c') {\n      // Coordinate array; calculate the array size.\n      nelem = naxes[0];\n      for (m = 0; m < naxis-1; m++) {\n        *(wtbp->dimlen + m) = naxes[m+1];\n        nelem *= naxes[m+1];\n      }\n    } else {\n      // Index vector; check length.\n      if ((nelem = naxes[0]) != *(wtbp->dimlen)) {\n        // N.B. coordinate array precedes the index vectors.\n        *status = BAD_TDIM;\n        goto cleanup;\n      }\n    }\n\n    free(naxes);\n    naxes = 0;\n\n    // Allocate memory for the array.\n    if (!(*wtbp->arrayp = calloc((size_t)nelem, sizeof(double)))) {\n      *status = MEMORY_ALLOCATION;\n      goto cleanup;\n    }\n\n    // Read the array from the table.\n    if (fits_read_col_dbl(fptr, colnum, wtbp->row, 1L, nelem, 0.0,\n        *wtbp->arrayp, &anynul, status)) {\n      goto cleanup;\n    }\n  }\n\ncleanup:\n  // Move back to the starting HDU.\n  nostat = 0;\n  fits_movabs_hdu(fptr, hdunum, 0, &nostat);\n\n  // Release allocated memory.\n  if (naxes) free(naxes);\n  if (*status) {\n    wtbp = wtb;\n    for (iwtb = 0; iwtb < nwtb; iwtb++, wtbp++) {\n      if (*wtbp->arrayp) free(*wtbp->arrayp);\n    }\n  }\n\n  return *status;\n}",
                "filename": "cextern/wcslib/C/getwcstab.c",
                "start_index": 1276,
                "end_index": 4005,
                "start_line": 34,
                "end_line": 151,
                "max_line": 151,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\n\"\"\"\nA package for reading and writing FITS files and manipulating their\ncontents.\n\nA module for reading and writing Flexible Image Transport System\n(FITS) files.  This file format was endorsed by the International\nAstronomical Union in 1999 and mandated by NASA as the standard format\nfor storing high energy astrophysics data.  For details of the FITS\nstandard, see the NASA/Science Office of Standards and Technology\npublication, NOST 100-2.0.\n\"\"\"\n\nfrom astropy import config as _config\n\n# Set module-global boolean variables\n# TODO: Make it possible to set these variables via environment variables\n# again, once support for that is added to Astropy\n\n\nclass Conf(_config.ConfigNamespace):\n    \"\"\"\n    Configuration parameters for `astropy.io.fits`.\n    \"\"\"\n\n    enable_record_valued_keyword_cards = _config.ConfigItem(\n        True,\n        \"If True, enable support for record-valued keywords as described by \"\n        \"FITS WCS distortion paper. Otherwise they are treated as normal \"\n        \"keywords.\",\n        aliases=[\"astropy.io.fits.enabled_record_valued_keyword_cards\"],\n    )\n    extension_name_case_sensitive = _config.ConfigItem(\n        False,\n        \"If True, extension names (i.e. the ``EXTNAME`` keyword) should be \"\n        \"treated as case-sensitive.\",\n    )\n    strip_header_whitespace = _config.ConfigItem(\n        True,\n        \"If True, automatically remove trailing whitespace for string values in\"\n        \" headers. Otherwise the values are returned verbatim, with all \"\n        \"whitespace intact.\",\n    )\n    use_memmap = _config.ConfigItem(\n        True,\n        \"If True, use memory-mapped file access to read/write the data in \"\n        \"FITS files. This generally provides better performance, especially \"\n        \"for large files, but may affect performance in I/O-heavy \"\n        \"applications.\",\n    )\n    lazy_load_hdus = _config.ConfigItem(\n        True,\n        \"If True, use lazy loading of HDUs when opening FITS files by \"\n        \"default; that is fits.open() will only seek for and read HDUs on \"\n        \"demand rather than reading all HDUs at once.  See the documentation \"\n        \"for fits.open() for more details.\",\n    )\n    enable_uint = _config.ConfigItem(\n        True,\n        \"If True, default to recognizing the convention for representing \"\n        \"unsigned integers in FITS--if an array has BITPIX > 0, BSCALE = 1, \"\n        \"and BZERO = 2**BITPIX, represent the data as unsigned integers \"\n        \"per this convention.\",\n    )\n\n\nconf = Conf()\n\n\n# Public API compatibility imports\n# These need to come after the global config variables, as some of the\n# submodules use them\nfrom . import card, column, convenience, hdu\nfrom .card import *\nfrom .column import *\nfrom .convenience import *\nfrom .diff import *\nfrom .fitsrec import FITS_rec, FITS_record\nfrom .hdu import *\nfrom .hdu.compressed import CompImageSection\nfrom .hdu.groups import GroupData",
                "filename": "astropy/io/fits/__init__.py",
                "start_index": 0,
                "end_index": 2974,
                "start_line": 1,
                "end_line": 82,
                "max_line": 104,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\nimport copy\nimport numbers\nimport operator\nimport re\nimport sys\nimport warnings\nimport weakref\nfrom collections import OrderedDict\nfrom contextlib import suppress\nfrom functools import reduce\n\nimport numpy as np\nfrom numpy import char as chararray\n\nfrom astropy.utils import indent, isiterable, lazyproperty\nfrom astropy.utils.exceptions import AstropyUserWarning\n\nfrom .card import CARD_LENGTH, Card\nfrom .util import NotifierMixin, _convert_array, _is_int, cmp, encode_ascii, pairwise\nfrom .verify import VerifyError, VerifyWarning\n\n__all__ = [\"Column\", \"ColDefs\", \"Delayed\"]\n\n\n# mapping from TFORM data type to numpy data type (code)\n# L: Logical (Boolean)\n# B: Unsigned Byte\n# I: 16-bit Integer\n# J: 32-bit Integer\n# K: 64-bit Integer\n# E: Single-precision Floating Point\n# D: Double-precision Floating Point\n# C: Single-precision Complex\n# M: Double-precision Complex\n# A: Character\nFITS2NUMPY = {\n    \"L\": \"i1\",\n    \"B\": \"u1\",\n    \"I\": \"i2\",\n    \"J\": \"i4\",\n    \"K\": \"i8\",\n    \"E\": \"f4\",\n    \"D\": \"f8\",\n    \"C\": \"c8\",\n    \"M\": \"c16\",\n    \"A\": \"a\",\n}\n\n# the inverse dictionary of the above\nNUMPY2FITS = {val: key for key, val in FITS2NUMPY.items()}\n# Normally booleans are represented as ints in Astropy, but if passed in a numpy\n# boolean array, that should be supported\nNUMPY2FITS[\"b1\"] = \"L\"\n# Add unsigned types, which will be stored as signed ints with a TZERO card.\nNUMPY2FITS[\"u2\"] = \"I\"\nNUMPY2FITS[\"u4\"] = \"J\"\nNUMPY2FITS[\"u8\"] = \"K\"\n# Add half precision floating point numbers which will be up-converted to\n# single precision.\nNUMPY2FITS[\"f2\"] = \"E\"\n\n# This is the order in which values are converted to FITS types\n# Note that only double precision floating point/complex are supported\nFORMATORDER = [\"L\", \"B\", \"I\", \"J\", \"K\", \"D\", \"M\", \"A\"]\n\n# Convert single precision floating point/complex to double precision.\nFITSUPCONVERTERS = {\"E\": \"D\", \"C\": \"M\"}\n\n# mapping from ASCII table TFORM data type to numpy data type\n# A: Character\n# I: Integer (32-bit)\n# J: Integer (64-bit; non-standard)\n# F: Float (64-bit; fixed decimal notation)\n# E: Float (64-bit; exponential notation)\n# D: Float (64-bit; exponential notation, always 64-bit by convention)\nASCII2NUMPY = {\"A\": \"a\", \"I\": \"i4\", \"J\": \"i8\", \"F\": \"f8\", \"E\": \"f8\", \"D\": \"f8\"}\n\n# Maps FITS ASCII column format codes to the appropriate Python string\n# formatting codes for that type.\nASCII2STR = {\"A\": \"\", \"I\": \"d\", \"J\": \"d\", \"F\": \"f\", \"E\": \"E\", \"D\": \"E\"}\n\n# For each ASCII table format code, provides a default width (and decimal\n# precision) for when one isn't given explicitly in the column format\nASCII_DEFAULT_WIDTHS = {\n    \"A\": (1, 0),\n    \"I\": (10, 0),\n    \"J\": (15, 0),\n    \"E\": (15, 7),\n    \"F\": (16, 7),\n    \"D\": (25, 17),\n}\n\n# TDISPn for both ASCII and Binary tables\nTDISP_RE_DICT = {}\nTDISP_RE_DICT[\"F\"] = re.compile(\n    r\"(?:(?P<formatc>[F])(?:(?P<width>[0-9]+)\\.{1}(?P<precision>[0-9])+)+)|\"\n)",
                "filename": "astropy/io/fits/column.py",
                "start_index": 0,
                "end_index": 2933,
                "start_line": 1,
                "end_line": 2756,
                "max_line": 2763,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            },
            {
                "code": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\n\nimport contextlib\nimport csv\nimport operator\nimport os\nimport re\nimport sys\nimport textwrap\nimport warnings\nfrom contextlib import suppress\n\nimport numpy as np\nfrom numpy import char as chararray\n\n# This module may have many dependencies on astropy.io.fits.column, but\n# astropy.io.fits.column has fewer dependencies overall, so it's easier to\n# keep table/column-related utilities in astropy.io.fits.column\nfrom astropy.io.fits.column import (\n    ATTRIBUTE_TO_KEYWORD,\n    FITS2NUMPY,\n    KEYWORD_NAMES,\n    KEYWORD_TO_ATTRIBUTE,\n    TDEF_RE,\n    ColDefs,\n    Column,\n    _AsciiColDefs,\n    _cmp_recformats,\n    _convert_format,\n    _FormatP,\n    _FormatQ,\n    _makep,\n    _parse_tformat,\n    _scalar_to_format,\n)\nfrom astropy.io.fits.fitsrec import FITS_rec, _get_recarray_field, _has_unicode_fields\nfrom astropy.io.fits.header import Header, _pad_length\nfrom astropy.io.fits.util import _is_int, _str_to_num, path_like\nfrom astropy.utils import lazyproperty\nfrom astropy.utils.exceptions import AstropyDeprecationWarning\n\nfrom .base import DELAYED, ExtensionHDU, _ValidHDU\n\n\nclass FITSTableDumpDialect(csv.excel):\n    \"\"\"\n    A CSV dialect for the Astropy format of ASCII dumps of FITS tables.\n    \"\"\"\n\n    delimiter = \" \"\n    lineterminator = \"\\n\"\n    quotechar = '\"'\n    quoting = csv.QUOTE_ALL\n    skipinitialspace = True",
                "filename": "astropy/io/fits/hdu/table.py",
                "start_index": 0,
                "end_index": 1393,
                "start_line": 1,
                "end_line": 55,
                "max_line": 1612,
                "git_instance": "github",
                "repo_name": "testbed/astropy__astropy__5.0",
                "sha": ""
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "astropy/io/fits/hdu/table.py": [
                {
                    "chunk": {
                        "code": "data = hdu.data\n        for idx, length in enumerate(vla_lengths):\n            if length is not None:\n                arr = data.columns._arrays[idx]\n                dt = recformats[idx][len(str(length)) :]\n\n                # NOTE: FormatQ not supported here; it's hard to determine\n                # whether or not it will be necessary to use a wider descriptor\n                # type. The function documentation will have to serve as a\n                # warning that this is not supported.\n                recformats[idx] = _FormatP(dt, max=length)\n                data.columns._recformats[idx] = recformats[idx]\n                name = data.columns.names[idx]\n                data._cache_field(name, _makep(arr, arr, recformats[idx]))\n\n        def format_value(col, val):\n            # Special formatting for a couple particular data types\n            if recformats[col] == FITS2NUMPY[\"L\"]:\n                return bool(int(val))\n            elif recformats[col] == FITS2NUMPY[\"M\"]:\n                # For some reason, in arrays/fields where numpy expects a\n                # complex it's not happy to take a string representation\n                # (though it's happy to do that in other contexts), so we have\n                # to convert the string representation for it:\n                return complex(val)\n            else:\n                return val\n\n        # Jump back to the start of the data and create a new line reader\n        fileobj.seek(initialpos)\n        linereader = csv.reader(fileobj, dialect=FITSTableDumpDialect)\n        for row, line in enumerate(linereader):\n            col = 0\n            idx = 0\n            while idx < len(line):\n                if line[idx] == \"VLA_Length=\":\n                    vla_len = vla_lengths[col]\n                    idx += 2\n                    slice_ = slice(idx, idx + vla_len)\n                    data[row][col][:] = line[idx : idx + vla_len]\n                    idx += vla_len\n                elif dtype[col].shape:\n                    # This is an array column\n                    array_size = int(np.multiply.reduce(dtype[col].shape))\n                    slice_ = slice(idx, idx + array_size)\n                    idx += array_size\n                else:\n                    slice_ = None\n\n                if slice_ is None:\n                    # This is a scalar row element\n                    data[row][col] = format_value(col, line[idx])\n                    idx += 1\n                else:\n                    data[row][col].flat[:] = [\n                        format_value(col, val) for val in line[slice_]\n                    ]\n\n                col += 1\n\n        if close_file:\n            fileobj.close()\n\n        return data",
                        "filename": "astropy/io/fits/hdu/table.py",
                        "start_index": 56804,
                        "end_index": 59493,
                        "start_line": 917,
                        "end_line": 1510,
                        "max_line": 1612,
                        "git_instance": "github",
                        "repo_name": "testbed/astropy__astropy__5.0",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet from 'astropy/io/fits/hdu/table.py' contains code that handles variable length array (VLA) columns in FITS binary tables, which is directly related to the issue of reading binary tables with variable length columns."
                },
                {
                    "chunk": {
                        "code": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\n\nimport contextlib\nimport csv\nimport operator\nimport os\nimport re\nimport sys\nimport textwrap\nimport warnings\nfrom contextlib import suppress\n\nimport numpy as np\nfrom numpy import char as chararray\n\n# This module may have many dependencies on astropy.io.fits.column, but\n# astropy.io.fits.column has fewer dependencies overall, so it's easier to\n# keep table/column-related utilities in astropy.io.fits.column\nfrom astropy.io.fits.column import (\n    ATTRIBUTE_TO_KEYWORD,\n    FITS2NUMPY,\n    KEYWORD_NAMES,\n    KEYWORD_TO_ATTRIBUTE,\n    TDEF_RE,\n    ColDefs,\n    Column,\n    _AsciiColDefs,\n    _cmp_recformats,\n    _convert_format,\n    _FormatP,\n    _FormatQ,\n    _makep,\n    _parse_tformat,\n    _scalar_to_format,\n)\nfrom astropy.io.fits.fitsrec import FITS_rec, _get_recarray_field, _has_unicode_fields\nfrom astropy.io.fits.header import Header, _pad_length\nfrom astropy.io.fits.util import _is_int, _str_to_num, path_like\nfrom astropy.utils import lazyproperty\nfrom astropy.utils.exceptions import AstropyDeprecationWarning\n\nfrom .base import DELAYED, ExtensionHDU, _ValidHDU\n\n\nclass FITSTableDumpDialect(csv.excel):\n    \"\"\"\n    A CSV dialect for the Astropy format of ASCII dumps of FITS tables.\n    \"\"\"\n\n    delimiter = \" \"\n    lineterminator = \"\\n\"\n    quotechar = '\"'\n    quoting = csv.QUOTE_ALL\n    skipinitialspace = True",
                        "filename": "astropy/io/fits/hdu/table.py",
                        "start_index": 0,
                        "end_index": 1393,
                        "start_line": 1,
                        "end_line": 55,
                        "max_line": 1612,
                        "git_instance": "github",
                        "repo_name": "testbed/astropy__astropy__5.0",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet from 'astropy/io/fits/hdu/table.py' includes imports and references to utilities for handling table and column-related operations in FITS files, which may be relevant to the issue of handling variable length array columns."
                }
            ],
            "astropy/io/fits/column.py": [
                {
                    "chunk": {
                        "code": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\nimport copy\nimport numbers\nimport operator\nimport re\nimport sys\nimport warnings\nimport weakref\nfrom collections import OrderedDict\nfrom contextlib import suppress\nfrom functools import reduce\n\nimport numpy as np\nfrom numpy import char as chararray\n\nfrom astropy.utils import indent, isiterable, lazyproperty\nfrom astropy.utils.exceptions import AstropyUserWarning\n\nfrom .card import CARD_LENGTH, Card\nfrom .util import NotifierMixin, _convert_array, _is_int, cmp, encode_ascii, pairwise\nfrom .verify import VerifyError, VerifyWarning\n\n__all__ = [\"Column\", \"ColDefs\", \"Delayed\"]\n\n\n# mapping from TFORM data type to numpy data type (code)\n# L: Logical (Boolean)\n# B: Unsigned Byte\n# I: 16-bit Integer\n# J: 32-bit Integer\n# K: 64-bit Integer\n# E: Single-precision Floating Point\n# D: Double-precision Floating Point\n# C: Single-precision Complex\n# M: Double-precision Complex\n# A: Character\nFITS2NUMPY = {\n    \"L\": \"i1\",\n    \"B\": \"u1\",\n    \"I\": \"i2\",\n    \"J\": \"i4\",\n    \"K\": \"i8\",\n    \"E\": \"f4\",\n    \"D\": \"f8\",\n    \"C\": \"c8\",\n    \"M\": \"c16\",\n    \"A\": \"a\",\n}\n\n# the inverse dictionary of the above\nNUMPY2FITS = {val: key for key, val in FITS2NUMPY.items()}\n# Normally booleans are represented as ints in Astropy, but if passed in a numpy\n# boolean array, that should be supported\nNUMPY2FITS[\"b1\"] = \"L\"\n# Add unsigned types, which will be stored as signed ints with a TZERO card.\nNUMPY2FITS[\"u2\"] = \"I\"\nNUMPY2FITS[\"u4\"] = \"J\"\nNUMPY2FITS[\"u8\"] = \"K\"\n# Add half precision floating point numbers which will be up-converted to\n# single precision.\nNUMPY2FITS[\"f2\"] = \"E\"\n\n# This is the order in which values are converted to FITS types\n# Note that only double precision floating point/complex are supported\nFORMATORDER = [\"L\", \"B\", \"I\", \"J\", \"K\", \"D\", \"M\", \"A\"]\n\n# Convert single precision floating point/complex to double precision.\nFITSUPCONVERTERS = {\"E\": \"D\", \"C\": \"M\"}\n\n# mapping from ASCII table TFORM data type to numpy data type\n# A: Character\n# I: Integer (32-bit)\n# J: Integer (64-bit; non-standard)\n# F: Float (64-bit; fixed decimal notation)\n# E: Float (64-bit; exponential notation)\n# D: Float (64-bit; exponential notation, always 64-bit by convention)\nASCII2NUMPY = {\"A\": \"a\", \"I\": \"i4\", \"J\": \"i8\", \"F\": \"f8\", \"E\": \"f8\", \"D\": \"f8\"}\n\n# Maps FITS ASCII column format codes to the appropriate Python string\n# formatting codes for that type.\nASCII2STR = {\"A\": \"\", \"I\": \"d\", \"J\": \"d\", \"F\": \"f\", \"E\": \"E\", \"D\": \"E\"}\n\n# For each ASCII table format code, provides a default width (and decimal\n# precision) for when one isn't given explicitly in the column format\nASCII_DEFAULT_WIDTHS = {\n    \"A\": (1, 0),\n    \"I\": (10, 0),\n    \"J\": (15, 0),\n    \"E\": (15, 7),\n    \"F\": (16, 7),\n    \"D\": (25, 17),\n}\n\n# TDISPn for both ASCII and Binary tables\nTDISP_RE_DICT = {}\nTDISP_RE_DICT[\"F\"] = re.compile(\n    r\"(?:(?P<formatc>[F])(?:(?P<width>[0-9]+)\\.{1}(?P<precision>[0-9])+)+)|\"\n)",
                        "filename": "astropy/io/fits/column.py",
                        "start_index": 0,
                        "end_index": 2933,
                        "start_line": 1,
                        "end_line": 2756,
                        "max_line": 2763,
                        "git_instance": "github",
                        "repo_name": "testbed/astropy__astropy__5.0",
                        "sha": ""
                    },
                    "reason_for_relevance": "The snippet from 'astropy/io/fits/column.py' defines mappings and conversions between FITS column formats and numpy data types, which is relevant to the issue since the problem involves reading FITS columns with specific data types that are causing errors."
                }
            ],
            "astropy/io/fits/hdu/base.py": [
                {
                    "chunk": {
                        "code": "# Licensed under a 3-clause BSD style license - see PYFITS.rst\n\n\nimport datetime\nimport numbers\nimport os\nimport sys\nimport warnings\nfrom contextlib import suppress\nfrom inspect import Parameter, signature\n\nimport numpy as np\n\nfrom astropy.io.fits import conf\nfrom astropy.io.fits.file import _File\nfrom astropy.io.fits.header import Header, _BasicHeader, _DelayedHeader, _pad_length\nfrom astropy.io.fits.util import (\n    _extract_number,\n    _free_space_check,\n    _get_array_mmap,\n    _is_int,\n    _is_pseudo_integer,\n    _pseudo_zero,\n    decode_ascii,\n    first,\n    itersubclasses,\n)\nfrom astropy.io.fits.verify import _ErrList, _Verify\nfrom astropy.utils import lazyproperty\nfrom astropy.utils.exceptions import AstropyUserWarning\n\n__all__ = [\n    \"DELAYED\",\n    # classes\n    \"InvalidHDUException\",\n    \"ExtensionHDU\",\n    \"NonstandardExtHDU\",\n]\n\n\nclass _Delayed:\n    pass\n\n\nDELAYED = _Delayed()\n\n\nBITPIX2DTYPE = {\n    8: \"uint8\",\n    16: \"int16\",\n    32: \"int32\",\n    64: \"int64\",\n    -32: \"float32\",\n    -64: \"float64\",\n}\n\"\"\"Maps FITS BITPIX values to Numpy dtype names.\"\"\"\n\nDTYPE2BITPIX = {\n    \"int8\": 8,\n    \"uint8\": 8,\n    \"int16\": 16,\n    \"uint16\": 16,\n    \"int32\": 32,\n    \"uint32\": 32,\n    \"int64\": 64,\n    \"uint64\": 64,\n    \"float32\": -32,\n    \"float64\": -64,\n}\n\"\"\"\nMaps Numpy dtype names to FITS BITPIX values (this includes unsigned\nintegers, with the assumption that the pseudo-unsigned integer convention\nwill be used in this case.\n\"\"\"\n\n\nclass InvalidHDUException(Exception):\n    \"\"\"\n    A custom exception class used mainly to signal to _BaseHDU.__new__ that\n    an HDU cannot possibly be considered valid, and must be assumed to be\n    corrupted.\n    \"\"\"",
                        "filename": "astropy/io/fits/hdu/base.py",
                        "start_index": 0,
                        "end_index": 1678,
                        "start_line": 1,
                        "end_line": 1661,
                        "max_line": 1666,
                        "git_instance": "github",
                        "repo_name": "testbed/astropy__astropy__5.0",
                        "sha": ""
                    },
                    "reason_for_relevance": "The snippet from 'astropy/io/fits/hdu/base.py' includes code for handling HDUs (Header Data Units), which could be relevant when investigating issues related to reading and interpreting FITS file structures, including binary tables with variable length columns."
                }
            ]
        },
        "solution_task": "Based on the provided information, the following solutions address the reported issues:\n\n- `IndexError: index 1 is out of bounds for axis 1 with size 1`:\n  - Check the code where the FITS data is being accessed by index. Ensure that the index is within the bounds of the data array's shape.\n  - If using variable-length arrays (VLAs), ensure that the correct lengths are being used when accessing the data.\n\n- `UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 1: ordinal not in range(128)`:\n  - When opening FITS files with `fits.open`, use the `encoding='utf-8'` parameter to handle non-ASCII characters in the header.\n  - If the error occurs during file reading, ensure that the correct encoding is specified when reading text data.\n\n- `OSError: Header missing END card.`:\n  - Verify that the FITS file is not corrupted and contains a valid header with an `END` card.\n  - If creating or modifying a FITS header, ensure that the `END` card is properly written.\n\n- For handling variable-length array columns in FITS binary tables:\n  - When creating columns with variable-length arrays, use the correct `format` specifier, such as `'1PJ(1)'` for a 1-dimensional array of variable length.\n  - Ensure that the `fits.Column` objects are created with the correct `dtype` and `format` that match the data being written.\n\n- For issues related to writing and reading n-dimensional arrays in VLA columns:\n  - Ensure that the `format` specified in `fits.Column` is correct for the dimensionality of the array. For example, use `'1PJ(n)'` where `n` is the size of the array dimension.\n  - When reading the data back, ensure that the correct shape is reconstructed from the VLA data.\n\n- General advice for reading and writing FITS files with `astropy.io.fits`:\n  - Always check the version of Astropy to ensure compatibility with FITS standards, especially for advanced features like VLAs.\n  - Use `fits.verify` to check the compliance of FITS files with the standard.\n  - When encountering errors, use `fits.open` with the `ignore_missing_end=True` parameter to attempt to open files with missing `END` cards.\n\n- For the specific error messages and code snippets provided:\n  - Check the usage of `fits.BinTableHDU.from_columns` to ensure that the columns are defined with the correct formats and data types.\n  - If using `np.array`, `np.ones`, or `np.full` to create data arrays, ensure that the resulting arrays have the correct shape and data type before inserting them into FITS columns.\n  - When writing data with `writeto`, use `overwrite=True` to avoid issues with existing files.\n  - If the FITS file structure includes binary table extensions with variable length columns, ensure that the FITS standard for multi-dimensional VLAs is followed.",
        "bouncer_response": {
            "score": 2,
            "criteria": "The RESPONSE provides some generic advice and references to code snippets that could be related to the issue, but it lacks actionable, specific guidance to resolve the described bug.",
            "supporting_evidence": "The RESPONSE offers generic advice such as checking array bounds and ensuring the correct format specifiers are used, which is somewhat relevant but not directly actionable for the specific issue described in the PROMPT. The advice to use 'encoding=\"utf-8\"' when opening FITS files is not applicable to the issue at hand, as the problem is not related to character encoding but to the handling of variable-length array columns. The RESPONSE also suggests using 'fits.verify' and 'ignore_missing_end=True', which are not directly related to the problem of reading and writing multi-dimensional arrays in VLA columns. The code snippets provided are from a repository that does not exist (the links are placeholders), and therefore, they do not add any value to the RESPONSE. Overall, the RESPONSE fails to provide precise, actionable guidance and does not directly address all aspects of the described bug.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711736575.868211,
        "result": "Doesn't seem like we have fully grasped all the specifics of this ticket \ud83d\ude15.                   But we've outlined some ideas that might help you get started:\n\nBased on the provided information, the following solutions address the reported issues:\n\n- `IndexError: index 1 is out of bounds for axis 1 with size 1`:\n  - Check the code where the FITS data is being accessed by index. Ensure that the index is within the bounds of the data array's shape.\n  - If using variable-length arrays (VLAs), ensure that the correct lengths are being used when accessing the data.\n\n- `UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 1: ordinal not in range(128)`:\n  - When opening FITS files with `fits.open`, use the `encoding='utf-8'` parameter to handle non-ASCII characters in the header.\n  - If the error occurs during file reading, ensure that the correct encoding is specified when reading text data.\n\n- `OSError: Header missing END card.`:\n  - Verify that the FITS file is not corrupted and contains a valid header with an `END` card.\n  - If creating or modifying a FITS header, ensure that the `END` card is properly written.\n\n- For handling variable-length array columns in FITS binary tables:\n  - When creating columns with variable-length arrays, use the correct `format` specifier, such as `'1PJ(1)'` for a 1-dimensional array of variable length.\n  - Ensure that the `fits.Column` objects are created with the correct `dtype` and `format` that match the data being written.\n\n- For issues related to writing and reading n-dimensional arrays in VLA columns:\n  - Ensure that the `format` specified in `fits.Column` is correct for the dimensionality of the array. For example, use `'1PJ(n)'` where `n` is the size of the array dimension.\n  - When reading the data back, ensure that the correct shape is reconstructed from the VLA data.\n\n- General advice for reading and writing FITS files with `astropy.io.fits`:\n  - Always check the version of Astropy to ensure compatibility with FITS standards, especially for advanced features like VLAs.\n  - Use `fits.verify` to check the compliance of FITS files with the standard.\n  - When encountering errors, use `fits.open` with the `ignore_missing_end=True` parameter to attempt to open files with missing `END` cards.\n\n- For the specific error messages and code snippets provided:\n  - Check the usage of `fits.BinTableHDU.from_columns` to ensure that the columns are defined with the correct formats and data types.\n  - If using `np.array`, `np.ones`, or `np.full` to create data arrays, ensure that the resulting arrays have the correct shape and data type before inserting them into FITS columns.\n  - When writing data with `writeto`, use `overwrite=True` to avoid issues with existing files.\n  - If the FITS file structure includes binary table extensions with variable length columns, ensure that the FITS standard for multi-dimensional VLAs is followed.\n\n### Code snippets to check\n\n-  \u2192 [astropy](https://github.com/testbed/astropy__astropy__5.0/tree//astropy) \u2192 [io](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io) \u2192 [fits](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits) \u2192 [hdu](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits/hdu)- [Lines 917 - 1510](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/hdu/table.py#L917-L1510)\n\n This snippet from 'astropy/io/fits/hdu/table.py' contains code that handles variable length array (VLA) columns in FITS binary tables, which is directly related to the issue of reading binary tables with variable length columns. \n\n\n   - [Lines 1 - 55](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/hdu/table.py#L1-L55)\n\n This snippet from 'astropy/io/fits/hdu/table.py' includes imports and references to utilities for handling table and column-related operations in FITS files, which may be relevant to the issue of handling variable length array columns.\n-  \u2192 [astropy](https://github.com/testbed/astropy__astropy__5.0/tree//astropy) \u2192 [io](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io) \u2192 [fits](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits)- [Lines 1 - 2756](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/column.py#L1-L2756)\n\n The snippet from 'astropy/io/fits/column.py' defines mappings and conversions between FITS column formats and numpy data types, which is relevant to the issue since the problem involves reading FITS columns with specific data types that are causing errors.\n-  \u2192 [astropy](https://github.com/testbed/astropy__astropy__5.0/tree//astropy) \u2192 [io](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io) \u2192 [fits](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits) \u2192 [hdu](https://github.com/testbed/astropy__astropy__5.0/tree//astropy/io/fits/hdu)- [Lines 1 - 1661](https://github.com/testbed/astropy__astropy__5.0/blob//astropy/io/fits/hdu/base.py#L1-L1661)\n\n The snippet from 'astropy/io/fits/hdu/base.py' includes code for handling HDUs (Header Data Units), which could be relevant when investigating issues related to reading and interpreting FITS file structures, including binary tables with variable length columns."
    }
}