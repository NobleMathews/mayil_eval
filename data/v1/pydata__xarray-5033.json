{
    "id": "pydata__xarray-5033",
    "repo_name": "testbed/pydata__xarray__0.12",
    "task_id": 1206165826215451465,
    "title": "Simplify adding custom backends",
    "body": "<!-- Please do a quick search of existing issues to make sure that this has not been asked before. -->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI've been working on opening custom hdf formats in xarray, reading up on the apiv2 it is currently only possible to declare a new external plugin in setup.py but that doesn't seem easy or intuitive to me.\r\n\r\n**Describe the solution you'd like**\r\nWhy can't we simply be allowed to add functions to the engine parameter? Example:\r\n```python\r\nfrom custom_backend import engine\r\n\r\nds = xr.load_dataset(filename, engine=engine)\r\n```\r\nThis seems like a small function change to me from my initial _quick_ look because there's mainly a bunch of string checks in the normal case until we get to the registered backend functions, if we send in a function instead in the engine-parameter we can just bypass those checks.\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/pydata__xarray__0.12.git",
    "requested_commit": "",
    "mayil_response": "To implement the feature request of allowing custom backends to be added via a function to the `engine` parameter, you can modify the `get_backend` function in `xarray/backends/plugins.py` to accept a callable as an engine. Here's a high-level overview of the steps:\n\n- Modify the `get_backend` function to check if the `engine` parameter is a callable function.\n- If it is a callable, use it directly as the backend without going through the registered backend entry points.\n- Ensure that the callable provided adheres to the `BackendEntrypoint` interface, particularly the `open_dataset` method.\n\nHere's a code snippet that demonstrates these changes:\n\n```python\n# In xarray/backends/plugins.py\n\ndef get_backend(engine: str | type[BackendEntrypoint] | Callable) -> BackendEntrypoint:\n    \"\"\"Select open_dataset method based on current engine.\"\"\"\n    if isinstance(engine, str):\n        engines = list_engines()\n        if engine not in engines:\n            raise ValueError(\n                f\"unrecognized engine {engine} must be one of: {list(engines)}\"\n            )\n        backend = engines[engine]\n    elif isinstance(engine, type) and issubclass(engine, BackendEntrypoint):\n        backend = engine()\n    elif callable(engine):\n        # Check if the callable adheres to the BackendEntrypoint interface\n        required_methods = ['open_dataset']\n        if all(hasattr(engine, method) for method in required_methods):\n            backend = engine\n        else:\n            raise TypeError(\n                \"engine must be a string, a subclass of \"\n                \"xarray.backends.BackendEntrypoint, or a callable with required methods: \"\n                f\"{required_methods}\"\n            )\n    else:\n        raise TypeError(\n            \"engine must be a string, a subclass of \"\n            \"xarray.backends.BackendEntrypoint, or a callable\"\n        )\n\n    return backend\n```\n\nWith this change, users can now pass a custom backend function directly to the `engine` parameter when calling `xr.load_dataset`:\n\n```python\nfrom custom_backend import custom_open_dataset\n\nds = xr.load_dataset(filename, engine=custom_open_dataset)\n```\n\nMake sure to update the documentation to reflect this new capability and provide guidelines on how to create a callable that is compatible with the `BackendEntrypoint` interface.\n\n### Code snippets to check\n\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [backends](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/backends)- [Lines 147 - 217](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/backends/plugins.py#L147-L217)\n\n This snippet contains the 'get_backend' function which is responsible for selecting the backend based on the engine parameter. It needs to be modified to allow passing a function directly to the engine parameter.\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [backends](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/backends)- [Lines 435 - 513](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/backends/common.py#L435-L513)\n\n This snippet defines the 'BackendEntrypoint' class which is the base class for all backend entry points. It may need to be reviewed to ensure that custom backend functions can be integrated seamlessly.\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [backends](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/backends)- [Lines 1 - 131](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/backends/api.py#L1-L131)\n\n This snippet from 'xarray/backends/api.py' includes the logic for opening datasets and may need to be updated to support the direct use of functions as the engine parameter.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0005495,
        "snippet_processor": 0.06112,
        "issue_star_creation": 0.025959999999999997,
        "issue_star_solver": 0.08023,
        "bouncer": 0.027180000000000003
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711759330.7312489,
        "relevant_snippets": [
            {
                "code": "name: \ud83d\udca1 Feature Request\ndescription: Suggest an idea for xarray\nlabels: [enhancement]\nbody:\n  - type: textarea\n    id: description\n    attributes:\n      label: Is your feature request related to a problem?\n      description: |\n        Please do a quick search of existing issues to make sure that this has not been asked before.\n        Please provide a clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\n    validations:\n      required: true\n  - type: textarea\n    id: solution\n    attributes:\n      label: Describe the solution you'd like\n      description: |\n        A clear and concise description of what you want to happen.\n  - type: textarea\n    id: alternatives\n    attributes:\n      label: Describe alternatives you've considered\n      description: |\n        A clear and concise description of any alternative solutions or features you've considered.\n    validations:\n      required: false\n  - type: textarea\n    id: additional-context\n    attributes:\n      label: Additional context\n      description: |\n        Add any other context about the feature request here.\n    validations:\n      required: false",
                "filename": ".github/ISSUE_TEMPLATE/newfeature.yml",
                "start_index": 0,
                "end_index": 1154,
                "start_line": 1,
                "end_line": 35,
                "max_line": 35,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "def guess_engine(\n    store_spec: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n) -> str | type[BackendEntrypoint]:\n    engines = list_engines()\n\n    for engine, backend in engines.items():\n        try:\n            if backend.guess_can_open(store_spec):\n                return engine\n        except PermissionError:\n            raise\n        except Exception:\n            warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n\n    compatible_engines = []\n    for engine, (_, backend_cls) in BACKEND_ENTRYPOINTS.items():\n        try:\n            backend = backend_cls()\n            if backend.guess_can_open(store_spec):\n                compatible_engines.append(engine)\n        except Exception:\n            warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n\n    installed_engines = [k for k in engines if k != \"store\"]\n    if not compatible_engines:\n        if installed_engines:\n            error_msg = (\n                \"did not find a match in any of xarray's currently installed IO \"\n                f\"backends {installed_engines}. Consider explicitly selecting one of the \"\n                \"installed engines via the ``engine`` parameter, or installing \"\n                \"additional IO dependencies, see:\\n\"\n                \"https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\\n\"\n                \"https://docs.xarray.dev/en/stable/user-guide/io.html\"\n            )\n        else:\n            error_msg = (\n                \"xarray is unable to open this file because it has no currently \"\n                \"installed IO backends. Xarray's read/write support requires \"\n                \"installing optional IO dependencies, see:\\n\"\n                \"https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\\n\"\n                \"https://docs.xarray.dev/en/stable/user-guide/io\"\n            )\n    else:\n        error_msg = (\n            \"found the following matches with the input file in xarray's IO \"\n            f\"backends: {compatible_engines}. But their dependencies may not be installed, see:\\n\"\n            \"https://docs.xarray.dev/en/stable/user-guide/io.html \\n\"\n            \"https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\"\n        )\n\n    raise ValueError(error_msg)\n\n\ndef get_backend(engine: str | type[BackendEntrypoint]) -> BackendEntrypoint:\n    \"\"\"Select open_dataset method based on current engine.\"\"\"\n    if isinstance(engine, str):\n        engines = list_engines()\n        if engine not in engines:\n            raise ValueError(\n                f\"unrecognized engine {engine} must be one of: {list(engines)}\"\n            )\n        backend = engines[engine]\n    elif isinstance(engine, type) and issubclass(engine, BackendEntrypoint):\n        backend = engine()\n    else:\n        raise TypeError(\n            \"engine must be a string or a subclass of \"\n            f\"xarray.backends.BackendEntrypoint: {engine}\"\n        )\n\n    return backend",
                "filename": "xarray/backends/plugins.py",
                "start_index": 5213,
                "end_index": 8171,
                "start_line": 147,
                "end_line": 217,
                "max_line": 217,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "class WritableCFDataStore(AbstractWritableDataStore):\n    __slots__ = ()\n\n    def encode(self, variables, attributes):\n        # All NetCDF files get CF encoded by default, without this attempting\n        # to write times, for example, would fail.\n        variables, attributes = cf_encoder(variables, attributes)\n        variables = {k: self.encode_variable(v) for k, v in variables.items()}\n        attributes = {k: self.encode_attribute(v) for k, v in attributes.items()}\n        return variables, attributes\n\n\nclass BackendEntrypoint:\n    \"\"\"\n    ``BackendEntrypoint`` is a class container and it is the main interface\n    for the backend plugins, see :ref:`RST backend_entrypoint`.\n    It shall implement:\n\n    - ``open_dataset`` method: it shall implement reading from file, variables\n      decoding and it returns an instance of :py:class:`~xarray.Dataset`.\n      It shall take in input at least ``filename_or_obj`` argument and\n      ``drop_variables`` keyword argument.\n      For more details see :ref:`RST open_dataset`.\n    - ``guess_can_open`` method: it shall return ``True`` if the backend is able to open\n      ``filename_or_obj``, ``False`` otherwise. The implementation of this\n      method is not mandatory.\n\n    Attributes\n    ----------\n\n    open_dataset_parameters : tuple, default: None\n        A list of ``open_dataset`` method parameters.\n        The setting of this attribute is not mandatory.\n    description : str, default: \"\"\n        A short string describing the engine.\n        The setting of this attribute is not mandatory.\n    url : str, default: \"\"\n        A string with the URL to the backend's documentation.\n        The setting of this attribute is not mandatory.\n    \"\"\"\n\n    open_dataset_parameters: ClassVar[tuple | None] = None\n    description: ClassVar[str] = \"\"\n    url: ClassVar[str] = \"\"\n\n    def __repr__(self) -> str:\n        txt = f\"<{type(self).__name__}>\"\n        if self.description:\n            txt += f\"\\n  {self.description}\"\n        if self.url:\n            txt += f\"\\n  Learn more at {self.url}\"\n        return txt\n\n    def open_dataset(\n        self,\n        filename_or_obj: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n        *,\n        drop_variables: str | Iterable[str] | None = None,\n        **kwargs: Any,\n    ) -> Dataset:\n        \"\"\"\n        Backend open_dataset method used by Xarray in :py:func:`~xarray.open_dataset`.\n        \"\"\"\n\n        raise NotImplementedError\n\n    def guess_can_open(\n        self,\n        filename_or_obj: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n    ) -> bool:\n        \"\"\"\n        Backend open_dataset method used by Xarray in :py:func:`~xarray.open_dataset`.\n        \"\"\"\n\n        return False\n\n\n# mapping of engine name to (module name, BackendEntrypoint Class)\nBACKEND_ENTRYPOINTS: dict[str, tuple[str | None, type[BackendEntrypoint]]] = {}",
                "filename": "xarray/backends/common.py",
                "start_index": 13469,
                "end_index": 16341,
                "start_line": 435,
                "end_line": 513,
                "max_line": 513,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "\"\"\"\nUseful for:\n\n* users learning xarray\n* building tutorials in the documentation.\n\n\"\"\"\nfrom __future__ import annotations\n\nimport os\nimport pathlib\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\n\nfrom xarray.backends.api import open_dataset as _open_dataset\nfrom xarray.core.dataarray import DataArray\nfrom xarray.core.dataset import Dataset\n\nif TYPE_CHECKING:\n    from xarray.backends.api import T_Engine\n\n\n_default_cache_dir_name = \"xarray_tutorial_data\"\nbase_url = \"https://github.com/pydata/xarray-data\"\nversion = \"master\"\n\n\ndef _construct_cache_dir(path):\n    import pooch\n\n    if isinstance(path, os.PathLike):\n        path = os.fspath(path)\n    elif path is None:\n        path = pooch.os_cache(_default_cache_dir_name)\n\n    return path\n\n\nexternal_urls = {}  # type: dict\nfile_formats = {\n    \"air_temperature\": 3,\n    \"air_temperature_gradient\": 4,\n    \"ASE_ice_velocity\": 4,\n    \"basin_mask\": 4,\n    \"ersstv5\": 4,\n    \"rasm\": 3,\n    \"ROMS_example\": 4,\n    \"tiny\": 3,\n    \"eraint_uvz\": 3,\n}\n\n\ndef _check_netcdf_engine_installed(name):\n    version = file_formats.get(name)\n    if version == 3:\n        try:\n            import scipy  # noqa\n        except ImportError:\n            try:\n                import netCDF4  # noqa\n            except ImportError:\n                raise ImportError(\n                    f\"opening tutorial dataset {name} requires either scipy or \"\n                    \"netCDF4 to be installed.\"\n                )\n    if version == 4:\n        try:\n            import h5netcdf  # noqa\n        except ImportError:\n            try:\n                import netCDF4  # noqa\n            except ImportError:\n                raise ImportError(\n                    f\"opening tutorial dataset {name} requires either h5netcdf \"\n                    \"or netCDF4 to be installed.\"\n                )\n\n\n# idea borrowed from Seaborn",
                "filename": "xarray/tutorial.py",
                "start_index": 0,
                "end_index": 1851,
                "start_line": 1,
                "end_line": 80,
                "max_line": 243,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "class PerformanceBackend(xr.backends.BackendEntrypoint):\n            def open_dataset(\n                self,\n                filename_or_obj: str | os.PathLike | None,\n                drop_variables: tuple[str] = None,\n                *,\n                mask_and_scale=True,\n                decode_times=True,\n                concat_characters=True,\n                decode_coords=True,\n                use_cftime=None,\n                decode_timedelta=None,\n                lock=None,\n                **kwargs,\n            ) -> xr.Dataset:\n                filename_or_obj = xr.backends.common._normalize_path(filename_or_obj)\n                store = PerformanceStore.open(filename_or_obj, lock=lock)\n\n                store_entrypoint = xr.backends.store.StoreBackendEntrypoint()\n\n                ds = store_entrypoint.open_dataset(\n                    store,\n                    mask_and_scale=mask_and_scale,\n                    decode_times=decode_times,\n                    concat_characters=concat_characters,\n                    decode_coords=decode_coords,\n                    drop_variables=drop_variables,\n                    use_cftime=use_cftime,\n                    decode_timedelta=decode_timedelta,\n                )\n                return ds\n\n        self.engine = PerformanceBackend",
                "filename": "asv_bench/benchmarks/dataset_io.py",
                "start_index": 20011,
                "end_index": 21308,
                "start_line": 612,
                "end_line": 644,
                "max_line": 652,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "from __future__ import annotations\n\nimport functools\nimport inspect\nimport itertools\nimport sys\nimport warnings\nfrom importlib.metadata import entry_points\nfrom typing import TYPE_CHECKING, Any, Callable\n\nfrom xarray.backends.common import BACKEND_ENTRYPOINTS, BackendEntrypoint\nfrom xarray.core.utils import module_available\n\nif TYPE_CHECKING:\n    import os\n    from importlib.metadata import EntryPoint\n\n    if sys.version_info >= (3, 10):\n        from importlib.metadata import EntryPoints\n    else:\n        EntryPoints = list[EntryPoint]\n    from io import BufferedIOBase\n\n    from xarray.backends.common import AbstractDataStore\n\nSTANDARD_BACKENDS_ORDER = [\"netcdf4\", \"h5netcdf\", \"scipy\"]\n\n\ndef remove_duplicates(entrypoints: EntryPoints) -> list[EntryPoint]:\n    # sort and group entrypoints by name\n    entrypoints_sorted = sorted(entrypoints, key=lambda ep: ep.name)\n    entrypoints_grouped = itertools.groupby(entrypoints_sorted, key=lambda ep: ep.name)\n    # check if there are multiple entrypoints for the same name\n    unique_entrypoints = []\n    for name, _matches in entrypoints_grouped:\n        # remove equal entrypoints\n        matches = list(set(_matches))\n        unique_entrypoints.append(matches[0])\n        matches_len = len(matches)\n        if matches_len > 1:\n            all_module_names = [e.value.split(\":\")[0] for e in matches]\n            selected_module_name = all_module_names[0]\n            warnings.warn(\n                f\"Found {matches_len} entrypoints for the engine name {name}:\"\n                f\"\\n {all_module_names}.\\n \"\n                f\"The entrypoint {selected_module_name} will be used.\",\n                RuntimeWarning,\n            )\n    return unique_entrypoints\n\n\ndef detect_parameters(open_dataset: Callable) -> tuple[str, ...]:\n    signature = inspect.signature(open_dataset)\n    parameters = signature.parameters\n    parameters_list = []\n    for name, param in parameters.items():\n        if param.kind in (\n            inspect.Parameter.VAR_KEYWORD,\n            inspect.Parameter.VAR_POSITIONAL,\n        ):\n            raise TypeError(\n                f\"All the parameters in {open_dataset!r} signature should be explicit. \"\n                \"*args and **kwargs is not supported\"\n            )\n        if name != \"self\":\n            parameters_list.append(name)\n    return tuple(parameters_list)\n\n\ndef backends_dict_from_pkg(\n    entrypoints: list[EntryPoint],\n) -> dict[str, type[BackendEntrypoint]]:\n    backend_entrypoints = {}\n    for entrypoint in entrypoints:\n        name = entrypoint.name\n        try:\n            backend = entrypoint.load()\n            backend_entrypoints[name] = backend\n        except Exception as ex:\n            warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n    return backend_entrypoints",
                "filename": "xarray/backends/plugins.py",
                "start_index": 0,
                "end_index": 2795,
                "start_line": 1,
                "end_line": 81,
                "max_line": 217,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "from __future__ import annotations\n\nimport os\nfrom collections.abc import Hashable, Iterable, Mapping, MutableMapping, Sequence\nfrom functools import partial\nfrom io import BytesIO\nfrom numbers import Number\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Final,\n    Literal,\n    Union,\n    cast,\n    overload,\n)\n\nimport numpy as np\n\nfrom xarray import backends, conventions\nfrom xarray.backends import plugins\nfrom xarray.backends.common import (\n    AbstractDataStore,\n    ArrayWriter,\n    _find_absolute_paths,\n    _normalize_path,\n)\nfrom xarray.backends.locks import _get_scheduler\nfrom xarray.core import indexing\nfrom xarray.core.combine import (\n    _infer_concat_order_from_positions,\n    _nested_combine,\n    combine_by_coords,\n)\nfrom xarray.core.daskmanager import DaskManager\nfrom xarray.core.dataarray import DataArray\nfrom xarray.core.dataset import Dataset, _get_chunk, _maybe_chunk\nfrom xarray.core.indexes import Index\nfrom xarray.core.parallelcompat import guess_chunkmanager\nfrom xarray.core.utils import is_remote_uri\n\nif TYPE_CHECKING:\n    try:\n        from dask.delayed import Delayed\n    except ImportError:\n        Delayed = None  # type: ignore\n    from io import BufferedIOBase\n\n    from xarray.backends.common import BackendEntrypoint\n    from xarray.core.types import (\n        CombineAttrsOptions,\n        CompatOptions,\n        JoinOptions,\n        NestedSequence,\n        T_Chunks,\n    )\n\n    T_NetcdfEngine = Literal[\"netcdf4\", \"scipy\", \"h5netcdf\"]\n    T_Engine = Union[\n        T_NetcdfEngine,\n        Literal[\"pydap\", \"pynio\", \"pseudonetcdf\", \"zarr\"],\n        type[BackendEntrypoint],\n        str,  # no nice typing support for custom backends\n        None,\n    ]\n    T_NetcdfTypes = Literal[\n        \"NETCDF4\", \"NETCDF4_CLASSIC\", \"NETCDF3_64BIT\", \"NETCDF3_CLASSIC\"\n    ]\n\n\nDATAARRAY_NAME = \"__xarray_dataarray_name__\"\nDATAARRAY_VARIABLE = \"__xarray_dataarray_variable__\"\n\nENGINES = {\n    \"netcdf4\": backends.NetCDF4DataStore.open,\n    \"scipy\": backends.ScipyDataStore,\n    \"pydap\": backends.PydapDataStore.open,\n    \"h5netcdf\": backends.H5NetCDFStore.open,\n    \"pynio\": backends.NioDataStore,\n    \"pseudonetcdf\": backends.PseudoNetCDFDataStore.open,\n    \"zarr\": backends.ZarrStore.open_group,\n}\n\n\ndef _get_default_engine_remote_uri() -> Literal[\"netcdf4\", \"pydap\"]:\n    engine: Literal[\"netcdf4\", \"pydap\"]\n    try:\n        import netCDF4  # noqa: F401\n\n        engine = \"netcdf4\"\n    except ImportError:  # pragma: no cover\n        try:\n            import pydap  # noqa: F401\n\n            engine = \"pydap\"\n        except ImportError:\n            raise ValueError(\n                \"netCDF4 or pydap is required for accessing \"\n                \"remote datasets via OPeNDAP\"\n            )\n    return engine",
                "filename": "xarray/backends/api.py",
                "start_index": 0,
                "end_index": 2756,
                "start_line": 1,
                "end_line": 131,
                "max_line": 1703,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "class PseudoNetCDFBackendEntrypoint(BackendEntrypoint):\n    \"\"\"\n    Backend for netCDF-like data formats in the air quality field\n    based on the PseudoNetCDF package.\n\n    It can open:\n    - CAMx\n    - RACM2 box-model outputs\n    - Kinetic Pre-Processor outputs\n    - ICARTT Data files (ffi1001)\n    - CMAQ Files\n    - GEOS-Chem Binary Punch/NetCDF files\n    - and many more\n\n    This backend is not selected by default for any files, so make\n    sure to specify ``engine=\"pseudonetcdf\"`` in ``open_dataset``.\n\n    For more information about the underlying library, visit:\n    https://pseudonetcdf.readthedocs.io\n\n    See Also\n    --------\n    backends.PseudoNetCDFDataStore\n    \"\"\"\n\n    description = (\n        \"Open many atmospheric science data formats using PseudoNetCDF in Xarray\"\n    )\n    url = \"https://docs.xarray.dev/en/stable/generated/xarray.backends.PseudoNetCDFBackendEntrypoint.html\"\n\n    # *args and **kwargs are not allowed in open_backend_dataset_ kwargs,\n    # unless the open_dataset_parameters are explicitly defined like this:\n    open_dataset_parameters = (\n        \"filename_or_obj\",\n        \"mask_and_scale\",\n        \"decode_times\",\n        \"concat_characters\",\n        \"decode_coords\",\n        \"drop_variables\",\n        \"use_cftime\",\n        \"decode_timedelta\",\n        \"mode\",\n        \"lock\",\n    )\n\n    def open_dataset(\n        self,\n        filename_or_obj: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n        mask_and_scale=False,\n        decode_times=True,\n        concat_characters=True,\n        decode_coords=True,\n        drop_variables: str | Iterable[str] | None = None,\n        use_cftime=None,\n        decode_timedelta=None,\n        mode=None,\n        lock=None,\n        **format_kwargs,\n    ) -> Dataset:\n        filename_or_obj = _normalize_path(filename_or_obj)\n        store = PseudoNetCDFDataStore.open(\n            filename_or_obj, lock=lock, mode=mode, **format_kwargs\n        )\n\n        store_entrypoint = StoreBackendEntrypoint()\n        with close_on_error(store):\n            ds = store_entrypoint.open_dataset(\n                store,\n                mask_and_scale=mask_and_scale,\n                decode_times=decode_times,\n                concat_characters=concat_characters,\n                decode_coords=decode_coords,\n                drop_variables=drop_variables,\n                use_cftime=use_cftime,\n                decode_timedelta=decode_timedelta,\n            )\n        return ds\n\n\nBACKEND_ENTRYPOINTS[\"pseudonetcdf\"] = (\"PseudoNetCDF\", PseudoNetCDFBackendEntrypoint)",
                "filename": "xarray/backends/pseudonetcdf_.py",
                "start_index": 3147,
                "end_index": 5695,
                "start_line": 108,
                "end_line": 187,
                "max_line": 187,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "def set_missing_parameters(\n    backend_entrypoints: dict[str, type[BackendEntrypoint]]\n) -> None:\n    for _, backend in backend_entrypoints.items():\n        if backend.open_dataset_parameters is None:\n            open_dataset = backend.open_dataset\n            backend.open_dataset_parameters = detect_parameters(open_dataset)\n\n\ndef sort_backends(\n    backend_entrypoints: dict[str, type[BackendEntrypoint]]\n) -> dict[str, type[BackendEntrypoint]]:\n    ordered_backends_entrypoints = {}\n    for be_name in STANDARD_BACKENDS_ORDER:\n        if backend_entrypoints.get(be_name, None) is not None:\n            ordered_backends_entrypoints[be_name] = backend_entrypoints.pop(be_name)\n    ordered_backends_entrypoints.update(\n        {name: backend_entrypoints[name] for name in sorted(backend_entrypoints)}\n    )\n    return ordered_backends_entrypoints\n\n\ndef build_engines(entrypoints: EntryPoints) -> dict[str, BackendEntrypoint]:\n    backend_entrypoints: dict[str, type[BackendEntrypoint]] = {}\n    for backend_name, (module_name, backend) in BACKEND_ENTRYPOINTS.items():\n        if module_name is None or module_available(module_name):\n            backend_entrypoints[backend_name] = backend\n    entrypoints_unique = remove_duplicates(entrypoints)\n    external_backend_entrypoints = backends_dict_from_pkg(entrypoints_unique)\n    backend_entrypoints.update(external_backend_entrypoints)\n    backend_entrypoints = sort_backends(backend_entrypoints)\n    set_missing_parameters(backend_entrypoints)\n    return {name: backend() for name, backend in backend_entrypoints.items()}\n\n\n@functools.lru_cache(maxsize=1)\ndef list_engines() -> dict[str, BackendEntrypoint]:\n    \"\"\"\n    Return a dictionary of available engines and their BackendEntrypoint objects.\n\n    Returns\n    -------\n    dictionary\n\n    Notes\n    -----\n    This function lives in the backends namespace (``engs=xr.backends.list_engines()``).\n    If available, more information is available about each backend via ``engs[\"eng_name\"]``.\n\n    # New selection mechanism introduced with Python 3.10. See GH6514.\n    \"\"\"\n    if sys.version_info >= (3, 10):\n        entrypoints = entry_points(group=\"xarray.backends\")\n    else:\n        entrypoints = entry_points().get(\"xarray.backends\", [])\n    return build_engines(entrypoints)\n\n\ndef refresh_engines() -> None:\n    \"\"\"Refreshes the backend engines based on installed packages.\"\"\"\n    list_engines.cache_clear()",
                "filename": "xarray/backends/plugins.py",
                "start_index": 2798,
                "end_index": 5210,
                "start_line": 84,
                "end_line": 144,
                "max_line": 217,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            },
            {
                "code": "from __future__ import annotations\n\nfrom collections.abc import Iterable\nfrom typing import TYPE_CHECKING, Any\n\nfrom xarray import conventions\nfrom xarray.backends.common import (\n    BACKEND_ENTRYPOINTS,\n    AbstractDataStore,\n    BackendEntrypoint,\n)\nfrom xarray.core.dataset import Dataset\n\nif TYPE_CHECKING:\n    import os\n    from io import BufferedIOBase\n\n\nclass StoreBackendEntrypoint(BackendEntrypoint):\n    description = \"Open AbstractDataStore instances in Xarray\"\n    url = \"https://docs.xarray.dev/en/stable/generated/xarray.backends.StoreBackendEntrypoint.html\"\n\n    def guess_can_open(\n        self,\n        filename_or_obj: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n    ) -> bool:\n        return isinstance(filename_or_obj, AbstractDataStore)\n\n    def open_dataset(  # type: ignore[override]  # allow LSP violation, not supporting **kwargs\n        self,\n        filename_or_obj: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n        *,\n        mask_and_scale=True,\n        decode_times=True,\n        concat_characters=True,\n        decode_coords=True,\n        drop_variables: str | Iterable[str] | None = None,\n        use_cftime=None,\n        decode_timedelta=None,\n    ) -> Dataset:\n        assert isinstance(filename_or_obj, AbstractDataStore)\n\n        vars, attrs = filename_or_obj.load()\n        encoding = filename_or_obj.get_encoding()\n\n        vars, attrs, coord_names = conventions.decode_cf_variables(\n            vars,\n            attrs,\n            mask_and_scale=mask_and_scale,\n            decode_times=decode_times,\n            concat_characters=concat_characters,\n            decode_coords=decode_coords,\n            drop_variables=drop_variables,\n            use_cftime=use_cftime,\n            decode_timedelta=decode_timedelta,\n        )\n\n        ds = Dataset(vars, attrs=attrs)\n        ds = ds.set_coords(coord_names.intersection(vars))\n        ds.set_close(filename_or_obj.close)\n        ds.encoding = encoding\n\n        return ds\n\n\nBACKEND_ENTRYPOINTS[\"store\"] = (None, StoreBackendEntrypoint)",
                "filename": "xarray/backends/store.py",
                "start_index": 0,
                "end_index": 2061,
                "start_line": 1,
                "end_line": 66,
                "max_line": 66,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__0.12",
                "sha": ""
            }
        ],
        "classification": "feature request",
        "snippet_processor_task": {
            "xarray/backends/plugins.py": [
                {
                    "chunk": {
                        "code": "def guess_engine(\n    store_spec: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n) -> str | type[BackendEntrypoint]:\n    engines = list_engines()\n\n    for engine, backend in engines.items():\n        try:\n            if backend.guess_can_open(store_spec):\n                return engine\n        except PermissionError:\n            raise\n        except Exception:\n            warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n\n    compatible_engines = []\n    for engine, (_, backend_cls) in BACKEND_ENTRYPOINTS.items():\n        try:\n            backend = backend_cls()\n            if backend.guess_can_open(store_spec):\n                compatible_engines.append(engine)\n        except Exception:\n            warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n\n    installed_engines = [k for k in engines if k != \"store\"]\n    if not compatible_engines:\n        if installed_engines:\n            error_msg = (\n                \"did not find a match in any of xarray's currently installed IO \"\n                f\"backends {installed_engines}. Consider explicitly selecting one of the \"\n                \"installed engines via the ``engine`` parameter, or installing \"\n                \"additional IO dependencies, see:\\n\"\n                \"https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\\n\"\n                \"https://docs.xarray.dev/en/stable/user-guide/io.html\"\n            )\n        else:\n            error_msg = (\n                \"xarray is unable to open this file because it has no currently \"\n                \"installed IO backends. Xarray's read/write support requires \"\n                \"installing optional IO dependencies, see:\\n\"\n                \"https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\\n\"\n                \"https://docs.xarray.dev/en/stable/user-guide/io\"\n            )\n    else:\n        error_msg = (\n            \"found the following matches with the input file in xarray's IO \"\n            f\"backends: {compatible_engines}. But their dependencies may not be installed, see:\\n\"\n            \"https://docs.xarray.dev/en/stable/user-guide/io.html \\n\"\n            \"https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\"\n        )\n\n    raise ValueError(error_msg)\n\n\ndef get_backend(engine: str | type[BackendEntrypoint]) -> BackendEntrypoint:\n    \"\"\"Select open_dataset method based on current engine.\"\"\"\n    if isinstance(engine, str):\n        engines = list_engines()\n        if engine not in engines:\n            raise ValueError(\n                f\"unrecognized engine {engine} must be one of: {list(engines)}\"\n            )\n        backend = engines[engine]\n    elif isinstance(engine, type) and issubclass(engine, BackendEntrypoint):\n        backend = engine()\n    else:\n        raise TypeError(\n            \"engine must be a string or a subclass of \"\n            f\"xarray.backends.BackendEntrypoint: {engine}\"\n        )\n\n    return backend",
                        "filename": "xarray/backends/plugins.py",
                        "start_index": 5213,
                        "end_index": 8171,
                        "start_line": 147,
                        "end_line": 217,
                        "max_line": 217,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__0.12",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the 'get_backend' function which is responsible for selecting the backend based on the engine parameter. It needs to be modified to allow passing a function directly to the engine parameter."
                }
            ],
            "xarray/backends/common.py": [
                {
                    "chunk": {
                        "code": "class WritableCFDataStore(AbstractWritableDataStore):\n    __slots__ = ()\n\n    def encode(self, variables, attributes):\n        # All NetCDF files get CF encoded by default, without this attempting\n        # to write times, for example, would fail.\n        variables, attributes = cf_encoder(variables, attributes)\n        variables = {k: self.encode_variable(v) for k, v in variables.items()}\n        attributes = {k: self.encode_attribute(v) for k, v in attributes.items()}\n        return variables, attributes\n\n\nclass BackendEntrypoint:\n    \"\"\"\n    ``BackendEntrypoint`` is a class container and it is the main interface\n    for the backend plugins, see :ref:`RST backend_entrypoint`.\n    It shall implement:\n\n    - ``open_dataset`` method: it shall implement reading from file, variables\n      decoding and it returns an instance of :py:class:`~xarray.Dataset`.\n      It shall take in input at least ``filename_or_obj`` argument and\n      ``drop_variables`` keyword argument.\n      For more details see :ref:`RST open_dataset`.\n    - ``guess_can_open`` method: it shall return ``True`` if the backend is able to open\n      ``filename_or_obj``, ``False`` otherwise. The implementation of this\n      method is not mandatory.\n\n    Attributes\n    ----------\n\n    open_dataset_parameters : tuple, default: None\n        A list of ``open_dataset`` method parameters.\n        The setting of this attribute is not mandatory.\n    description : str, default: \"\"\n        A short string describing the engine.\n        The setting of this attribute is not mandatory.\n    url : str, default: \"\"\n        A string with the URL to the backend's documentation.\n        The setting of this attribute is not mandatory.\n    \"\"\"\n\n    open_dataset_parameters: ClassVar[tuple | None] = None\n    description: ClassVar[str] = \"\"\n    url: ClassVar[str] = \"\"\n\n    def __repr__(self) -> str:\n        txt = f\"<{type(self).__name__}>\"\n        if self.description:\n            txt += f\"\\n  {self.description}\"\n        if self.url:\n            txt += f\"\\n  Learn more at {self.url}\"\n        return txt\n\n    def open_dataset(\n        self,\n        filename_or_obj: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n        *,\n        drop_variables: str | Iterable[str] | None = None,\n        **kwargs: Any,\n    ) -> Dataset:\n        \"\"\"\n        Backend open_dataset method used by Xarray in :py:func:`~xarray.open_dataset`.\n        \"\"\"\n\n        raise NotImplementedError\n\n    def guess_can_open(\n        self,\n        filename_or_obj: str | os.PathLike[Any] | BufferedIOBase | AbstractDataStore,\n    ) -> bool:\n        \"\"\"\n        Backend open_dataset method used by Xarray in :py:func:`~xarray.open_dataset`.\n        \"\"\"\n\n        return False\n\n\n# mapping of engine name to (module name, BackendEntrypoint Class)\nBACKEND_ENTRYPOINTS: dict[str, tuple[str | None, type[BackendEntrypoint]]] = {}",
                        "filename": "xarray/backends/common.py",
                        "start_index": 13469,
                        "end_index": 16341,
                        "start_line": 435,
                        "end_line": 513,
                        "max_line": 513,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__0.12",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet defines the 'BackendEntrypoint' class which is the base class for all backend entry points. It may need to be reviewed to ensure that custom backend functions can be integrated seamlessly."
                }
            ],
            "xarray/backends/api.py": [
                {
                    "chunk": {
                        "code": "from __future__ import annotations\n\nimport os\nfrom collections.abc import Hashable, Iterable, Mapping, MutableMapping, Sequence\nfrom functools import partial\nfrom io import BytesIO\nfrom numbers import Number\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Final,\n    Literal,\n    Union,\n    cast,\n    overload,\n)\n\nimport numpy as np\n\nfrom xarray import backends, conventions\nfrom xarray.backends import plugins\nfrom xarray.backends.common import (\n    AbstractDataStore,\n    ArrayWriter,\n    _find_absolute_paths,\n    _normalize_path,\n)\nfrom xarray.backends.locks import _get_scheduler\nfrom xarray.core import indexing\nfrom xarray.core.combine import (\n    _infer_concat_order_from_positions,\n    _nested_combine,\n    combine_by_coords,\n)\nfrom xarray.core.daskmanager import DaskManager\nfrom xarray.core.dataarray import DataArray\nfrom xarray.core.dataset import Dataset, _get_chunk, _maybe_chunk\nfrom xarray.core.indexes import Index\nfrom xarray.core.parallelcompat import guess_chunkmanager\nfrom xarray.core.utils import is_remote_uri\n\nif TYPE_CHECKING:\n    try:\n        from dask.delayed import Delayed\n    except ImportError:\n        Delayed = None  # type: ignore\n    from io import BufferedIOBase\n\n    from xarray.backends.common import BackendEntrypoint\n    from xarray.core.types import (\n        CombineAttrsOptions,\n        CompatOptions,\n        JoinOptions,\n        NestedSequence,\n        T_Chunks,\n    )\n\n    T_NetcdfEngine = Literal[\"netcdf4\", \"scipy\", \"h5netcdf\"]\n    T_Engine = Union[\n        T_NetcdfEngine,\n        Literal[\"pydap\", \"pynio\", \"pseudonetcdf\", \"zarr\"],\n        type[BackendEntrypoint],\n        str,  # no nice typing support for custom backends\n        None,\n    ]\n    T_NetcdfTypes = Literal[\n        \"NETCDF4\", \"NETCDF4_CLASSIC\", \"NETCDF3_64BIT\", \"NETCDF3_CLASSIC\"\n    ]\n\n\nDATAARRAY_NAME = \"__xarray_dataarray_name__\"\nDATAARRAY_VARIABLE = \"__xarray_dataarray_variable__\"\n\nENGINES = {\n    \"netcdf4\": backends.NetCDF4DataStore.open,\n    \"scipy\": backends.ScipyDataStore,\n    \"pydap\": backends.PydapDataStore.open,\n    \"h5netcdf\": backends.H5NetCDFStore.open,\n    \"pynio\": backends.NioDataStore,\n    \"pseudonetcdf\": backends.PseudoNetCDFDataStore.open,\n    \"zarr\": backends.ZarrStore.open_group,\n}\n\n\ndef _get_default_engine_remote_uri() -> Literal[\"netcdf4\", \"pydap\"]:\n    engine: Literal[\"netcdf4\", \"pydap\"]\n    try:\n        import netCDF4  # noqa: F401\n\n        engine = \"netcdf4\"\n    except ImportError:  # pragma: no cover\n        try:\n            import pydap  # noqa: F401\n\n            engine = \"pydap\"\n        except ImportError:\n            raise ValueError(\n                \"netCDF4 or pydap is required for accessing \"\n                \"remote datasets via OPeNDAP\"\n            )\n    return engine",
                        "filename": "xarray/backends/api.py",
                        "start_index": 0,
                        "end_index": 2756,
                        "start_line": 1,
                        "end_line": 131,
                        "max_line": 1703,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__0.12",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet from 'xarray/backends/api.py' includes the logic for opening datasets and may need to be updated to support the direct use of functions as the engine parameter."
                }
            ]
        },
        "solution_task": "To implement the feature request of allowing custom backends to be added via a function to the `engine` parameter, you can modify the `get_backend` function in `xarray/backends/plugins.py` to accept a callable as an engine. Here's a high-level overview of the steps:\n\n- Modify the `get_backend` function to check if the `engine` parameter is a callable function.\n- If it is a callable, use it directly as the backend without going through the registered backend entry points.\n- Ensure that the callable provided adheres to the `BackendEntrypoint` interface, particularly the `open_dataset` method.\n\nHere's a code snippet that demonstrates these changes:\n\n```python\n# In xarray/backends/plugins.py\n\ndef get_backend(engine: str | type[BackendEntrypoint] | Callable) -> BackendEntrypoint:\n    \"\"\"Select open_dataset method based on current engine.\"\"\"\n    if isinstance(engine, str):\n        engines = list_engines()\n        if engine not in engines:\n            raise ValueError(\n                f\"unrecognized engine {engine} must be one of: {list(engines)}\"\n            )\n        backend = engines[engine]\n    elif isinstance(engine, type) and issubclass(engine, BackendEntrypoint):\n        backend = engine()\n    elif callable(engine):\n        # Check if the callable adheres to the BackendEntrypoint interface\n        required_methods = ['open_dataset']\n        if all(hasattr(engine, method) for method in required_methods):\n            backend = engine\n        else:\n            raise TypeError(\n                \"engine must be a string, a subclass of \"\n                \"xarray.backends.BackendEntrypoint, or a callable with required methods: \"\n                f\"{required_methods}\"\n            )\n    else:\n        raise TypeError(\n            \"engine must be a string, a subclass of \"\n            \"xarray.backends.BackendEntrypoint, or a callable\"\n        )\n\n    return backend\n```\n\nWith this change, users can now pass a custom backend function directly to the `engine` parameter when calling `xr.load_dataset`:\n\n```python\nfrom custom_backend import custom_open_dataset\n\nds = xr.load_dataset(filename, engine=custom_open_dataset)\n```\n\nMake sure to update the documentation to reflect this new capability and provide guidelines on how to create a callable that is compatible with the `BackendEntrypoint` interface.",
        "bouncer_response": {
            "score": 9,
            "criteria": "The RESPONSE delivers precise, actionable, and highly relevant suggestions that can directly lead to the successful implementation or improvement of the requested feature.",
            "supporting_evidence": "The RESPONSE provides a detailed and actionable solution to the feature request of allowing custom backends to be added via a function to the `engine` parameter. It includes a high-level overview of the necessary steps, a code snippet demonstrating the changes, and additional guidance on ensuring compatibility with the `BackendEntrypoint` interface. The RESPONSE also suggests updating the documentation to reflect the new capability, which is an important aspect of implementing a new feature. Furthermore, it provides links to specific code snippets that need to be checked or modified, which is highly valuable for developers looking to implement this feature.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711759406.988211,
        "result": "To implement the feature request of allowing custom backends to be added via a function to the `engine` parameter, you can modify the `get_backend` function in `xarray/backends/plugins.py` to accept a callable as an engine. Here's a high-level overview of the steps:\n\n- Modify the `get_backend` function to check if the `engine` parameter is a callable function.\n- If it is a callable, use it directly as the backend without going through the registered backend entry points.\n- Ensure that the callable provided adheres to the `BackendEntrypoint` interface, particularly the `open_dataset` method.\n\nHere's a code snippet that demonstrates these changes:\n\n```python\n# In xarray/backends/plugins.py\n\ndef get_backend(engine: str | type[BackendEntrypoint] | Callable) -> BackendEntrypoint:\n    \"\"\"Select open_dataset method based on current engine.\"\"\"\n    if isinstance(engine, str):\n        engines = list_engines()\n        if engine not in engines:\n            raise ValueError(\n                f\"unrecognized engine {engine} must be one of: {list(engines)}\"\n            )\n        backend = engines[engine]\n    elif isinstance(engine, type) and issubclass(engine, BackendEntrypoint):\n        backend = engine()\n    elif callable(engine):\n        # Check if the callable adheres to the BackendEntrypoint interface\n        required_methods = ['open_dataset']\n        if all(hasattr(engine, method) for method in required_methods):\n            backend = engine\n        else:\n            raise TypeError(\n                \"engine must be a string, a subclass of \"\n                \"xarray.backends.BackendEntrypoint, or a callable with required methods: \"\n                f\"{required_methods}\"\n            )\n    else:\n        raise TypeError(\n            \"engine must be a string, a subclass of \"\n            \"xarray.backends.BackendEntrypoint, or a callable\"\n        )\n\n    return backend\n```\n\nWith this change, users can now pass a custom backend function directly to the `engine` parameter when calling `xr.load_dataset`:\n\n```python\nfrom custom_backend import custom_open_dataset\n\nds = xr.load_dataset(filename, engine=custom_open_dataset)\n```\n\nMake sure to update the documentation to reflect this new capability and provide guidelines on how to create a callable that is compatible with the `BackendEntrypoint` interface.\n\n### Code snippets to check\n\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [backends](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/backends)- [Lines 147 - 217](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/backends/plugins.py#L147-L217)\n\n This snippet contains the 'get_backend' function which is responsible for selecting the backend based on the engine parameter. It needs to be modified to allow passing a function directly to the engine parameter.\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [backends](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/backends)- [Lines 435 - 513](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/backends/common.py#L435-L513)\n\n This snippet defines the 'BackendEntrypoint' class which is the base class for all backend entry points. It may need to be reviewed to ensure that custom backend functions can be integrated seamlessly.\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__0.12/tree//xarray) \u2192 [backends](https://github.com/testbed/pydata__xarray__0.12/tree//xarray/backends)- [Lines 1 - 131](https://github.com/testbed/pydata__xarray__0.12/blob//xarray/backends/api.py#L1-L131)\n\n This snippet from 'xarray/backends/api.py' includes the logic for opening datasets and may need to be updated to support the direct use of functions as the engine parameter."
    }
}