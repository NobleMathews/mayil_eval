{
    "id": "scikit-learn__scikit-learn-10459",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
    "task_id": 791889339145981002,
    "title": "[RFC] Dissociate NaN and Inf when considering force_all_finite in check_array",
    "body": "Due to changes proposed in #10404, it seems that `check_array` as currently a main limitation. `force_all_finite` will force both `NaN` and `inf`to be rejected. If preprocessing methods (whenever this is possible) should let pass `NaN`, this argument is not enough permissive.\r\n\r\nBefore to implement anything, I think it could be good to have some feedback on the way to go. I see the following solutions:\r\n\r\n1. `force_all_finite` could still accept a bool to preserve the behaviour. Additionally, it could accept an `str` to filter only `inf`.\r\n2. #7892 proposes to have an additional argument `allow_nan`. @amueller was worried that it makes `check_array` to complex.\r\n3. make a private function `_assert_finite_or_nan` (similarly to [this proposal](https://github.com/scikit-learn/scikit-learn/pull/10437/files#diff-5ebddebc20987b6125fffc893f5abc4cR2379) removing the numpy version checking) in the `data.py` which can be shared between the preprocessing methods.\r\n\r\nThey are the solutions that I have in mind for the moment but anything else is welcomed.\r\n@jnothman @agramfort @amueller @lesteve @ogrisel @GaelVaroquaux I would be grateful for any insight.\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.20.git",
    "requested_commit": "",
    "mayil_response": "- Update the `check_array` function to accept a string for the `force_all_finite` parameter with a new option 'allow-nan' that allows NaNs but not infs.\n- Modify the `_assert_all_finite` function to handle the new 'allow-nan' option by setting `allow_nan=True` when `force_all_finite` is 'allow-nan'.\n- Ensure that the `_assert_all_finite_element_wise` function is called with the correct `allow_nan` argument based on the value of `force_all_finite`.\n- Update the documentation of `check_array` to reflect the new behavior of the `force_all_finite` parameter.\n- No changes are required in the `_assert_finite_or_nan` function as it is a private function and its behavior is not described in the issue.\n- Ensure that all calls to `check_array` within preprocessing methods are reviewed and updated if necessary to pass the correct value for `force_all_finite` based on whether NaNs should be allowed or not.\n- No changes are required in the `check_estimators_nan_inf` function as it is designed to check for the presence of NaNs and infs in estimator inputs, which is a separate concern from the `check_array` function's behavior.\n- No changes are required in the `_sgd_fast_helpers.h` file as it deals with low-level finite checks in Cython code, which is not directly related to the `check_array` function's Python-level behavior.\n- No changes are required in the `_ensure_no_complex_data`, `_check_estimator_name`, `_pandas_dtype_needs_early_conversion`, `_is_extension_array_dtype`, and `assert_all_finite` functions as they are not directly related to the handling of NaNs and infs in the `check_array` function.\n- No changes are required in the `_univariate_selection.py` file as it deals with NaN handling in scoring functions, which is separate from the `check_array` function's behavior.\n- No changes are required in the `check_outlier_contamination` and `check_classifiers_multilabel_representation_invariance` functions as they are not related to the `check_array` function's behavior.\n- No changes are required in the `_yield_classifier_checks` and `check_supervised_y_no_nan` functions as they are part of the estimator checks and not directly related to the `check_array` function's behavior.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/utils)- [Lines 567 - 2229](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L567-L2229)\n\n This snippet shows the current implementation of the `force_all_finite` parameter in `check_array`, which is central to the issue described. \n\n\n   - [Lines 95 - 2278](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L95-L2278)\n\n This snippet contains the `_assert_all_finite` function that is called by `check_array` and is responsible for checking if the array contains only finite values. It is directly related to handling NaN and Inf values. \n\n\n   - [Lines 135 - 2278](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L135-L2278)\n\n This snippet is the continuation of the `_assert_all_finite` function and includes the element-wise check for finiteness, which is relevant to the issue.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.000641,
        "snippet_processor": 0.08109000000000001,
        "issue_star_creation": 0.027979999999999998,
        "issue_star_solver": 0.06982000000000001,
        "bouncer": 0.03111
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711742308.493377,
        "relevant_snippets": [
            {
                "code": "if force_all_finite:\n            _assert_all_finite(\n                array,\n                input_name=input_name,\n                estimator_name=estimator_name,\n                allow_nan=force_all_finite == \"allow-nan\",\n            )",
                "filename": "sklearn/utils/validation.py",
                "start_index": 34523,
                "end_index": 34757,
                "start_line": 567,
                "end_line": 2229,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_estimators_empty_data_messages(name, estimator_orig):\n    e = clone(estimator_orig)\n    set_random_state(e, 1)\n\n    X_zero_samples = np.empty(0).reshape(0, 3)\n    # The precise message can change depending on whether X or y is\n    # validated first. Let us test the type of exception only:\n    err_msg = (\n        f\"The estimator {name} does not raise a ValueError when an \"\n        \"empty data is used to train. Perhaps use check_array in train.\"\n    )\n    with raises(ValueError, err_msg=err_msg):\n        e.fit(X_zero_samples, [])\n\n    X_zero_features = np.empty(0).reshape(12, 0)\n    # the following y should be accepted by both classifiers and regressors\n    # and ignored by unsupervised models\n    y = _enforce_estimator_tags_y(e, np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]))\n    msg = r\"0 feature\\(s\\) \\(shape=\\(\\d*, 0\\)\\) while a minimum of \\d* \" \"is required.\"\n    with raises(ValueError, match=msg):\n        e.fit(X_zero_features, y)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_estimators_nan_inf(name, estimator_orig):\n    # Checks that Estimator X's do not contain NaN or inf.\n    rnd = np.random.RandomState(0)\n    X_train_finite = _enforce_estimator_tags_X(\n        estimator_orig, rnd.uniform(size=(10, 3))\n    )\n    X_train_nan = rnd.uniform(size=(10, 3))\n    X_train_nan[0, 0] = np.nan\n    X_train_inf = rnd.uniform(size=(10, 3))\n    X_train_inf[0, 0] = np.inf\n    y = np.ones(10)\n    y[:5] = 0\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n    error_string_fit = f\"Estimator {name} doesn't check for NaN and inf in fit.\"\n    error_string_predict = f\"Estimator {name} doesn't check for NaN and inf in predict.\"\n    error_string_transform = (\n        f\"Estimator {name} doesn't check for NaN and inf in transform.\"\n    )\n    for X_train in [X_train_nan, X_train_inf]:\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n            set_random_state(estimator, 1)\n            # try to fit\n            with raises(ValueError, match=[\"inf\", \"NaN\"], err_msg=error_string_fit):\n                estimator.fit(X_train, y)\n            # actually fit\n            estimator.fit(X_train_finite, y)\n\n            # predict\n            if hasattr(estimator, \"predict\"):\n                with raises(\n                    ValueError,\n                    match=[\"inf\", \"NaN\"],\n                    err_msg=error_string_predict,\n                ):\n                    estimator.predict(X_train)\n\n            # transform\n            if hasattr(estimator, \"transform\"):\n                with raises(\n                    ValueError,\n                    match=[\"inf\", \"NaN\"],\n                    err_msg=error_string_transform,\n                ):\n                    estimator.transform(X_train)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 67270,
                "end_index": 70112,
                "start_line": 181,
                "end_line": 2043,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "// We cannot directly reuse the npy_isfinite from npy_math.h as numpy\n// and scikit-learn are not necessarily built with the same compiler.\n// When re-declaring the functions in the template for cython\n// specific for each parameter input type, it needs to be 2 different functions\n// as cython doesn't support function overloading.\n#ifdef _MSC_VER\n# include <float.h>\n# define skl_isfinite _finite\n# define skl_isfinite32 _finite\n# define skl_isfinite64 _finite\n#else\n# include <numpy/npy_math.h>\n# define skl_isfinite npy_isfinite\n# define skl_isfinite32 npy_isfinite\n# define skl_isfinite64 npy_isfinite\n#endif",
                "filename": "sklearn/linear_model/_sgd_fast_helpers.h",
                "start_index": 0,
                "end_index": 613,
                "start_line": 1,
                "end_line": 16,
                "max_line": 16,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def _ensure_no_complex_data(array):\n    if (\n        hasattr(array, \"dtype\")\n        and array.dtype is not None\n        and hasattr(array.dtype, \"kind\")\n        and array.dtype.kind == \"c\"\n    ):\n        raise ValueError(\"Complex data not supported\\n{}\\n\".format(array))\n\n\ndef _check_estimator_name(estimator):\n    if estimator is not None:\n        if isinstance(estimator, str):\n            return estimator\n        else:\n            return estimator.__class__.__name__\n    return None\n\n\ndef _pandas_dtype_needs_early_conversion(pd_dtype):\n    \"\"\"Return True if pandas extension pd_dtype need to be converted early.\"\"\"\n    # Check these early for pandas versions without extension dtypes\n    from pandas import SparseDtype\n    from pandas.api.types import (\n        is_bool_dtype,\n        is_float_dtype,\n        is_integer_dtype,\n    )\n\n    if is_bool_dtype(pd_dtype):\n        # bool and extension booleans need early conversion because __array__\n        # converts mixed dtype dataframes into object dtypes\n        return True\n\n    if isinstance(pd_dtype, SparseDtype):\n        # Sparse arrays will be converted later in `check_array`\n        return False\n\n    try:\n        from pandas.api.types import is_extension_array_dtype\n    except ImportError:\n        return False\n\n    if isinstance(pd_dtype, SparseDtype) or not is_extension_array_dtype(pd_dtype):\n        # Sparse arrays will be converted later in `check_array`\n        # Only handle extension arrays for integer and floats\n        return False\n    elif is_float_dtype(pd_dtype):\n        # Float ndarrays can normally support nans. They need to be converted\n        # first to map pd.NA to np.nan\n        return True\n    elif is_integer_dtype(pd_dtype):\n        # XXX: Warn when converting from a high integer to a float\n        return True\n\n    return False\n\n\ndef _is_extension_array_dtype(array):\n    # Pandas extension arrays have a dtype with an na_value\n    return hasattr(array, \"dtype\") and hasattr(array.dtype, \"na_value\")",
                "filename": "sklearn/utils/validation.py",
                "start_index": 19519,
                "end_index": 21514,
                "start_line": 584,
                "end_line": 644,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"Utilities for input validation\"\"\"\n\n# Authors: Olivier Grisel\n#          Gael Varoquaux\n#          Andreas Mueller\n#          Lars Buitinck\n#          Alexandre Gramfort\n#          Nicolas Tresegnie\n#          Sylvain Marie\n# License: BSD 3 clause\n\nimport numbers\nimport operator\nimport sys\nimport warnings\nfrom contextlib import suppress\nfrom functools import reduce, wraps\nfrom inspect import Parameter, isclass, signature\n\nimport joblib\nimport numpy as np\nimport scipy.sparse as sp\n\n# mypy error: Module 'numpy.core.numeric' has no attribute 'ComplexWarning'\nfrom numpy.core.numeric import ComplexWarning  # type: ignore\n\nfrom .. import get_config as _get_config\nfrom ..exceptions import DataConversionWarning, NotFittedError, PositiveSpectrumWarning\nfrom ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\nfrom ._isfinite import FiniteStatus, cy_isfinite\nfrom .fixes import _object_dtype_isnan\n\nFLOAT_DTYPES = (np.float64, np.float32, np.float16)\n\n\n# This function is not used anymore at this moment in the code base but we keep it in\n# case that we merge a new public function without kwarg only by mistake, which would\n# require a deprecation cycle to fix.",
                "filename": "sklearn/utils/validation.py",
                "start_index": 0,
                "end_index": 1195,
                "start_line": 1,
                "end_line": 38,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"Univariate features selection.\"\"\"\n\n# Authors: V. Michel, B. Thirion, G. Varoquaux, A. Gramfort, E. Duchesnay.\n#          L. Buitinck, A. Joly\n# License: BSD 3 clause\n\n\nimport warnings\nfrom numbers import Integral, Real\n\nimport numpy as np\nfrom scipy import special, stats\nfrom scipy.sparse import issparse\n\nfrom ..base import BaseEstimator, _fit_context\nfrom ..preprocessing import LabelBinarizer\nfrom ..utils import as_float_array, check_array, check_X_y, safe_mask, safe_sqr\nfrom ..utils._param_validation import Interval, StrOptions, validate_params\nfrom ..utils.extmath import row_norms, safe_sparse_dot\nfrom ..utils.validation import check_is_fitted\nfrom ._base import SelectorMixin\n\n\ndef _clean_nans(scores):\n    \"\"\"\n    Fixes Issue #1240: NaNs can't be properly compared, so change them to the\n    smallest value of scores's dtype. -inf seems to be unreliable.\n    \"\"\"\n    # XXX where should this function be called? fit? scoring functions\n    # themselves?\n    scores = as_float_array(scores, copy=True)\n    scores[np.isnan(scores)] = np.finfo(scores.dtype).min\n    return scores\n\n\n######################################################################\n# Scoring functions\n\n\n# The following function is a rewriting of scipy.stats.f_oneway\n# Contrary to the scipy.stats.f_oneway implementation it does not\n# copy the data while keeping the inputs unchanged.",
                "filename": "sklearn/feature_selection/_univariate_selection.py",
                "start_index": 0,
                "end_index": 1367,
                "start_line": 1,
                "end_line": 42,
                "max_line": 1084,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def _assert_all_finite(\n    X, allow_nan=False, msg_dtype=None, estimator_name=None, input_name=\"\"\n):\n    \"\"\"Like assert_all_finite, but only for ndarray.\"\"\"\n\n    xp, _ = get_namespace(X)\n\n    if _get_config()[\"assume_finite\"]:\n        return\n\n    X = xp.asarray(X)\n\n    # for object dtype data, we only check for NaNs (GH-13254)\n    if X.dtype == np.dtype(\"object\") and not allow_nan:\n        if _object_dtype_isnan(X).any():\n            raise ValueError(\"Input contains NaN\")\n\n    # We need only consider float arrays, hence can early return for all else.\n    if not xp.isdtype(X.dtype, (\"real floating\", \"complex floating\")):\n        return\n\n    # First try an O(n) time, O(1) space solution for the common case that\n    # everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\n    # Cython implementation to prevent false positives and provide a detailed\n    # error message.\n    with np.errstate(over=\"ignore\"):\n        first_pass_isfinite = xp.isfinite(xp.sum(X))\n    if first_pass_isfinite:\n        return\n\n    _assert_all_finite_element_wise(\n        X,\n        xp=xp,\n        allow_nan=allow_nan,\n        msg_dtype=msg_dtype,\n        estimator_name=estimator_name,\n        input_name=input_name,\n    )",
                "filename": "sklearn/utils/validation.py",
                "start_index": 3013,
                "end_index": 4241,
                "start_line": 95,
                "end_line": 2278,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def _assert_all_finite_element_wise(\n    X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=\"\"\n):\n    # Cython implementation doesn't support FP16 or complex numbers\n    use_cython = (\n        xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}\n    )\n    if use_cython:\n        out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)\n        has_nan_error = False if allow_nan else out == FiniteStatus.has_nan\n        has_inf = out == FiniteStatus.has_infinite\n    else:\n        has_inf = xp.any(xp.isinf(X))\n        has_nan_error = False if allow_nan else xp.any(xp.isnan(X))\n    if has_inf or has_nan_error:\n        if has_nan_error:\n            type_err = \"NaN\"\n        else:\n            msg_dtype = msg_dtype if msg_dtype is not None else X.dtype\n            type_err = f\"infinity or a value too large for {msg_dtype!r}\"\n        padded_input_name = input_name + \" \" if input_name else \"\"\n        msg_err = f\"Input {padded_input_name}contains {type_err}.\"\n        if estimator_name and input_name == \"X\" and has_nan_error:\n            # Improve the error message on how to handle missing values in\n            # scikit-learn.\n            msg_err += (\n                f\"\\n{estimator_name} does not accept missing values\"\n                \" encoded as NaN natively. For supervised learning, you might want\"\n                \" to consider sklearn.ensemble.HistGradientBoostingClassifier and\"\n                \" Regressor which accept missing values encoded as NaNs natively.\"\n                \" Alternatively, it is possible to preprocess the data, for\"\n                \" instance by using an imputer transformer in a pipeline or drop\"\n                \" samples with missing values. See\"\n                \" https://scikit-learn.org/stable/modules/impute.html\"\n                \" You can find a list of all estimators that handle NaN values\"\n                \" at the following page:\"\n                \" https://scikit-learn.org/stable/modules/impute.html\"\n                \"#estimators-that-handle-nan-values\"\n            )\n        raise ValueError(msg_err)\n\n\ndef assert_all_finite(\n    X,\n    *,\n    allow_nan=False,\n    estimator_name=None,\n    input_name=\"\",\n):\n    \"\"\"Throw a ValueError if X contains NaN or infinity.\n\n    Parameters\n    ----------\n    X : {ndarray, sparse matrix}\n        The input data.\n\n    allow_nan : bool, default=False\n        If True, do not throw error when `X` contains NaN.\n\n    estimator_name : str, default=None\n        The estimator name, used to construct the error message.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.\n    \"\"\"\n    _assert_all_finite(\n        X.data if sp.issparse(X) else X,\n        allow_nan=allow_nan,\n        estimator_name=estimator_name,\n        input_name=input_name,\n    )",
                "filename": "sklearn/utils/validation.py",
                "start_index": 4244,
                "end_index": 7227,
                "start_line": 135,
                "end_line": 2278,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def check_outlier_contamination(name, estimator_orig):\n    # Check that the contamination parameter is in (0.0, 0.5] when it is an\n    # interval constraint.\n\n    if not hasattr(estimator_orig, \"_parameter_constraints\"):\n        # Only estimator implementing parameter constraints will be checked\n        return\n\n    if \"contamination\" not in estimator_orig._parameter_constraints:\n        return\n\n    contamination_constraints = estimator_orig._parameter_constraints[\"contamination\"]\n    if not any([isinstance(c, Interval) for c in contamination_constraints]):\n        raise AssertionError(\n            \"contamination constraints should contain a Real Interval constraint.\"\n        )\n\n    for constraint in contamination_constraints:\n        if isinstance(constraint, Interval):\n            assert (\n                constraint.type == Real\n                and constraint.left >= 0.0\n                and constraint.right <= 0.5\n                and (constraint.left > 0 or constraint.closed in {\"right\", \"neither\"})\n            ), \"contamination constraint should be an interval in (0, 0.5]\"\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_classifiers_multilabel_representation_invariance(name, classifier_orig):\n    X, y = make_multilabel_classification(\n        n_samples=100,\n        n_features=2,\n        n_classes=5,\n        n_labels=3,\n        length=50,\n        allow_unlabeled=True,\n        random_state=0,\n    )\n    X = scale(X)\n\n    X_train, y_train = X[:80], y[:80]\n    X_test = X[80:]\n\n    y_train_list_of_lists = y_train.tolist()\n    y_train_list_of_arrays = list(y_train)\n\n    classifier = clone(classifier_orig)\n    set_random_state(classifier)\n\n    y_pred = classifier.fit(X_train, y_train).predict(X_test)\n\n    y_pred_list_of_lists = classifier.fit(X_train, y_train_list_of_lists).predict(\n        X_test\n    )\n\n    y_pred_list_of_arrays = classifier.fit(X_train, y_train_list_of_arrays).predict(\n        X_test\n    )\n\n    assert_array_equal(y_pred, y_pred_list_of_arrays)\n    assert_array_equal(y_pred, y_pred_list_of_lists)\n\n    assert y_pred.dtype == y_pred_list_of_arrays.dtype\n    assert y_pred.dtype == y_pred_list_of_lists.dtype\n    assert type(y_pred) == type(y_pred_list_of_arrays)\n    assert type(y_pred) == type(y_pred_list_of_lists)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 91144,
                "end_index": 93410,
                "start_line": 2600,
                "end_line": 2665,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def _yield_classifier_checks(classifier):\n    tags = _safe_tags(classifier)\n\n    # test classifiers can handle non-array data and pandas objects\n    yield check_classifier_data_not_an_array\n    # test classifiers trained on a single label always return this label\n    yield check_classifiers_one_label\n    yield check_classifiers_one_label_sample_weights\n    yield check_classifiers_classes\n    yield check_estimators_partial_fit_n_features\n    if tags[\"multioutput\"]:\n        yield check_classifier_multioutput\n    # basic consistency testing\n    yield check_classifiers_train\n    yield partial(check_classifiers_train, readonly_memmap=True)\n    yield partial(check_classifiers_train, readonly_memmap=True, X_dtype=\"float32\")\n    yield check_classifiers_regression_target\n    if tags[\"multilabel\"]:\n        yield check_classifiers_multilabel_representation_invariance\n        yield check_classifiers_multilabel_output_format_predict\n        yield check_classifiers_multilabel_output_format_predict_proba\n        yield check_classifiers_multilabel_output_format_decision_function\n    if not tags[\"no_validation\"]:\n        yield check_supervised_y_no_nan\n        if not tags[\"multioutput_only\"]:\n            yield check_supervised_y_2d\n    if tags[\"requires_fit\"]:\n        yield check_estimators_unfitted\n    if \"class_weight\" in classifier.get_params().keys():\n        yield check_class_weight_classifiers\n\n    yield check_non_transformer_estimators_n_iter\n    # test if predict_proba is a monotonic transformation of decision_function\n    yield check_decision_proba_consistency\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_supervised_y_no_nan(name, estimator_orig):\n    # Checks that the Estimator targets are not NaN.\n    estimator = clone(estimator_orig)\n    rng = np.random.RandomState(888)\n    X = rng.standard_normal(size=(10, 5))\n\n    for value in [np.nan, np.inf]:\n        y = np.full(10, value)\n        y = _enforce_estimator_tags_y(estimator, y)\n\n        module_name = estimator.__module__\n        if module_name.startswith(\"sklearn.\") and not (\n            \"test_\" in module_name or module_name.endswith(\"_testing\")\n        ):\n            # In scikit-learn we want the error message to mention the input\n            # name and be specific about the kind of unexpected value.\n            if np.isinf(value):\n                match = (\n                    r\"Input (y|Y) contains infinity or a value too large for\"\n                    r\" dtype\\('float64'\\).\"\n                )\n            else:\n                match = r\"Input (y|Y) contains NaN.\"\n        else:\n            # Do not impose a particular error message to third-party libraries.\n            match = None\n        err_msg = (\n            f\"Estimator {name} should have raised error on fitting array y with inf\"\n            \" value.\"\n        )\n        with raises(ValueError, match=match, err_msg=err_msg):\n            estimator.fit(X, y)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 4352,
                "end_index": 7266,
                "start_line": 145,
                "end_line": 1355,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            }
        ],
        "classification": "other",
        "snippet_processor_task": {
            "sklearn/utils/validation.py": [
                {
                    "chunk": {
                        "code": "if force_all_finite:\n            _assert_all_finite(\n                array,\n                input_name=input_name,\n                estimator_name=estimator_name,\n                allow_nan=force_all_finite == \"allow-nan\",\n            )",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 34523,
                        "end_index": 34757,
                        "start_line": 567,
                        "end_line": 2229,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet shows the current implementation of the `force_all_finite` parameter in `check_array`, which is central to the issue described."
                },
                {
                    "chunk": {
                        "code": "def _assert_all_finite(\n    X, allow_nan=False, msg_dtype=None, estimator_name=None, input_name=\"\"\n):\n    \"\"\"Like assert_all_finite, but only for ndarray.\"\"\"\n\n    xp, _ = get_namespace(X)\n\n    if _get_config()[\"assume_finite\"]:\n        return\n\n    X = xp.asarray(X)\n\n    # for object dtype data, we only check for NaNs (GH-13254)\n    if X.dtype == np.dtype(\"object\") and not allow_nan:\n        if _object_dtype_isnan(X).any():\n            raise ValueError(\"Input contains NaN\")\n\n    # We need only consider float arrays, hence can early return for all else.\n    if not xp.isdtype(X.dtype, (\"real floating\", \"complex floating\")):\n        return\n\n    # First try an O(n) time, O(1) space solution for the common case that\n    # everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\n    # Cython implementation to prevent false positives and provide a detailed\n    # error message.\n    with np.errstate(over=\"ignore\"):\n        first_pass_isfinite = xp.isfinite(xp.sum(X))\n    if first_pass_isfinite:\n        return\n\n    _assert_all_finite_element_wise(\n        X,\n        xp=xp,\n        allow_nan=allow_nan,\n        msg_dtype=msg_dtype,\n        estimator_name=estimator_name,\n        input_name=input_name,\n    )",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 3013,
                        "end_index": 4241,
                        "start_line": 95,
                        "end_line": 2278,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the `_assert_all_finite` function that is called by `check_array` and is responsible for checking if the array contains only finite values. It is directly related to handling NaN and Inf values."
                },
                {
                    "chunk": {
                        "code": "def _assert_all_finite_element_wise(\n    X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=\"\"\n):\n    # Cython implementation doesn't support FP16 or complex numbers\n    use_cython = (\n        xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}\n    )\n    if use_cython:\n        out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)\n        has_nan_error = False if allow_nan else out == FiniteStatus.has_nan\n        has_inf = out == FiniteStatus.has_infinite\n    else:\n        has_inf = xp.any(xp.isinf(X))\n        has_nan_error = False if allow_nan else xp.any(xp.isnan(X))\n    if has_inf or has_nan_error:\n        if has_nan_error:\n            type_err = \"NaN\"\n        else:\n            msg_dtype = msg_dtype if msg_dtype is not None else X.dtype\n            type_err = f\"infinity or a value too large for {msg_dtype!r}\"\n        padded_input_name = input_name + \" \" if input_name else \"\"\n        msg_err = f\"Input {padded_input_name}contains {type_err}.\"\n        if estimator_name and input_name == \"X\" and has_nan_error:\n            # Improve the error message on how to handle missing values in\n            # scikit-learn.\n            msg_err += (\n                f\"\\n{estimator_name} does not accept missing values\"\n                \" encoded as NaN natively. For supervised learning, you might want\"\n                \" to consider sklearn.ensemble.HistGradientBoostingClassifier and\"\n                \" Regressor which accept missing values encoded as NaNs natively.\"\n                \" Alternatively, it is possible to preprocess the data, for\"\n                \" instance by using an imputer transformer in a pipeline or drop\"\n                \" samples with missing values. See\"\n                \" https://scikit-learn.org/stable/modules/impute.html\"\n                \" You can find a list of all estimators that handle NaN values\"\n                \" at the following page:\"\n                \" https://scikit-learn.org/stable/modules/impute.html\"\n                \"#estimators-that-handle-nan-values\"\n            )\n        raise ValueError(msg_err)\n\n\ndef assert_all_finite(\n    X,\n    *,\n    allow_nan=False,\n    estimator_name=None,\n    input_name=\"\",\n):\n    \"\"\"Throw a ValueError if X contains NaN or infinity.\n\n    Parameters\n    ----------\n    X : {ndarray, sparse matrix}\n        The input data.\n\n    allow_nan : bool, default=False\n        If True, do not throw error when `X` contains NaN.\n\n    estimator_name : str, default=None\n        The estimator name, used to construct the error message.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.\n    \"\"\"\n    _assert_all_finite(\n        X.data if sp.issparse(X) else X,\n        allow_nan=allow_nan,\n        estimator_name=estimator_name,\n        input_name=input_name,\n    )",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 4244,
                        "end_index": 7227,
                        "start_line": 135,
                        "end_line": 2278,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet is the continuation of the `_assert_all_finite` function and includes the element-wise check for finiteness, which is relevant to the issue."
                }
            ]
        },
        "solution_task": "- Update the `check_array` function to accept a string for the `force_all_finite` parameter with a new option 'allow-nan' that allows NaNs but not infs.\n- Modify the `_assert_all_finite` function to handle the new 'allow-nan' option by setting `allow_nan=True` when `force_all_finite` is 'allow-nan'.\n- Ensure that the `_assert_all_finite_element_wise` function is called with the correct `allow_nan` argument based on the value of `force_all_finite`.\n- Update the documentation of `check_array` to reflect the new behavior of the `force_all_finite` parameter.\n- No changes are required in the `_assert_finite_or_nan` function as it is a private function and its behavior is not described in the issue.\n- Ensure that all calls to `check_array` within preprocessing methods are reviewed and updated if necessary to pass the correct value for `force_all_finite` based on whether NaNs should be allowed or not.\n- No changes are required in the `check_estimators_nan_inf` function as it is designed to check for the presence of NaNs and infs in estimator inputs, which is a separate concern from the `check_array` function's behavior.\n- No changes are required in the `_sgd_fast_helpers.h` file as it deals with low-level finite checks in Cython code, which is not directly related to the `check_array` function's Python-level behavior.\n- No changes are required in the `_ensure_no_complex_data`, `_check_estimator_name`, `_pandas_dtype_needs_early_conversion`, `_is_extension_array_dtype`, and `assert_all_finite` functions as they are not directly related to the handling of NaNs and infs in the `check_array` function.\n- No changes are required in the `_univariate_selection.py` file as it deals with NaN handling in scoring functions, which is separate from the `check_array` function's behavior.\n- No changes are required in the `check_outlier_contamination` and `check_classifiers_multilabel_representation_invariance` functions as they are not related to the `check_array` function's behavior.\n- No changes are required in the `_yield_classifier_checks` and `check_supervised_y_no_nan` functions as they are part of the estimator checks and not directly related to the `check_array` function's behavior.",
        "bouncer_response": {
            "score": 7,
            "criteria": "RESPONSES that are highly relevant, offering clear and comprehensive guidance or solutions for the described bug, should score between 7 and 9.",
            "supporting_evidence": "The RESPONSE provides a clear and actionable solution to the issue described in the PROMPT by suggesting an update to the `check_array` function to accept a new string option for the `force_all_finite` parameter. It also outlines the necessary modifications to the `_assert_all_finite` function and the handling of the `allow_nan` argument. The RESPONSE includes a review of related functions and files to ensure no changes are needed there, which is helpful for avoiding unnecessary work. Additionally, it suggests updating the documentation to reflect the new behavior, which is an important step in the process. The RESPONSE does not address all three solutions proposed in the PROMPT but focuses on a variation of the first solution, which is still relevant and actionable.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711742444.63217,
        "result": "- Update the `check_array` function to accept a string for the `force_all_finite` parameter with a new option 'allow-nan' that allows NaNs but not infs.\n- Modify the `_assert_all_finite` function to handle the new 'allow-nan' option by setting `allow_nan=True` when `force_all_finite` is 'allow-nan'.\n- Ensure that the `_assert_all_finite_element_wise` function is called with the correct `allow_nan` argument based on the value of `force_all_finite`.\n- Update the documentation of `check_array` to reflect the new behavior of the `force_all_finite` parameter.\n- No changes are required in the `_assert_finite_or_nan` function as it is a private function and its behavior is not described in the issue.\n- Ensure that all calls to `check_array` within preprocessing methods are reviewed and updated if necessary to pass the correct value for `force_all_finite` based on whether NaNs should be allowed or not.\n- No changes are required in the `check_estimators_nan_inf` function as it is designed to check for the presence of NaNs and infs in estimator inputs, which is a separate concern from the `check_array` function's behavior.\n- No changes are required in the `_sgd_fast_helpers.h` file as it deals with low-level finite checks in Cython code, which is not directly related to the `check_array` function's Python-level behavior.\n- No changes are required in the `_ensure_no_complex_data`, `_check_estimator_name`, `_pandas_dtype_needs_early_conversion`, `_is_extension_array_dtype`, and `assert_all_finite` functions as they are not directly related to the handling of NaNs and infs in the `check_array` function.\n- No changes are required in the `_univariate_selection.py` file as it deals with NaN handling in scoring functions, which is separate from the `check_array` function's behavior.\n- No changes are required in the `check_outlier_contamination` and `check_classifiers_multilabel_representation_invariance` functions as they are not related to the `check_array` function's behavior.\n- No changes are required in the `_yield_classifier_checks` and `check_supervised_y_no_nan` functions as they are part of the estimator checks and not directly related to the `check_array` function's behavior.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/utils)- [Lines 567 - 2229](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L567-L2229)\n\n This snippet shows the current implementation of the `force_all_finite` parameter in `check_array`, which is central to the issue described. \n\n\n   - [Lines 95 - 2278](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L95-L2278)\n\n This snippet contains the `_assert_all_finite` function that is called by `check_array` and is responsible for checking if the array contains only finite values. It is directly related to handling NaN and Inf values. \n\n\n   - [Lines 135 - 2278](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/validation.py#L135-L2278)\n\n This snippet is the continuation of the `_assert_all_finite` function and includes the element-wise check for finiteness, which is relevant to the issue."
    }
}