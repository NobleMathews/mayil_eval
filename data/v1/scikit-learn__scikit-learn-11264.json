{
    "id": "scikit-learn__scikit-learn-11264",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
    "task_id": 1712477941681405978,
    "title": "randomized_svd is slow for dok_matrix and lil_matrix",
    "body": "#### Description\r\n\r\n`sklearn.utils.extmath.randomized_svd` (and its object-oriented interface, `sklearn.decomposition.TruncatedSVD`) is extremely slow for certain types of sparse matrix.\r\n\r\n#### Steps/Code to Reproduce\r\n\r\n```\r\n>>> import numpy as np\r\n>>> import scipy.sparse as sp\r\n>>> from sklearn.utils.extmath import randomized_svd\r\n>>> import timeit\r\n>>> \r\n>>> def test(X, seed=42):\r\n>>> \tU, S, VT = randomized_svd(X, 50, random_state=seed)\r\n>>> \r\n>>> np.random.seed(42)\r\n>>> X = np.random.normal(0,1,[1000,1000]) * np.random.poisson(0.1, [1000,1000])\r\n>>> X = sp.csr_matrix(X)\r\n>>> %timeit -n 50 test(X)\r\n50 loops, best of 3: 381 ms per loop\r\n>>> \r\n>>> X = sp.csc_matrix(X)\r\n>>> %timeit -n 50 test(X)\r\n50 loops, best of 3: 400 ms per loop\r\n>>> \r\n>>> X = sp.bsr_matrix(X)\r\n>>> %timeit -n 50 test(X)\r\n50 loops, best of 3: 392 ms per loop\r\n>>> \r\n>>> X = sp.coo_matrix(X)\r\n>>> %timeit -n 50 test(X)\r\n50 loops, best of 3: 578 ms per loop\r\n>>> \r\n>>> X = sp.lil_matrix(X)\r\n>>> %timeit -n 50 test(X)\r\n50 loops, best of 3: 1.45 s per loop\r\n>>> \r\n>>> X = sp.dok_matrix(X)\r\n>>> %timeit -n 50 test(X)\r\n50 loops, best of 3: 22.1 s per loop\r\n```\r\n\r\n#### Expected Results\r\n\r\nEither all sparse matrices should be processed in roughly the same amount of time, or a warning should be printed.\r\n\r\n#### Actual Results\r\n\r\n`randomized_svd` silently takes up to 50x longer than necessary.\r\n\r\n#### Versions\r\n\r\nWindows-10-10.0.17134-SP0\r\nPython 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 11:57:41) [MSC v.1900 64 bit (AMD64)]\r\nNumPy 1.14.4\r\nSciPy 1.1.0\r\nScikit-Learn 0.19.1\r\n\r\nAlso tested on:\r\n\r\nLinux-4.16.11-1-ARCH-x86_64-with-arch-Arch-Linux\r\nPython 3.6.5 (default, May 11 2018, 04:00:52)\r\n[GCC 8.1.0]\r\nNumPy 1.14.5\r\nSciPy 1.1.0\r\nScikit-Learn 0.19.1\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.20.git",
    "requested_commit": "",
    "mayil_response": "- Convert `dok_matrix` and `lil_matrix` to `csr_matrix` before calling `randomized_svd` to improve performance.\n- Add a warning message to inform users about the performance impact when using inefficient sparse matrix types like `dok_matrix` and `lil_matrix`.\n- Example code snippet to convert and warn:\n\n```python\nfrom scipy.sparse import dok_matrix, lil_matrix, csr_matrix\nfrom sklearn.utils.extmath import randomized_svd\nfrom warnings import warn\n\ndef efficient_randomized_svd(X, n_components, random_state=None):\n    if isinstance(X, (dok_matrix, lil_matrix)):\n        warn(\"Converting to csr_matrix for efficiency reasons.\")\n        X = csr_matrix(X)\n    return randomized_svd(X, n_components, random_state=random_state)\n```\n\n### Code snippets to check\n\n-  \u2192 [benchmarks](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//benchmarks)- [Lines 1 - 76](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//benchmarks/bench_plot_randomized_svd.py#L1-L76)\n\n This snippet contains benchmarks related to the randomized_svd function, which is directly relevant to the issue of performance with different sparse matrix types. \n\n\n   - [Lines 446 - 528](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//benchmarks/bench_plot_randomized_svd.py#L446-L528)\n\n This snippet includes a benchmarking function for randomized_svd, which is relevant to the issue as it may help identify performance discrepancies across different matrix types.",
    "ai_cost": {
        "search_embedding": 2.6e-07,
        "issue_classifier": 0.005174,
        "snippet_processor": 0.06475,
        "issue_star_creation": 0.04989,
        "issue_star_solver": 0.08403000000000001,
        "bouncer": 0.12060000000000001
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711741500.125813,
        "relevant_snippets": [
            {
                "code": "\"\"\"Benchmarks of Singular Value Decomposition (Exact and Approximate)\n\nThe data is mostly low rank but is a fat infinite tail.\n\"\"\"\nimport gc\nfrom collections import defaultdict\nfrom time import time\n\nimport numpy as np\nfrom scipy.linalg import svd\n\nfrom sklearn.datasets import make_low_rank_matrix\nfrom sklearn.utils.extmath import randomized_svd\n\n\ndef compute_bench(samples_range, features_range, n_iter=3, rank=50):\n    it = 0\n\n    results = defaultdict(lambda: [])\n\n    max_it = len(samples_range) * len(features_range)\n    for n_samples in samples_range:\n        for n_features in features_range:\n            it += 1\n            print(\"====================\")\n            print(\"Iteration %03d of %03d\" % (it, max_it))\n            print(\"====================\")\n            X = make_low_rank_matrix(\n                n_samples, n_features, effective_rank=rank, tail_strength=0.2\n            )\n\n            gc.collect()\n            print(\"benchmarking scipy svd: \")\n            tstart = time()\n            svd(X, full_matrices=False)\n            results[\"scipy svd\"].append(time() - tstart)\n\n            gc.collect()\n            print(\"benchmarking scikit-learn randomized_svd: n_iter=0\")\n            tstart = time()\n            randomized_svd(X, rank, n_iter=0)\n            results[\"scikit-learn randomized_svd (n_iter=0)\"].append(time() - tstart)\n\n            gc.collect()\n            print(\"benchmarking scikit-learn randomized_svd: n_iter=%d \" % n_iter)\n            tstart = time()\n            randomized_svd(X, rank, n_iter=n_iter)\n            results[\"scikit-learn randomized_svd (n_iter=%d)\" % n_iter].append(\n                time() - tstart\n            )\n\n    return results\n\n\nif __name__ == \"__main__\":\n    from mpl_toolkits.mplot3d import axes3d  # noqa register the 3d projection\n    import matplotlib.pyplot as plt\n\n    samples_range = np.linspace(2, 1000, 4).astype(int)\n    features_range = np.linspace(2, 1000, 4).astype(int)\n    results = compute_bench(samples_range, features_range)\n\n    label = \"scikit-learn singular value decomposition benchmark results\"\n    fig = plt.figure(label)\n    ax = fig.gca(projection=\"3d\")\n    for c, (label, timings) in zip(\"rbg\", sorted(results.items())):\n        X, Y = np.meshgrid(samples_range, features_range)\n        Z = np.asarray(timings).reshape(samples_range.shape[0], features_range.shape[0])\n        # plot the actual surface\n        ax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3, color=c)\n        # dummy point plot to stick the legend to since surface plot do not\n        # support legends (yet?)\n        ax.plot([1], [1], [1], color=c, label=label)\n\n    ax.set_xlabel(\"n_samples\")\n    ax.set_ylabel(\"n_features\")\n    ax.set_zlabel(\"Time (s)\")\n    ax.legend()\n    plt.show()",
                "filename": "benchmarks/bench_plot_svd.py",
                "start_index": 0,
                "end_index": 2748,
                "start_line": 1,
                "end_line": 79,
                "max_line": 79,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "from time import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.sparse as sparse\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\ndegree = 2\ntrials = 3\nnum_rows = 1000\ndimensionalities = np.array([1, 2, 8, 16, 32, 64])\ndensities = np.array([0.01, 0.1, 1.0])\ncsr_times = {d: np.zeros(len(dimensionalities)) for d in densities}\ndense_times = {d: np.zeros(len(dimensionalities)) for d in densities}\ntransform = PolynomialFeatures(\n    degree=degree, include_bias=False, interaction_only=False\n)\n\nfor trial in range(trials):\n    for density in densities:\n        for dim_index, dim in enumerate(dimensionalities):\n            print(trial, density, dim)\n            X_csr = sparse.random(num_rows, dim, density).tocsr()\n            X_dense = X_csr.toarray()\n            # CSR\n            t0 = time()\n            transform.fit_transform(X_csr)\n            csr_times[density][dim_index] += time() - t0\n            # Dense\n            t0 = time()\n            transform.fit_transform(X_dense)\n            dense_times[density][dim_index] += time() - t0\n\ncsr_linestyle = (0, (3, 1, 1, 1, 1, 1))  # densely dashdotdotted\ndense_linestyle = (0, ())  # solid\n\nfig, axes = plt.subplots(nrows=len(densities), ncols=1, figsize=(8, 10))\nfor density, ax in zip(densities, axes):\n    ax.plot(\n        dimensionalities,\n        csr_times[density] / trials,\n        label=\"csr\",\n        linestyle=csr_linestyle,\n    )\n    ax.plot(\n        dimensionalities,\n        dense_times[density] / trials,\n        label=\"dense\",\n        linestyle=dense_linestyle,\n    )\n    ax.set_title(\"density %0.2f, degree=%d, n_samples=%d\" % (density, degree, num_rows))\n    ax.legend()\n    ax.set_xlabel(\"Dimensionality\")\n    ax.set_ylabel(\"Time (seconds)\")\n\nplt.tight_layout()\nplt.show()",
                "filename": "benchmarks/bench_feature_expansions.py",
                "start_index": 0,
                "end_index": 1773,
                "start_line": 1,
                "end_line": 58,
                "max_line": 58,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"\nBenchmarks on the power iterations phase in randomized SVD.\n\nWe test on various synthetic and real datasets the effect of increasing\nthe number of power iterations in terms of quality of approximation\nand running time. A number greater than 0 should help with noisy matrices,\nwhich are characterized by a slow spectral decay.\n\nWe test several policy for normalizing the power iterations. Normalization\nis crucial to avoid numerical issues.\n\nThe quality of the approximation is measured by the spectral norm discrepancy\nbetween the original input matrix and the reconstructed one (by multiplying\nthe randomized_svd's outputs). The spectral norm is always equivalent to the\nlargest singular value of a matrix. (3) justifies this choice. However, one can\nnotice in these experiments that Frobenius and spectral norms behave\nvery similarly in a qualitative sense. Therefore, we suggest to run these\nbenchmarks with `enable_spectral_norm = False`, as Frobenius' is MUCH faster to\ncompute.\n\nThe benchmarks follow.\n\n(a) plot: time vs norm, varying number of power iterations\n    data: many datasets\n    goal: compare normalization policies and study how the number of power\n    iterations affect time and norm\n\n(b) plot: n_iter vs norm, varying rank of data and number of components for\n    randomized_SVD\n    data: low-rank matrices on which we control the rank\n    goal: study whether the rank of the matrix and the number of components\n    extracted by randomized SVD affect \"the optimal\" number of power iterations\n\n(c) plot: time vs norm, varying datasets\n    data: many datasets\n    goal: compare default configurations\n\nWe compare the following algorithms:\n-   randomized_svd(..., power_iteration_normalizer='none')\n-   randomized_svd(..., power_iteration_normalizer='LU')\n-   randomized_svd(..., power_iteration_normalizer='QR')\n-   randomized_svd(..., power_iteration_normalizer='auto')\n-   fbpca.pca() from https://github.com/facebook/fbpca (if installed)\n\nConclusion\n----------\n- n_iter=2 appears to be a good default value\n- power_iteration_normalizer='none' is OK if n_iter is small, otherwise LU\n  gives similar errors to QR but is cheaper. That's what 'auto' implements.\n\nReferences\n----------\n(1) :arxiv:`\"Finding structure with randomness:\n    Stochastic algorithms for constructing approximate matrix decompositions.\"\n    <0909.4061>`\n    Halko, et al., (2009)\n\n(2) A randomized algorithm for the decomposition of matrices\n    Per-Gunnar Martinsson, Vladimir Rokhlin and Mark Tygert\n\n(3) An implementation of a randomized algorithm for principal component\n    analysis\n    A. Szlam et al. 2014\n\"\"\"\n\n# Author: Giorgio Patrini\n\nimport gc\nimport os.path\nimport pickle\nfrom collections import defaultdict\nfrom time import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy as sp",
                "filename": "benchmarks/bench_plot_randomized_svd.py",
                "start_index": 0,
                "end_index": 2808,
                "start_line": 1,
                "end_line": 76,
                "max_line": 528,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"\n==============================\nLasso on dense and sparse data\n==============================\n\nWe show that linear_model.Lasso provides the same results for dense and sparse\ndata and that in the case of sparse data the speed is improved.\n\n\"\"\"\n\nfrom time import time\n\nfrom scipy import linalg, sparse\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import Lasso\n\n# %%\n# Comparing the two Lasso implementations on Dense data\n# -----------------------------------------------------\n#\n# We create a linear regression problem that is suitable for the Lasso,\n# that is to say, with more features than samples. We then store the data\n# matrix in both dense (the usual) and sparse format, and train a Lasso on\n# each. We compute the runtime of both and check that they learned the\n# same model by computing the Euclidean norm of the difference between the\n# coefficients they learned. Because the data is dense, we expect better\n# runtime with a dense data format.\n\nX, y = make_regression(n_samples=200, n_features=5000, random_state=0)\n# create a copy of X in sparse format\nX_sp = sparse.coo_matrix(X)\n\nalpha = 1\nsparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)\ndense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)\n\nt0 = time()\nsparse_lasso.fit(X_sp, y)\nprint(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n\nt0 = time()\ndense_lasso.fit(X, y)\nprint(f\"Dense Lasso done in {(time() - t0):.3f}s\")\n\n# compare the regression coefficients\ncoeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\nprint(f\"Distance between coefficients : {coeff_diff:.2e}\")\n\n#\n# %%\n# Comparing the two Lasso implementations on Sparse data\n# ------------------------------------------------------\n#\n# We make the previous problem sparse by replacing all small values with 0\n# and run the same comparisons as above. Because the data is now sparse, we\n# expect the implementation that uses the sparse data format to be faster.\n\n# make a copy of the previous data\nXs = X.copy()\n# make Xs sparse by replacing the values lower than 2.5 with 0s\nXs[Xs < 2.5] = 0.0\n# create a copy of Xs in sparse format\nXs_sp = sparse.coo_matrix(Xs)\nXs_sp = Xs_sp.tocsc()\n\n# compute the proportion of non-zero coefficient in the data matrix\nprint(f\"Matrix density : {(Xs_sp.nnz / float(X.size) * 100):.3f}%\")\n\nalpha = 0.1\nsparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\ndense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n\nt0 = time()\nsparse_lasso.fit(Xs_sp, y)\nprint(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n\nt0 = time()\ndense_lasso.fit(Xs, y)\nprint(f\"Dense Lasso done in  {(time() - t0):.3f}s\")\n\n# compare the regression coefficients\ncoeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\nprint(f\"Distance between coefficients : {coeff_diff:.2e}\")\n\n# %%",
                "filename": "examples/linear_model/plot_lasso_dense_vs_sparse_data.py",
                "start_index": 0,
                "end_index": 2825,
                "start_line": 1,
                "end_line": 86,
                "max_line": 86,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def bench_c(datasets, n_comps):\n    all_time = defaultdict(list)\n    if enable_spectral_norm:\n        all_spectral = defaultdict(list)\n    all_frobenius = defaultdict(list)\n\n    for dataset_name in datasets:\n        X = get_data(dataset_name)\n        if X is None:\n            continue\n\n        if enable_spectral_norm:\n            X_spectral_norm = norm_diff(X, norm=2, msg=False, random_state=0)\n        X_fro_norm = norm_diff(X, norm=\"fro\", msg=False)\n        n_comps = np.minimum(n_comps, np.min(X.shape))\n\n        label = \"sklearn\"\n        print(\"%s %d x %d - %s\" % (dataset_name, X.shape[0], X.shape[1], label))\n        U, s, V, time = svd_timing(X, n_comps, n_iter=2, n_oversamples=10, method=label)\n\n        all_time[label].append(time)\n        if enable_spectral_norm:\n            A = U.dot(np.diag(s).dot(V))\n            all_spectral[label].append(\n                norm_diff(X - A, norm=2, random_state=0) / X_spectral_norm\n            )\n        f = scalable_frobenius_norm_discrepancy(X, U, s, V)\n        all_frobenius[label].append(f / X_fro_norm)\n\n        if fbpca_available:\n            label = \"fbpca\"\n            print(\"%s %d x %d - %s\" % (dataset_name, X.shape[0], X.shape[1], label))\n            U, s, V, time = svd_timing(\n                X, n_comps, n_iter=2, n_oversamples=2, method=label\n            )\n            all_time[label].append(time)\n            if enable_spectral_norm:\n                A = U.dot(np.diag(s).dot(V))\n                all_spectral[label].append(\n                    norm_diff(X - A, norm=2, random_state=0) / X_spectral_norm\n                )\n            f = scalable_frobenius_norm_discrepancy(X, U, s, V)\n            all_frobenius[label].append(f / X_fro_norm)\n\n    if len(all_time) == 0:\n        raise ValueError(\"No tests ran. Aborting.\")\n\n    if enable_spectral_norm:\n        title = \"normalized spectral norm diff vs running time\"\n        scatter_time_vs_s(all_time, all_spectral, datasets, title)\n    title = \"normalized Frobenius norm diff vs running time\"\n    scatter_time_vs_s(all_time, all_frobenius, datasets, title)\n\n\nif __name__ == \"__main__\":\n    random_state = check_random_state(1234)\n\n    power_iter = np.arange(0, 6)\n    n_comps = 50\n\n    for dataset_name in datasets:\n        X = get_data(dataset_name)\n        if X is None:\n            continue\n        print(\n            \" >>>>>> Benching sklearn and fbpca on %s %d x %d\"\n            % (dataset_name, X.shape[0], X.shape[1])\n        )\n        bench_a(\n            X,\n            dataset_name,\n            power_iter,\n            n_oversamples=2,\n            n_comps=np.minimum(n_comps, np.min(X.shape)),\n        )\n\n    print(\" >>>>>> Benching on simulated low rank matrix with variable rank\")\n    bench_b(power_iter)\n\n    print(\" >>>>>> Benching sklearn and fbpca default configurations\")\n    bench_c(datasets + big_sparse_datasets, n_comps)\n\n    plt.show()",
                "filename": "benchmarks/bench_plot_randomized_svd.py",
                "start_index": 15211,
                "end_index": 18085,
                "start_line": 446,
                "end_line": 528,
                "max_line": 528,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "if __name__ == \"__main__\":\n    print(\"============================================\")\n    print(\"Warning: this is going to take a looong time\")\n    print(\"============================================\")\n\n    n = 10\n    step = 10000\n    n_samples = 10000\n    dim = 10\n    n_classes = 10\n    for i in range(n):\n        print(\"============================================\")\n        print(\"Entering iteration %s of %s\" % (i, n))\n        print(\"============================================\")\n        n_samples += step\n        X = np.random.randn(n_samples, dim)\n        Y = np.random.randint(0, n_classes, (n_samples,))\n        bench_scikit_tree_classifier(X, Y)\n        Y = np.random.randn(n_samples)\n        bench_scikit_tree_regressor(X, Y)\n\n    xx = range(0, n * step, step)\n    plt.figure(\"scikit-learn tree benchmark results\")\n    plt.subplot(211)\n    plt.title(\"Learning with varying number of samples\")\n    plt.plot(xx, scikit_classifier_results, \"g-\", label=\"classification\")\n    plt.plot(xx, scikit_regressor_results, \"r-\", label=\"regression\")\n    plt.legend(loc=\"upper left\")\n    plt.xlabel(\"number of samples\")\n    plt.ylabel(\"Time (s)\")\n\n    scikit_classifier_results = []\n    scikit_regressor_results = []\n    n = 10\n    step = 500\n    start_dim = 500\n    n_classes = 10\n\n    dim = start_dim\n    for i in range(0, n):\n        print(\"============================================\")\n        print(\"Entering iteration %s of %s\" % (i, n))\n        print(\"============================================\")\n        dim += step\n        X = np.random.randn(100, dim)\n        Y = np.random.randint(0, n_classes, (100,))\n        bench_scikit_tree_classifier(X, Y)\n        Y = np.random.randn(100)\n        bench_scikit_tree_regressor(X, Y)\n\n    xx = np.arange(start_dim, start_dim + n * step, step)\n    plt.subplot(212)\n    plt.title(\"Learning in high dimensional spaces\")\n    plt.plot(xx, scikit_classifier_results, \"g-\", label=\"classification\")\n    plt.plot(xx, scikit_regressor_results, \"r-\", label=\"regression\")\n    plt.legend(loc=\"upper left\")\n    plt.xlabel(\"number of dimensions\")\n    plt.ylabel(\"Time (s)\")\n    plt.axis(\"tight\")\n    plt.show()",
                "filename": "benchmarks/bench_tree.py",
                "start_index": 1480,
                "end_index": 3622,
                "start_line": 63,
                "end_line": 122,
                "max_line": 122,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"\nA comparison of different methods in GLM\n\nData comes from a random square matrix.\n\n\"\"\"\nfrom datetime import datetime\n\nimport numpy as np\n\nfrom sklearn import linear_model\n\nif __name__ == \"__main__\":\n    import matplotlib.pyplot as plt\n\n    n_iter = 40\n\n    time_ridge = np.empty(n_iter)\n    time_ols = np.empty(n_iter)\n    time_lasso = np.empty(n_iter)\n\n    dimensions = 500 * np.arange(1, n_iter + 1)\n\n    for i in range(n_iter):\n        print(\"Iteration %s of %s\" % (i, n_iter))\n\n        n_samples, n_features = 10 * i + 3, 10 * i + 3\n\n        X = np.random.randn(n_samples, n_features)\n        Y = np.random.randn(n_samples)\n\n        start = datetime.now()\n        ridge = linear_model.Ridge(alpha=1.0)\n        ridge.fit(X, Y)\n        time_ridge[i] = (datetime.now() - start).total_seconds()\n\n        start = datetime.now()\n        ols = linear_model.LinearRegression()\n        ols.fit(X, Y)\n        time_ols[i] = (datetime.now() - start).total_seconds()\n\n        start = datetime.now()\n        lasso = linear_model.LassoLars()\n        lasso.fit(X, Y)\n        time_lasso[i] = (datetime.now() - start).total_seconds()\n\n    plt.figure(\"scikit-learn GLM benchmark results\")\n    plt.xlabel(\"Dimensions\")\n    plt.ylabel(\"Time (s)\")\n    plt.plot(dimensions, time_ridge, color=\"r\")\n    plt.plot(dimensions, time_ols, color=\"g\")\n    plt.plot(dimensions, time_lasso, color=\"b\")\n\n    plt.legend([\"Ridge\", \"OLS\", \"LassoLars\"], loc=\"upper left\")\n    plt.axis(\"tight\")\n    plt.show()",
                "filename": "benchmarks/bench_glm.py",
                "start_index": 0,
                "end_index": 1477,
                "start_line": 1,
                "end_line": 56,
                "max_line": 56,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"\n===========================\nRandom projection benchmark\n===========================\n\nBenchmarks for random projections.\n\n\"\"\"\nimport collections\nimport gc\nimport optparse\nimport sys\nfrom datetime import datetime\n\nimport numpy as np\nimport scipy.sparse as sp\n\nfrom sklearn import clone\nfrom sklearn.random_projection import (\n    GaussianRandomProjection,\n    SparseRandomProjection,\n    johnson_lindenstrauss_min_dim,\n)\n\n\ndef type_auto_or_float(val):\n    if val == \"auto\":\n        return \"auto\"\n    else:\n        return float(val)\n\n\ndef type_auto_or_int(val):\n    if val == \"auto\":\n        return \"auto\"\n    else:\n        return int(val)\n\n\ndef compute_time(t_start, delta):\n    mu_second = 0.0 + 10**6  # number of microseconds in a second\n\n    return delta.seconds + delta.microseconds / mu_second\n\n\ndef bench_scikit_transformer(X, transformer):\n    gc.collect()\n\n    clf = clone(transformer)\n\n    # start time\n    t_start = datetime.now()\n    clf.fit(X)\n    delta = datetime.now() - t_start\n    # stop time\n    time_to_fit = compute_time(t_start, delta)\n\n    # start time\n    t_start = datetime.now()\n    clf.transform(X)\n    delta = datetime.now() - t_start\n    # stop time\n    time_to_transform = compute_time(t_start, delta)\n\n    return time_to_fit, time_to_transform\n\n\n# Make some random data with uniformly located non zero entries with\n# Gaussian distributed values\ndef make_sparse_random_data(n_samples, n_features, n_nonzeros, random_state=None):\n    rng = np.random.RandomState(random_state)\n    data_coo = sp.coo_matrix(\n        (\n            rng.randn(n_nonzeros),\n            (\n                rng.randint(n_samples, size=n_nonzeros),\n                rng.randint(n_features, size=n_nonzeros),\n            ),\n        ),\n        shape=(n_samples, n_features),\n    )\n    return data_coo.toarray(), data_coo.tocsr()\n\n\ndef print_row(clf_type, time_fit, time_transform):\n    print(\n        \"%s | %s | %s\"\n        % (\n            clf_type.ljust(30),\n            (\"%.4fs\" % time_fit).center(12),\n            (\"%.4fs\" % time_transform).center(12),\n        )\n    )",
                "filename": "benchmarks/bench_random_projections.py",
                "start_index": 0,
                "end_index": 2071,
                "start_line": 1,
                "end_line": 296,
                "max_line": 303,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"\n=========================================================================\nComparing randomized search and grid search for hyperparameter estimation\n=========================================================================\n\nCompare randomized search and grid search for optimizing hyperparameters of a\nlinear SVM with SGD training.\nAll parameters that influence the learning are searched simultaneously\n(except for the number of estimators, which poses a time / quality tradeoff).\n\nThe randomized search and the grid search explore exactly the same space of\nparameters. The result in parameter settings is quite similar, while the run\ntime for randomized search is drastically lower.\n\nThe performance is may slightly worse for the randomized search, and is likely\ndue to a noise effect and would not carry over to a held-out test set.\n\nNote that in practice, one would not search over this many different parameters\nsimultaneously using grid search, but pick only the ones deemed most important.\n\n\"\"\"\n\nfrom time import time\n\nimport numpy as np\nimport scipy.stats as stats\n\nfrom sklearn.datasets import load_digits\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n# get some data\nX, y = load_digits(return_X_y=True, n_class=3)\n\n# build a classifier\nclf = SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True)\n\n\n# Utility function to report best scores\ndef report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\n                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                    results[\"mean_test_score\"][candidate],\n                    results[\"std_test_score\"][candidate],\n                )\n            )\n            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n            print(\"\")\n\n\n# specify parameters and distributions to sample from\nparam_dist = {\n    \"average\": [True, False],\n    \"l1_ratio\": stats.uniform(0, 1),\n    \"alpha\": stats.loguniform(1e-2, 1e0),\n}\n\n# run randomized search\nn_iter_search = 15\nrandom_search = RandomizedSearchCV(\n    clf, param_distributions=param_dist, n_iter=n_iter_search\n)\n\nstart = time()\nrandom_search.fit(X, y)\nprint(\n    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n    % ((time() - start), n_iter_search)\n)\nreport(random_search.cv_results_)\n\n# use a full grid over all parameters\nparam_grid = {\n    \"average\": [True, False],\n    \"l1_ratio\": np.linspace(0, 1, num=10),\n    \"alpha\": np.power(10, np.arange(-2, 1, dtype=float)),\n}\n\n# run grid search\ngrid_search = GridSearchCV(clf, param_grid=param_grid)\nstart = time()\ngrid_search.fit(X, y)\n\nprint(\n    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n)",
                "filename": "examples/model_selection/plot_randomized_search.py",
                "start_index": 0,
                "end_index": 2970,
                "start_line": 1,
                "end_line": 92,
                "max_line": 92,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "\"\"\"\nBenchmark SGD prediction time with dense/sparse coefficients.\n\nInvoke with\n-----------\n\n$ kernprof.py -l sparsity_benchmark.py\n$ python -m line_profiler sparsity_benchmark.py.lprof\n\nTypical output\n--------------\n\ninput data sparsity: 0.050000\ntrue coef sparsity: 0.000100\ntest data sparsity: 0.027400\nmodel sparsity: 0.000024\nr^2 on test data (dense model) : 0.233651\nr^2 on test data (sparse model) : 0.233651\nWrote profile results to sparsity_benchmark.py.lprof\nTimer unit: 1e-06 s\n\nFile: sparsity_benchmark.py\nFunction: benchmark_dense_predict at line 51\nTotal time: 0.532979 s\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n    51                                           @profile\n    52                                           def benchmark_dense_predict():\n    53       301          640      2.1      0.1      for _ in range(300):\n    54       300       532339   1774.5     99.9          clf.predict(X_test)\n\nFile: sparsity_benchmark.py\nFunction: benchmark_sparse_predict at line 56\nTotal time: 0.39274 s\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n    56                                           @profile\n    57                                           def benchmark_sparse_predict():\n    58         1        10854  10854.0      2.8      X_test_sparse = csr_matrix(X_test)\n    59       301          477      1.6      0.1      for _ in range(300):\n    60       300       381409   1271.4     97.1          clf.predict(X_test_sparse)\n\"\"\"\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.metrics import r2_score\n\nnp.random.seed(42)\n\n\ndef sparsity_ratio(X):\n    return np.count_nonzero(X) / float(n_samples * n_features)\n\n\nn_samples, n_features = 5000, 300\nX = np.random.randn(n_samples, n_features)\ninds = np.arange(n_samples)\nnp.random.shuffle(inds)\nX[inds[int(n_features / 1.2) :]] = 0  # sparsify input\nprint(\"input data sparsity: %f\" % sparsity_ratio(X))\ncoef = 3 * np.random.randn(n_features)\ninds = np.arange(n_features)\nnp.random.shuffle(inds)\ncoef[inds[n_features // 2 :]] = 0  # sparsify coef\nprint(\"true coef sparsity: %f\" % sparsity_ratio(coef))\ny = np.dot(X, coef)\n\n# add noise\ny += 0.01 * np.random.normal((n_samples,))\n\n# Split data in train set and test set\nn_samples = X.shape[0]\nX_train, y_train = X[: n_samples // 2], y[: n_samples // 2]\nX_test, y_test = X[n_samples // 2 :], y[n_samples // 2 :]\nprint(\"test data sparsity: %f\" % sparsity_ratio(X_test))\n\n###############################################################################\nclf = SGDRegressor(penalty=\"l1\", alpha=0.2, max_iter=2000, tol=None)\nclf.fit(X_train, y_train)\nprint(\"model sparsity: %f\" % sparsity_ratio(clf.coef_))\n\n\ndef benchmark_dense_predict():\n    for _ in range(300):\n        clf.predict(X_test)",
                "filename": "benchmarks/bench_sparsify.py",
                "start_index": 0,
                "end_index": 2930,
                "start_line": 1,
                "end_line": 89,
                "max_line": 107,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "benchmarks/bench_plot_randomized_svd.py": [
                {
                    "chunk": {
                        "code": "\"\"\"\nBenchmarks on the power iterations phase in randomized SVD.\n\nWe test on various synthetic and real datasets the effect of increasing\nthe number of power iterations in terms of quality of approximation\nand running time. A number greater than 0 should help with noisy matrices,\nwhich are characterized by a slow spectral decay.\n\nWe test several policy for normalizing the power iterations. Normalization\nis crucial to avoid numerical issues.\n\nThe quality of the approximation is measured by the spectral norm discrepancy\nbetween the original input matrix and the reconstructed one (by multiplying\nthe randomized_svd's outputs). The spectral norm is always equivalent to the\nlargest singular value of a matrix. (3) justifies this choice. However, one can\nnotice in these experiments that Frobenius and spectral norms behave\nvery similarly in a qualitative sense. Therefore, we suggest to run these\nbenchmarks with `enable_spectral_norm = False`, as Frobenius' is MUCH faster to\ncompute.\n\nThe benchmarks follow.\n\n(a) plot: time vs norm, varying number of power iterations\n    data: many datasets\n    goal: compare normalization policies and study how the number of power\n    iterations affect time and norm\n\n(b) plot: n_iter vs norm, varying rank of data and number of components for\n    randomized_SVD\n    data: low-rank matrices on which we control the rank\n    goal: study whether the rank of the matrix and the number of components\n    extracted by randomized SVD affect \"the optimal\" number of power iterations\n\n(c) plot: time vs norm, varying datasets\n    data: many datasets\n    goal: compare default configurations\n\nWe compare the following algorithms:\n-   randomized_svd(..., power_iteration_normalizer='none')\n-   randomized_svd(..., power_iteration_normalizer='LU')\n-   randomized_svd(..., power_iteration_normalizer='QR')\n-   randomized_svd(..., power_iteration_normalizer='auto')\n-   fbpca.pca() from https://github.com/facebook/fbpca (if installed)\n\nConclusion\n----------\n- n_iter=2 appears to be a good default value\n- power_iteration_normalizer='none' is OK if n_iter is small, otherwise LU\n  gives similar errors to QR but is cheaper. That's what 'auto' implements.\n\nReferences\n----------\n(1) :arxiv:`\"Finding structure with randomness:\n    Stochastic algorithms for constructing approximate matrix decompositions.\"\n    <0909.4061>`\n    Halko, et al., (2009)\n\n(2) A randomized algorithm for the decomposition of matrices\n    Per-Gunnar Martinsson, Vladimir Rokhlin and Mark Tygert\n\n(3) An implementation of a randomized algorithm for principal component\n    analysis\n    A. Szlam et al. 2014\n\"\"\"\n\n# Author: Giorgio Patrini\n\nimport gc\nimport os.path\nimport pickle\nfrom collections import defaultdict\nfrom time import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy as sp",
                        "filename": "benchmarks/bench_plot_randomized_svd.py",
                        "start_index": 0,
                        "end_index": 2808,
                        "start_line": 1,
                        "end_line": 76,
                        "max_line": 528,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains benchmarks related to the randomized_svd function, which is directly relevant to the issue of performance with different sparse matrix types."
                },
                {
                    "chunk": {
                        "code": "def bench_c(datasets, n_comps):\n    all_time = defaultdict(list)\n    if enable_spectral_norm:\n        all_spectral = defaultdict(list)\n    all_frobenius = defaultdict(list)\n\n    for dataset_name in datasets:\n        X = get_data(dataset_name)\n        if X is None:\n            continue\n\n        if enable_spectral_norm:\n            X_spectral_norm = norm_diff(X, norm=2, msg=False, random_state=0)\n        X_fro_norm = norm_diff(X, norm=\"fro\", msg=False)\n        n_comps = np.minimum(n_comps, np.min(X.shape))\n\n        label = \"sklearn\"\n        print(\"%s %d x %d - %s\" % (dataset_name, X.shape[0], X.shape[1], label))\n        U, s, V, time = svd_timing(X, n_comps, n_iter=2, n_oversamples=10, method=label)\n\n        all_time[label].append(time)\n        if enable_spectral_norm:\n            A = U.dot(np.diag(s).dot(V))\n            all_spectral[label].append(\n                norm_diff(X - A, norm=2, random_state=0) / X_spectral_norm\n            )\n        f = scalable_frobenius_norm_discrepancy(X, U, s, V)\n        all_frobenius[label].append(f / X_fro_norm)\n\n        if fbpca_available:\n            label = \"fbpca\"\n            print(\"%s %d x %d - %s\" % (dataset_name, X.shape[0], X.shape[1], label))\n            U, s, V, time = svd_timing(\n                X, n_comps, n_iter=2, n_oversamples=2, method=label\n            )\n            all_time[label].append(time)\n            if enable_spectral_norm:\n                A = U.dot(np.diag(s).dot(V))\n                all_spectral[label].append(\n                    norm_diff(X - A, norm=2, random_state=0) / X_spectral_norm\n                )\n            f = scalable_frobenius_norm_discrepancy(X, U, s, V)\n            all_frobenius[label].append(f / X_fro_norm)\n\n    if len(all_time) == 0:\n        raise ValueError(\"No tests ran. Aborting.\")\n\n    if enable_spectral_norm:\n        title = \"normalized spectral norm diff vs running time\"\n        scatter_time_vs_s(all_time, all_spectral, datasets, title)\n    title = \"normalized Frobenius norm diff vs running time\"\n    scatter_time_vs_s(all_time, all_frobenius, datasets, title)\n\n\nif __name__ == \"__main__\":\n    random_state = check_random_state(1234)\n\n    power_iter = np.arange(0, 6)\n    n_comps = 50\n\n    for dataset_name in datasets:\n        X = get_data(dataset_name)\n        if X is None:\n            continue\n        print(\n            \" >>>>>> Benching sklearn and fbpca on %s %d x %d\"\n            % (dataset_name, X.shape[0], X.shape[1])\n        )\n        bench_a(\n            X,\n            dataset_name,\n            power_iter,\n            n_oversamples=2,\n            n_comps=np.minimum(n_comps, np.min(X.shape)),\n        )\n\n    print(\" >>>>>> Benching on simulated low rank matrix with variable rank\")\n    bench_b(power_iter)\n\n    print(\" >>>>>> Benching sklearn and fbpca default configurations\")\n    bench_c(datasets + big_sparse_datasets, n_comps)\n\n    plt.show()",
                        "filename": "benchmarks/bench_plot_randomized_svd.py",
                        "start_index": 15211,
                        "end_index": 18085,
                        "start_line": 446,
                        "end_line": 528,
                        "max_line": 528,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet includes a benchmarking function for randomized_svd, which is relevant to the issue as it may help identify performance discrepancies across different matrix types."
                }
            ]
        },
        "solution_task": "- Convert `dok_matrix` and `lil_matrix` to `csr_matrix` before calling `randomized_svd` to improve performance.\n- Add a warning message to inform users about the performance impact when using inefficient sparse matrix types like `dok_matrix` and `lil_matrix`.\n- Example code snippet to convert and warn:\n\n```python\nfrom scipy.sparse import dok_matrix, lil_matrix, csr_matrix\nfrom sklearn.utils.extmath import randomized_svd\nfrom warnings import warn\n\ndef efficient_randomized_svd(X, n_components, random_state=None):\n    if isinstance(X, (dok_matrix, lil_matrix)):\n        warn(\"Converting to csr_matrix for efficiency reasons.\")\n        X = csr_matrix(X)\n    return randomized_svd(X, n_components, random_state=random_state)\n```",
        "bouncer_response": {
            "score": 9,
            "criteria": "RESPONSE delivers precise, actionable, and highly relevant hints and solutions that can directly lead to resolving the issues outlined in the PROMPT.",
            "supporting_evidence": "The RESPONSE provides a direct and actionable solution to the problem of `randomized_svd` being slow for `dok_matrix` and `lil_matrix`. It suggests converting these matrix types to `csr_matrix` before performing the SVD, which is known to be more efficient for these operations. Additionally, the RESPONSE includes a code snippet that not only performs the conversion but also issues a warning to the user, which addresses the expectation set in the PROMPT for either similar processing times or a warning. The RESPONSE also points to specific code snippets in the project's repository that could be relevant for benchmarking and further investigation, which is useful for developers looking to understand and address the performance issue in depth. The only reason for not giving a score of 10 is that the RESPONSE does not provide a detailed explanation of why `dok_matrix` and `lil_matrix` are slower, which could be valuable for a complete understanding of the issue. However, the RESPONSE is still highly valuable and actionable.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711741706.1080298,
        "result": "- Convert `dok_matrix` and `lil_matrix` to `csr_matrix` before calling `randomized_svd` to improve performance.\n- Add a warning message to inform users about the performance impact when using inefficient sparse matrix types like `dok_matrix` and `lil_matrix`.\n- Example code snippet to convert and warn:\n\n```python\nfrom scipy.sparse import dok_matrix, lil_matrix, csr_matrix\nfrom sklearn.utils.extmath import randomized_svd\nfrom warnings import warn\n\ndef efficient_randomized_svd(X, n_components, random_state=None):\n    if isinstance(X, (dok_matrix, lil_matrix)):\n        warn(\"Converting to csr_matrix for efficiency reasons.\")\n        X = csr_matrix(X)\n    return randomized_svd(X, n_components, random_state=random_state)\n```\n\n### Code snippets to check\n\n-  \u2192 [benchmarks](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//benchmarks)- [Lines 1 - 76](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//benchmarks/bench_plot_randomized_svd.py#L1-L76)\n\n This snippet contains benchmarks related to the randomized_svd function, which is directly relevant to the issue of performance with different sparse matrix types. \n\n\n   - [Lines 446 - 528](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//benchmarks/bench_plot_randomized_svd.py#L446-L528)\n\n This snippet includes a benchmarking function for randomized_svd, which is relevant to the issue as it may help identify performance discrepancies across different matrix types."
    }
}