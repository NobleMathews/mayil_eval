{
    "id": "pydata__xarray-6400",
    "repo_name": "testbed/pydata__xarray__2022.03",
    "task_id": 5626561754578184485,
    "title": "Very poor html repr performance on large multi-indexes",
    "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports: http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples: https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nWe have catestrophic performance on the  html repr of some long multi-indexed data arrays. Here's a case of it taking 12s.\r\n\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nimport xarray as xr\r\n\r\nds = xr.tutorial.load_dataset(\"air_temperature\")\r\nda = ds[\"air\"].stack(z=[...])\r\n\r\nda.shape \r\n\r\n# (3869000,)\r\n\r\n%timeit -n 1 -r 1 da._repr_html_()\r\n\r\n# 12.4 s !!\r\n\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nI thought we'd fixed some issues here: https://github.com/pydata/xarray/pull/4846/files\r\n\r\n**Environment**:\r\n\r\n<details><summary>Output of <tt>xr.show_versions()</tt></summary>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.8.10 (default, May  9 2021, 13:21:55) \r\n[Clang 12.0.5 (clang-1205.0.22.9)]\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 20.4.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: None\r\nLOCALE: ('en_US', 'UTF-8')\r\nlibhdf5: None\r\nlibnetcdf: None\r\n\r\nxarray: 0.18.2\r\npandas: 1.2.4\r\nnumpy: 1.20.3\r\nscipy: 1.6.3\r\nnetCDF4: None\r\npydap: None\r\nh5netcdf: None\r\nh5py: None\r\nNio: None\r\nzarr: 2.8.3\r\ncftime: 1.4.1\r\nnc_time_axis: None\r\nPseudoNetCDF: None\r\nrasterio: 1.2.3\r\ncfgrib: None\r\niris: None\r\nbottleneck: 1.3.2\r\ndask: 2021.06.1\r\ndistributed: 2021.06.1\r\nmatplotlib: 3.4.2\r\ncartopy: None\r\nseaborn: 0.11.1\r\nnumbagg: 0.2.1\r\npint: None\r\nsetuptools: 56.0.0\r\npip: 21.1.2\r\nconda: None\r\npytest: 6.2.4\r\nIPython: 7.24.0\r\nsphinx: 4.0.1\r\n\r\n\r\n</details>\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/pydata__xarray__2022.03.git",
    "requested_commit": "",
    "mayil_response": "- Review the `array_repr` function in `xarray/core/formatting_html.py` to identify any inefficient operations when handling large multi-indexed data arrays.\n- Optimize the generation of the HTML representation by minimizing the amount of data processed or displayed. For example, limit the number of displayed index entries or summary details for large datasets.\n- Consider adding a check for the size of the data array and adjust the level of detail in the HTML representation accordingly.\n- Implement pagination or a toggle for expanding/collapsing sections of the HTML representation to avoid rendering all details at once for large datasets.\n- If the issue persists, profile the `_repr_html_` method to identify specific bottlenecks and optimize those parts of the code.\n\n### Code snippets to check\n\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray) \u2192 [core](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray/core)- [Lines 254 - 342](https://github.com/testbed/pydata__xarray__2022.03/blob//xarray/core/formatting_html.py#L254-L342)\n\n This snippet contains the implementation of the HTML representation for xarray objects, which is relevant to the performance issue with the HTML repr of multi-indexed data arrays.\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray) \u2192 [core](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray/core)- [Lines 626 - 877](https://github.com/testbed/pydata__xarray__2022.03/blob//xarray/core/formatting.py#L626-L877)\n\n This snippet includes the plain text representation functions for xarray objects, which might be relevant for comparison or as a fallback to the HTML repr, and could be useful for understanding the overall repr system.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.00075,
        "snippet_processor": 0.05790000000000001,
        "issue_star_creation": 0.02583,
        "issue_star_solver": 0.07288,
        "bouncer": 0.02492
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711752409.4559202,
        "relevant_snippets": [
            {
                "code": "import numpy as np\nimport pandas as pd\n\nimport xarray as xr\n\n\nclass Repr:\n    def setup(self):\n        a = np.arange(0, 100)\n        data_vars = dict()\n        for i in a:\n            data_vars[f\"long_variable_name_{i}\"] = xr.DataArray(\n                name=f\"long_variable_name_{i}\",\n                data=np.arange(0, 20),\n                dims=[f\"long_coord_name_{i}_x\"],\n                coords={f\"long_coord_name_{i}_x\": np.arange(0, 20) * 2},\n            )\n        self.ds = xr.Dataset(data_vars)\n        self.ds.attrs = {f\"attr_{k}\": 2 for k in a}\n\n    def time_repr(self):\n        repr(self.ds)\n\n    def time_repr_html(self):\n        self.ds._repr_html_()\n\n\nclass ReprMultiIndex:\n    def setup(self):\n        index = pd.MultiIndex.from_product(\n            [range(1000), range(1000)], names=(\"level_0\", \"level_1\")\n        )\n        series = pd.Series(range(1000 * 1000), index=index)\n        self.da = xr.DataArray(series)\n\n    def time_repr(self):\n        repr(self.da)\n\n    def time_repr_html(self):\n        self.da._repr_html_()",
                "filename": "asv_bench/benchmarks/repr.py",
                "start_index": 0,
                "end_index": 1036,
                "start_line": 1,
                "end_line": 40,
                "max_line": 40,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "index_section = partial(\n    _mapping_section,\n    name=\"Indexes\",\n    details_func=summarize_indexes,\n    max_items_collapse=0,\n    expand_option_name=\"display_expand_indexes\",\n)\n\nattr_section = partial(\n    _mapping_section,\n    name=\"Attributes\",\n    details_func=summarize_attrs,\n    max_items_collapse=10,\n    expand_option_name=\"display_expand_attrs\",\n)\n\n\ndef _get_indexes_dict(indexes):\n    return {\n        tuple(index_vars.keys()): idx for idx, index_vars in indexes.group_by_index()\n    }\n\n\ndef _obj_repr(obj, header_components, sections):\n    \"\"\"Return HTML repr of an xarray object.\n\n    If CSS is not injected (untrusted notebook), fallback to the plain text repr.\n\n    \"\"\"\n    header = f\"<div class='xr-header'>{''.join(h for h in header_components)}</div>\"\n    sections = \"\".join(f\"<li class='xr-section-item'>{s}</li>\" for s in sections)\n\n    icons_svg, css_style = _load_static_files()\n    return (\n        \"<div>\"\n        f\"{icons_svg}<style>{css_style}</style>\"\n        f\"<pre class='xr-text-repr-fallback'>{escape(repr(obj))}</pre>\"\n        \"<div class='xr-wrap' style='display:none'>\"\n        f\"{header}\"\n        f\"<ul class='xr-sections'>{sections}</ul>\"\n        \"</div>\"\n        \"</div>\"\n    )\n\n\ndef array_repr(arr):\n    dims = OrderedDict((k, v) for k, v in zip(arr.dims, arr.shape))\n    if hasattr(arr, \"xindexes\"):\n        indexed_dims = arr.xindexes.dims\n    else:\n        indexed_dims = {}\n\n    obj_type = f\"xarray.{type(arr).__name__}\"\n    arr_name = f\"'{arr.name}'\" if getattr(arr, \"name\", None) else \"\"\n\n    header_components = [\n        f\"<div class='xr-obj-type'>{obj_type}</div>\",\n        f\"<div class='xr-array-name'>{arr_name}</div>\",\n        format_dims(dims, indexed_dims),\n    ]\n\n    sections = [array_section(arr)]\n\n    if hasattr(arr, \"coords\"):\n        sections.append(coord_section(arr.coords))\n\n    if hasattr(arr, \"xindexes\"):\n        indexes = _get_indexes_dict(arr.xindexes)\n        sections.append(index_section(indexes))\n\n    sections.append(attr_section(arr.attrs))\n\n    return _obj_repr(arr, header_components, sections)\n\n\ndef dataset_repr(ds):\n    obj_type = f\"xarray.{type(ds).__name__}\"\n\n    header_components = [f\"<div class='xr-obj-type'>{escape(obj_type)}</div>\"]\n\n    sections = [\n        dim_section(ds),\n        coord_section(ds.coords),\n        datavar_section(ds.data_vars),\n        index_section(_get_indexes_dict(ds.xindexes)),\n        attr_section(ds.attrs),\n    ]\n\n    return _obj_repr(ds, header_components, sections)",
                "filename": "xarray/core/formatting_html.py",
                "start_index": 7729,
                "end_index": 10213,
                "start_line": 254,
                "end_line": 342,
                "max_line": 342,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "cursive_repr(\"<recursive array>\")\ndef array_repr(arr):\n    from xarray.core.variable import Variable\n\n    max_rows = OPTIONS[\"display_max_rows\"]\n\n    # used for DataArray, Variable and IndexVariable\n    if hasattr(arr, \"name\") and arr.name is not None:\n        name_str = f\"{arr.name!r} \"\n    else:\n        name_str = \"\"\n\n    if (\n        isinstance(arr, Variable)\n        or _get_boolean_with_default(\"display_expand_data\", default=True)\n        or isinstance(arr.variable._data, MemoryCachedArray)\n    ):\n        data_repr = short_data_repr(arr)\n    else:\n        data_repr = inline_variable_array_repr(arr.variable, OPTIONS[\"display_width\"])\n\n    start = f\"<xarray.{type(arr).__name__} {name_str}\"\n    dims = dim_summary_limited(arr, col_width=len(start) + 1, max_rows=max_rows)\n    summary = [\n        f\"{start}({dims})>\",\n        data_repr,\n    ]\n\n    if hasattr(arr, \"coords\"):\n        if arr.coords:\n            col_width = _calculate_col_width(arr.coords)\n            summary.append(\n                coords_repr(arr.coords, col_width=col_width, max_rows=max_rows)\n            )\n\n        unindexed_dims_str = unindexed_dims_repr(\n            arr.dims, arr.coords, max_rows=max_rows\n        )\n        if unindexed_dims_str:\n            summary.append(unindexed_dims_str)\n\n        display_default_indexes = _get_boolean_with_default(\n            \"display_default_indexes\", False\n        )\n\n        xindexes = filter_nondefault_indexes(\n            _get_indexes_dict(arr.xindexes), not display_default_indexes\n        )\n\n        if xindexes:\n            summary.append(indexes_repr(xindexes, max_rows=max_rows))\n\n    if arr.attrs:\n        summary.append(attrs_repr(arr.attrs, max_rows=max_rows))\n\n    return \"\\n\".join(summary)\n\n\n@recursive_repr(\"<recursive Dataset>\")\ndef dataset_repr(ds):\n    summary = [f\"<xarray.{type(ds).__name__}>\"]\n\n    col_width = _calculate_col_width(ds.variables)\n    max_rows = OPTIONS[\"display_max_rows\"]\n\n    dims_start = pretty_print(\"Dimensions:\", col_width)\n    dims_values = dim_summary_limited(ds, col_width=col_width + 1, max_rows=max_rows)\n    summary.append(f\"{dims_start}({dims_values})\")\n\n    if ds.coords:\n        summary.append(coords_repr(ds.coords, col_width=col_width, max_rows=max_rows))\n\n    unindexed_dims_str = unindexed_dims_repr(ds.dims, ds.coords, max_rows=max_rows)\n    if unindexed_dims_str:\n        summary.append(unindexed_dims_str)\n\n    summary.append(data_vars_repr(ds.data_vars, col_width=col_width, max_rows=max_rows))\n\n    display_default_indexes = _get_boolean_with_default(\n        \"display_default_indexes\", False\n    )\n    xindexes = filter_nondefault_indexes(\n        _get_indexes_dict(ds.xindexes), not display_default_indexes\n    )\n    if xindexes:\n        summary.append(indexes_repr(xindexes, max_rows=max_rows))\n\n    if ds.attrs:\n        summary.append(attrs_repr(ds.attrs, max_rows=max_rows))\n\n    return \"\\n\".join(summary)\n\n\ndef",
                "filename": "xarray/core/formatting.py",
                "start_index": 20303,
                "end_index": 23207,
                "start_line": 626,
                "end_line": 877,
                "max_line": 893,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "class IOMultipleNetCDF:\n    \"\"\"\n    A few examples that benchmark reading/writing multiple netCDF files with\n    xarray\n    \"\"\"\n\n    timeout = 300.0\n    repeat = 1\n    number = 5\n\n    def make_ds(self, nfiles=10):\n        # multiple Dataset\n        self.ds = xr.Dataset()\n        self.nt = 1000\n        self.nx = 90\n        self.ny = 45\n        self.nfiles = nfiles\n\n        self.block_chunks = {\n            \"time\": self.nt / 4,\n            \"lon\": self.nx / 3,\n            \"lat\": self.ny / 3,\n        }\n\n        self.time_chunks = {\"time\": int(self.nt / 36)}\n\n        self.time_vars = np.split(\n            pd.date_range(\"1970-01-01\", periods=self.nt, freq=\"D\"), self.nfiles\n        )\n\n        self.ds_list = []\n        self.filenames_list = []\n        for i, times in enumerate(self.time_vars):\n            ds = xr.Dataset()\n            nt = len(times)\n            lons = xr.DataArray(\n                np.linspace(0, 360, self.nx),\n                dims=(\"lon\",),\n                attrs={\"units\": \"degrees east\", \"long_name\": \"longitude\"},\n            )\n            lats = xr.DataArray(\n                np.linspace(-90, 90, self.ny),\n                dims=(\"lat\",),\n                attrs={\"units\": \"degrees north\", \"long_name\": \"latitude\"},\n            )\n            ds[\"foo\"] = xr.DataArray(\n                randn((nt, self.nx, self.ny), frac_nan=0.2),\n                coords={\"lon\": lons, \"lat\": lats, \"time\": times},\n                dims=(\"time\", \"lon\", \"lat\"),\n                name=\"foo\",\n                attrs={\"units\": \"foo units\", \"description\": \"a description\"},\n            )\n            ds[\"bar\"] = xr.DataArray(\n                randn((nt, self.nx, self.ny), frac_nan=0.2),\n                coords={\"lon\": lons, \"lat\": lats, \"time\": times},\n                dims=(\"time\", \"lon\", \"lat\"),\n                name=\"bar\",\n                attrs={\"units\": \"bar units\", \"description\": \"a description\"},\n            )\n            ds[\"baz\"] = xr.DataArray(\n                randn((self.nx, self.ny), frac_nan=0.2).astype(np.float32),\n                coords={\"lon\": lons, \"lat\": lats},\n                dims=(\"lon\", \"lat\"),\n                name=\"baz\",\n                attrs={\"units\": \"baz units\", \"description\": \"a description\"},\n            )\n\n            ds.attrs = {\"history\": \"created for xarray benchmarking\"}\n\n            self.ds_list.append(ds)\n            self.filenames_list.append(\"test_netcdf_%i.nc\" % i)\n\n\nclass IOWriteMultipleNetCDF3(IOMultipleNetCDF):\n    def setup(self):\n        # TODO: Lazily skipped in CI as it is very demanding and slow.\n        # Improve times and remove errors.\n        _skip_slow()\n\n        self.make_ds()\n        self.format = \"NETCDF3_64BIT\"\n\n    def time_write_dataset_netcdf4(self):\n        xr.save_mfdataset(\n            self.ds_list, self.filenames_list, engine=\"netcdf4\", format=self.format\n        )\n\n    def time_write_dataset_scipy(self):\n        xr.save_mfdataset(\n            self.ds_list, self.filenames_list, engine=\"scipy\", format=self.format\n        )",
                "filename": "asv_bench/benchmarks/dataset_io.py",
                "start_index": 7697,
                "end_index": 10696,
                "start_line": 239,
                "end_line": 641,
                "max_line": 652,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "import numpy as np\n\nimport xarray as xr\n\nfrom . import requires_dask\n\nntime = 500\nnx = 50\nny = 50\n\n\nclass Reindex:\n    def setup(self):\n        data = np.random.RandomState(0).randn(ntime, nx, ny)\n        self.ds = xr.Dataset(\n            {\"temperature\": ((\"time\", \"x\", \"y\"), data)},\n            coords={\"time\": np.arange(ntime), \"x\": np.arange(nx), \"y\": np.arange(ny)},\n        )\n\n    def time_1d_coarse(self):\n        self.ds.reindex(time=np.arange(0, ntime, 5)).load()\n\n    def time_1d_fine_all_found(self):\n        self.ds.reindex(time=np.arange(0, ntime, 0.5), method=\"nearest\").load()\n\n    def time_1d_fine_some_missing(self):\n        self.ds.reindex(\n            time=np.arange(0, ntime, 0.5), method=\"nearest\", tolerance=0.1\n        ).load()\n\n    def time_2d_coarse(self):\n        self.ds.reindex(x=np.arange(0, nx, 2), y=np.arange(0, ny, 2)).load()\n\n    def time_2d_fine_all_found(self):\n        self.ds.reindex(\n            x=np.arange(0, nx, 0.5), y=np.arange(0, ny, 0.5), method=\"nearest\"\n        ).load()\n\n    def time_2d_fine_some_missing(self):\n        self.ds.reindex(\n            x=np.arange(0, nx, 0.5),\n            y=np.arange(0, ny, 0.5),\n            method=\"nearest\",\n            tolerance=0.1,\n        ).load()\n\n\nclass ReindexDask(Reindex):\n    def setup(self):\n        requires_dask()\n        super().setup()\n        self.ds = self.ds.chunk({\"time\": 100})",
                "filename": "asv_bench/benchmarks/reindexing.py",
                "start_index": 0,
                "end_index": 1378,
                "start_line": 1,
                "end_line": 52,
                "max_line": 52,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "/* CSS stylesheet for displaying xarray objects in jupyterlab.\n *\n */\n\n:root {\n  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n  --xr-background-color: var(--jp-layout-color0, white);\n  --xr-background-color-row-even: var(--jp-layout-color1, white);\n  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n}\n\nhtml[theme=dark],\nbody[data-theme=dark],\nbody.vscode-dark {\n  --xr-font-color0: rgba(255, 255, 255, 1);\n  --xr-font-color2: rgba(255, 255, 255, 0.54);\n  --xr-font-color3: rgba(255, 255, 255, 0.38);\n  --xr-border-color: #1F1F1F;\n  --xr-disabled-color: #515151;\n  --xr-background-color: #111111;\n  --xr-background-color-row-even: #111111;\n  --xr-background-color-row-odd: #313131;\n}\n\n.xr-wrap {\n  display: block !important;\n  min-width: 300px;\n  max-width: 700px;\n}\n\n.xr-text-repr-fallback {\n  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n  display: none;\n}\n\n.xr-header {\n  padding-top: 6px;\n  padding-bottom: 6px;\n  margin-bottom: 4px;\n  border-bottom: solid 1px var(--xr-border-color);\n}\n\n.xr-header > div,\n.xr-header > ul {\n  display: inline;\n  margin-top: 0;\n  margin-bottom: 0;\n}\n\n.xr-obj-type,\n.xr-array-name {\n  margin-left: 2px;\n  margin-right: 10px;\n}\n\n.xr-obj-type {\n  color: var(--xr-font-color2);\n}\n\n.xr-sections {\n  padding-left: 0 !important;\n  display: grid;\n  grid-template-columns: 150px auto auto 1fr 20px 20px;\n}\n\n.xr-section-item {\n  display: contents;\n}\n\n.xr-section-item input {\n  display: none;\n}\n\n.xr-section-item input + label {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-item input:enabled + label {\n  cursor: pointer;\n  color: var(--xr-font-color2);\n}\n\n.xr-section-item input:enabled + label:hover {\n  color: var(--xr-font-color0);\n}\n\n.xr-section-summary {\n  grid-column: 1;\n  color: var(--xr-font-color2);\n  font-weight: 500;\n}\n\n.xr-section-summary > span {\n  display: inline-block;\n  padding-left: 0.5em;\n}\n\n.xr-section-summary-in:disabled + label {\n  color: var(--xr-font-color2);\n}\n\n.xr-section-summary-in + label:before {\n  display: inline-block;\n  content: '\u25ba';\n  font-size: 11px;\n  width: 15px;\n  text-align: center;\n}\n\n.xr-section-summary-in:disabled + label:before {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-summary-in:checked + label:before {\n  content: '\u25bc';\n}\n\n.xr-section-summary-in:checked + label > span {\n  display: none;\n}\n\n.xr-section-summary,\n.xr-section-inline-details {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n.xr-section-inline-details {\n  grid-column: 2 / -1;\n}\n\n.xr-section-details {\n  display: none;\n  grid-column: 1 / -1;\n  margin-bottom: 5px;\n}\n\n.xr-section-summary-in:checked ~ .xr-section-details {\n  display: contents;\n}\n\n.x",
                "filename": "xarray/static/css/style.css",
                "start_index": 0,
                "end_index": 2932,
                "start_line": 1,
                "end_line": 340,
                "max_line": 348,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "import numpy as np\nimport pandas as pd\n\nimport xarray as xr\n\nfrom . import parameterized, requires_dask\n\n\nclass MultiIndexSeries:\n    def setup(self, dtype, subset):\n        data = np.random.rand(100000).astype(dtype)\n        index = pd.MultiIndex.from_product(\n            [\n                list(\"abcdefhijk\"),\n                list(\"abcdefhijk\"),\n                pd.date_range(start=\"2000-01-01\", periods=1000, freq=\"B\"),\n            ]\n        )\n        series = pd.Series(data, index)\n        if subset:\n            series = series[::3]\n        self.series = series\n\n    @parameterized([\"dtype\", \"subset\"], ([int, float], [True, False]))\n    def time_from_series(self, dtype, subset):\n        xr.DataArray.from_series(self.series)\n\n\nclass ToDataFrame:\n    def setup(self, *args, **kwargs):\n        xp = kwargs.get(\"xp\", np)\n        nvars = kwargs.get(\"nvars\", 1)\n        random_kws = kwargs.get(\"random_kws\", {})\n        method = kwargs.get(\"method\", \"to_dataframe\")\n\n        dim1 = 10_000\n        dim2 = 10_000\n\n        var = xr.Variable(\n            dims=(\"dim1\", \"dim2\"), data=xp.random.random((dim1, dim2), **random_kws)\n        )\n        data_vars = {f\"long_name_{v}\": ((\"dim1\", \"dim2\"), var) for v in range(nvars)}\n\n        ds = xr.Dataset(\n            data_vars, coords={\"dim1\": np.arange(0, dim1), \"dim2\": np.arange(0, dim2)}\n        )\n        self.to_frame = getattr(ds, method)\n\n    def time_to_dataframe(self):\n        self.to_frame()\n\n    def peakmem_to_dataframe(self):\n        self.to_frame()\n\n\nclass ToDataFrameDask(ToDataFrame):\n    def setup(self, *args, **kwargs):\n        requires_dask()\n\n        import dask.array as da\n\n        super().setup(\n            xp=da, random_kws=dict(chunks=5000), method=\"to_dask_dataframe\", nvars=500\n        )",
                "filename": "asv_bench/benchmarks/pandas.py",
                "start_index": 0,
                "end_index": 1762,
                "start_line": 1,
                "end_line": 64,
                "max_line": 64,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "def inline_dask_repr(array):\n    \"\"\"Similar to dask.array.DataArray.__repr__, but without\n    redundant information that's already printed by the repr\n    function of the xarray wrapper.\n    \"\"\"\n    assert isinstance(array, array_type(\"dask\")), array\n\n    chunksize = tuple(c[0] for c in array.chunks)\n\n    if hasattr(array, \"_meta\"):\n        meta = array._meta\n        identifier = (type(meta).__module__, type(meta).__name__)\n        meta_repr = _KNOWN_TYPE_REPRS.get(identifier, \".\".join(identifier))\n        meta_string = f\", meta={meta_repr}\"\n    else:\n        meta_string = \"\"\n\n    return f\"dask.array<chunksize={chunksize}{meta_string}>\"\n\n\ndef inline_sparse_repr(array):\n    \"\"\"Similar to sparse.COO.__repr__, but without the redundant shape/dtype.\"\"\"\n    sparse_array_type = array_type(\"sparse\")\n    assert isinstance(array, sparse_array_type), array\n    return \"<{}: nnz={:d}, fill_value={!s}>\".format(\n        type(array).__name__, array.nnz, array.fill_value\n    )\n\n\ndef inline_variable_array_repr(var, max_width):\n    \"\"\"Build a one-line summary of a variable's data.\"\"\"\n    if hasattr(var._data, \"_repr_inline_\"):\n        return var._data._repr_inline_(max_width)\n    if var._in_memory:\n        return format_array_flat(var, max_width)\n    dask_array_type = array_type(\"dask\")\n    if isinstance(var._data, dask_array_type):\n        return inline_dask_repr(var.data)\n    sparse_array_type = array_type(\"sparse\")\n    if isinstance(var._data, sparse_array_type):\n        return inline_sparse_repr(var.data)\n    if hasattr(var._data, \"__array_function__\"):\n        return maybe_truncate(repr(var._data).replace(\"\\n\", \" \"), max_width)\n    # internal xarray array type\n    return \"...\"\n\n\ndef summarize_variable(\n    name: Hashable,\n    var,\n    col_width: int,\n    max_width: int | None = None,\n    is_index: bool = False,\n):\n    \"\"\"Summarize a variable in one line, e.g., for the Dataset.__repr__.\"\"\"\n    variable = getattr(var, \"variable\", var)\n\n    if max_width is None:\n        max_width_options = OPTIONS[\"display_width\"]\n        if not isinstance(max_width_options, int):\n            raise TypeError(f\"`max_width` value of `{max_width}` is not a valid int\")\n        else:\n            max_width = max_width_options\n\n    marker = \"*\" if is_index else \" \"\n    first_col = pretty_print(f\"  {marker} {name} \", col_width)\n\n    if variable.dims:\n        dims_str = \"({}) \".format(\", \".join(map(str, variable.dims)))\n    else:\n        dims_str = \"\"\n    front_str = f\"{first_col}{dims_str}{variable.dtype} \"\n\n    values_width = max_width - len(front_str)\n    values_str = inline_variable_array_repr(variable, values_width)\n\n    return front_str + values_str",
                "filename": "xarray/core/formatting.py",
                "start_index": 8342,
                "end_index": 11003,
                "start_line": 240,
                "end_line": 316,
                "max_line": 893,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "from __future__ import annotations\n\nimport os\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\n\nimport xarray as xr\n\nfrom . import _skip_slow, parameterized, randint, randn, requires_dask\n\ntry:\n    import dask\n    import dask.multiprocessing\nexcept ImportError:\n    pass\n\n\nos.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n\n_ENGINES = tuple(xr.backends.list_engines().keys() - {\"store\"})\n\n\nclass IOSingleNetCDF:\n    \"\"\"\n    A few examples that benchmark reading/writing a single netCDF file with\n    xarray\n    \"\"\"\n\n    timeout = 300.0\n    repeat = 1\n    number = 5\n\n    def make_ds(self):\n        # single Dataset\n        self.ds = xr.Dataset()\n        self.nt = 1000\n        self.nx = 90\n        self.ny = 45\n\n        self.block_chunks = {\n            \"time\": self.nt / 4,\n            \"lon\": self.nx / 3,\n            \"lat\": self.ny / 3,\n        }\n\n        self.time_chunks = {\"time\": int(self.nt / 36)}\n\n        times = pd.date_range(\"1970-01-01\", periods=self.nt, freq=\"D\")\n        lons = xr.DataArray(\n            np.linspace(0, 360, self.nx),\n            dims=(\"lon\",),\n            attrs={\"units\": \"degrees east\", \"long_name\": \"longitude\"},\n        )\n        lats = xr.DataArray(\n            np.linspace(-90, 90, self.ny),\n            dims=(\"lat\",),\n            attrs={\"units\": \"degrees north\", \"long_name\": \"latitude\"},\n        )\n        self.ds[\"foo\"] = xr.DataArray(\n            randn((self.nt, self.nx, self.ny), frac_nan=0.2),\n            coords={\"lon\": lons, \"lat\": lats, \"time\": times},\n            dims=(\"time\", \"lon\", \"lat\"),\n            name=\"foo\",\n            attrs={\"units\": \"foo units\", \"description\": \"a description\"},\n        )\n        self.ds[\"bar\"] = xr.DataArray(\n            randn((self.nt, self.nx, self.ny), frac_nan=0.2),\n            coords={\"lon\": lons, \"lat\": lats, \"time\": times},\n            dims=(\"time\", \"lon\", \"lat\"),\n            name=\"bar\",\n            attrs={\"units\": \"bar units\", \"description\": \"a description\"},\n        )\n        self.ds[\"baz\"] = xr.DataArray(\n            randn((self.nx, self.ny), frac_nan=0.2).astype(np.float32),\n            coords={\"lon\": lons, \"lat\": lats},\n            dims=(\"lon\", \"lat\"),\n            name=\"baz\",\n            attrs={\"units\": \"baz units\", \"description\": \"a description\"},\n        )\n\n        self.ds.attrs = {\"history\": \"created for xarray benchmarking\"}\n\n        self.oinds = {\n            \"time\": randint(0, self.nt, 120),\n            \"lon\": randint(0, self.nx, 20),\n            \"lat\": randint(0, self.ny, 10),\n        }\n        self.vinds = {\n            \"time\": xr.DataArray(randint(0, self.nt, 120), dims=\"x\"),\n            \"lon\": xr.DataArray(randint(0, self.nx, 120), dims=\"x\"),\n            \"lat\": slice(3, 20),\n        }",
                "filename": "asv_bench/benchmarks/dataset_io.py",
                "start_index": 0,
                "end_index": 2724,
                "start_line": 1,
                "end_line": 607,
                "max_line": 652,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            },
            {
                "code": "import numpy as np\nimport pandas as pd\n\nimport xarray as xr\n\nfrom . import requires_dask, requires_sparse\n\n\nclass Unstacking:\n    def setup(self):\n        data = np.random.RandomState(0).randn(250, 500)\n        self.da_full = xr.DataArray(data, dims=list(\"ab\")).stack(flat_dim=[...])\n        self.da_missing = self.da_full[:-1]\n        self.df_missing = self.da_missing.to_pandas()\n\n    def time_unstack_fast(self):\n        self.da_full.unstack(\"flat_dim\")\n\n    def time_unstack_slow(self):\n        self.da_missing.unstack(\"flat_dim\")\n\n    def time_unstack_pandas_slow(self):\n        self.df_missing.unstack()\n\n\nclass UnstackingDask(Unstacking):\n    def setup(self, *args, **kwargs):\n        requires_dask()\n        super().setup(**kwargs)\n        self.da_full = self.da_full.chunk({\"flat_dim\": 25})\n\n\nclass UnstackingSparse(Unstacking):\n    def setup(self, *args, **kwargs):\n        requires_sparse()\n\n        import sparse\n\n        data = sparse.random((500, 1000), random_state=0, fill_value=0)\n        self.da_full = xr.DataArray(data, dims=list(\"ab\")).stack(flat_dim=[...])\n        self.da_missing = self.da_full[:-1]\n\n        mindex = pd.MultiIndex.from_arrays([np.arange(100), np.arange(100)])\n        self.da_eye_2d = xr.DataArray(np.ones((100,)), dims=\"z\", coords={\"z\": mindex})\n        self.da_eye_3d = xr.DataArray(\n            np.ones((100, 50)),\n            dims=(\"z\", \"foo\"),\n            coords={\"z\": mindex, \"foo\": np.arange(50)},\n        )\n\n    def time_unstack_to_sparse_2d(self):\n        self.da_eye_2d.unstack(sparse=True)\n\n    def time_unstack_to_sparse_3d(self):\n        self.da_eye_3d.unstack(sparse=True)\n\n    def peakmem_unstack_to_sparse_2d(self):\n        self.da_eye_2d.unstack(sparse=True)\n\n    def peakmem_unstack_to_sparse_3d(self):\n        self.da_eye_3d.unstack(sparse=True)\n\n    def time_unstack_pandas_slow(self):\n        pass",
                "filename": "asv_bench/benchmarks/unstacking.py",
                "start_index": 0,
                "end_index": 1859,
                "start_line": 1,
                "end_line": 64,
                "max_line": 64,
                "git_instance": "github",
                "repo_name": "testbed/pydata__xarray__2022.03",
                "sha": ""
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "xarray/core/formatting_html.py": [
                {
                    "chunk": {
                        "code": "index_section = partial(\n    _mapping_section,\n    name=\"Indexes\",\n    details_func=summarize_indexes,\n    max_items_collapse=0,\n    expand_option_name=\"display_expand_indexes\",\n)\n\nattr_section = partial(\n    _mapping_section,\n    name=\"Attributes\",\n    details_func=summarize_attrs,\n    max_items_collapse=10,\n    expand_option_name=\"display_expand_attrs\",\n)\n\n\ndef _get_indexes_dict(indexes):\n    return {\n        tuple(index_vars.keys()): idx for idx, index_vars in indexes.group_by_index()\n    }\n\n\ndef _obj_repr(obj, header_components, sections):\n    \"\"\"Return HTML repr of an xarray object.\n\n    If CSS is not injected (untrusted notebook), fallback to the plain text repr.\n\n    \"\"\"\n    header = f\"<div class='xr-header'>{''.join(h for h in header_components)}</div>\"\n    sections = \"\".join(f\"<li class='xr-section-item'>{s}</li>\" for s in sections)\n\n    icons_svg, css_style = _load_static_files()\n    return (\n        \"<div>\"\n        f\"{icons_svg}<style>{css_style}</style>\"\n        f\"<pre class='xr-text-repr-fallback'>{escape(repr(obj))}</pre>\"\n        \"<div class='xr-wrap' style='display:none'>\"\n        f\"{header}\"\n        f\"<ul class='xr-sections'>{sections}</ul>\"\n        \"</div>\"\n        \"</div>\"\n    )\n\n\ndef array_repr(arr):\n    dims = OrderedDict((k, v) for k, v in zip(arr.dims, arr.shape))\n    if hasattr(arr, \"xindexes\"):\n        indexed_dims = arr.xindexes.dims\n    else:\n        indexed_dims = {}\n\n    obj_type = f\"xarray.{type(arr).__name__}\"\n    arr_name = f\"'{arr.name}'\" if getattr(arr, \"name\", None) else \"\"\n\n    header_components = [\n        f\"<div class='xr-obj-type'>{obj_type}</div>\",\n        f\"<div class='xr-array-name'>{arr_name}</div>\",\n        format_dims(dims, indexed_dims),\n    ]\n\n    sections = [array_section(arr)]\n\n    if hasattr(arr, \"coords\"):\n        sections.append(coord_section(arr.coords))\n\n    if hasattr(arr, \"xindexes\"):\n        indexes = _get_indexes_dict(arr.xindexes)\n        sections.append(index_section(indexes))\n\n    sections.append(attr_section(arr.attrs))\n\n    return _obj_repr(arr, header_components, sections)\n\n\ndef dataset_repr(ds):\n    obj_type = f\"xarray.{type(ds).__name__}\"\n\n    header_components = [f\"<div class='xr-obj-type'>{escape(obj_type)}</div>\"]\n\n    sections = [\n        dim_section(ds),\n        coord_section(ds.coords),\n        datavar_section(ds.data_vars),\n        index_section(_get_indexes_dict(ds.xindexes)),\n        attr_section(ds.attrs),\n    ]\n\n    return _obj_repr(ds, header_components, sections)",
                        "filename": "xarray/core/formatting_html.py",
                        "start_index": 7729,
                        "end_index": 10213,
                        "start_line": 254,
                        "end_line": 342,
                        "max_line": 342,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__2022.03",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains the implementation of the HTML representation for xarray objects, which is relevant to the performance issue with the HTML repr of multi-indexed data arrays."
                }
            ],
            "xarray/core/formatting.py": [
                {
                    "chunk": {
                        "code": "cursive_repr(\"<recursive array>\")\ndef array_repr(arr):\n    from xarray.core.variable import Variable\n\n    max_rows = OPTIONS[\"display_max_rows\"]\n\n    # used for DataArray, Variable and IndexVariable\n    if hasattr(arr, \"name\") and arr.name is not None:\n        name_str = f\"{arr.name!r} \"\n    else:\n        name_str = \"\"\n\n    if (\n        isinstance(arr, Variable)\n        or _get_boolean_with_default(\"display_expand_data\", default=True)\n        or isinstance(arr.variable._data, MemoryCachedArray)\n    ):\n        data_repr = short_data_repr(arr)\n    else:\n        data_repr = inline_variable_array_repr(arr.variable, OPTIONS[\"display_width\"])\n\n    start = f\"<xarray.{type(arr).__name__} {name_str}\"\n    dims = dim_summary_limited(arr, col_width=len(start) + 1, max_rows=max_rows)\n    summary = [\n        f\"{start}({dims})>\",\n        data_repr,\n    ]\n\n    if hasattr(arr, \"coords\"):\n        if arr.coords:\n            col_width = _calculate_col_width(arr.coords)\n            summary.append(\n                coords_repr(arr.coords, col_width=col_width, max_rows=max_rows)\n            )\n\n        unindexed_dims_str = unindexed_dims_repr(\n            arr.dims, arr.coords, max_rows=max_rows\n        )\n        if unindexed_dims_str:\n            summary.append(unindexed_dims_str)\n\n        display_default_indexes = _get_boolean_with_default(\n            \"display_default_indexes\", False\n        )\n\n        xindexes = filter_nondefault_indexes(\n            _get_indexes_dict(arr.xindexes), not display_default_indexes\n        )\n\n        if xindexes:\n            summary.append(indexes_repr(xindexes, max_rows=max_rows))\n\n    if arr.attrs:\n        summary.append(attrs_repr(arr.attrs, max_rows=max_rows))\n\n    return \"\\n\".join(summary)\n\n\n@recursive_repr(\"<recursive Dataset>\")\ndef dataset_repr(ds):\n    summary = [f\"<xarray.{type(ds).__name__}>\"]\n\n    col_width = _calculate_col_width(ds.variables)\n    max_rows = OPTIONS[\"display_max_rows\"]\n\n    dims_start = pretty_print(\"Dimensions:\", col_width)\n    dims_values = dim_summary_limited(ds, col_width=col_width + 1, max_rows=max_rows)\n    summary.append(f\"{dims_start}({dims_values})\")\n\n    if ds.coords:\n        summary.append(coords_repr(ds.coords, col_width=col_width, max_rows=max_rows))\n\n    unindexed_dims_str = unindexed_dims_repr(ds.dims, ds.coords, max_rows=max_rows)\n    if unindexed_dims_str:\n        summary.append(unindexed_dims_str)\n\n    summary.append(data_vars_repr(ds.data_vars, col_width=col_width, max_rows=max_rows))\n\n    display_default_indexes = _get_boolean_with_default(\n        \"display_default_indexes\", False\n    )\n    xindexes = filter_nondefault_indexes(\n        _get_indexes_dict(ds.xindexes), not display_default_indexes\n    )\n    if xindexes:\n        summary.append(indexes_repr(xindexes, max_rows=max_rows))\n\n    if ds.attrs:\n        summary.append(attrs_repr(ds.attrs, max_rows=max_rows))\n\n    return \"\\n\".join(summary)\n\n\ndef",
                        "filename": "xarray/core/formatting.py",
                        "start_index": 20303,
                        "end_index": 23207,
                        "start_line": 626,
                        "end_line": 877,
                        "max_line": 893,
                        "git_instance": "github",
                        "repo_name": "testbed/pydata__xarray__2022.03",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet includes the plain text representation functions for xarray objects, which might be relevant for comparison or as a fallback to the HTML repr, and could be useful for understanding the overall repr system."
                }
            ]
        },
        "solution_task": "- Review the `array_repr` function in `xarray/core/formatting_html.py` to identify any inefficient operations when handling large multi-indexed data arrays.\n- Optimize the generation of the HTML representation by minimizing the amount of data processed or displayed. For example, limit the number of displayed index entries or summary details for large datasets.\n- Consider adding a check for the size of the data array and adjust the level of detail in the HTML representation accordingly.\n- Implement pagination or a toggle for expanding/collapsing sections of the HTML representation to avoid rendering all details at once for large datasets.\n- If the issue persists, profile the `_repr_html_` method to identify specific bottlenecks and optimize those parts of the code.",
        "bouncer_response": {
            "score": 7,
            "criteria": "RESPONSES that are highly relevant, offering clear and comprehensive guidance or solutions for the described bug, should score between 7 and 9.",
            "supporting_evidence": "The RESPONSE provides a series of actionable steps that are relevant to addressing the performance issue with the HTML representation of large multi-indexed data arrays in xarray. It suggests reviewing and optimizing the `array_repr` function, adding checks for data size, and implementing UI features like pagination or expand/collapse toggles to manage the display of large datasets. These are practical suggestions that could lead to resolving the performance issue. Additionally, the RESPONSE provides links to specific code snippets that could contain the inefficient operations, which is helpful for the debugging process. However, the RESPONSE does not provide specific code changes or detailed optimization strategies, which would be necessary to fully resolve the issue, hence it does not score a 10.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711752518.9670122,
        "result": "- Review the `array_repr` function in `xarray/core/formatting_html.py` to identify any inefficient operations when handling large multi-indexed data arrays.\n- Optimize the generation of the HTML representation by minimizing the amount of data processed or displayed. For example, limit the number of displayed index entries or summary details for large datasets.\n- Consider adding a check for the size of the data array and adjust the level of detail in the HTML representation accordingly.\n- Implement pagination or a toggle for expanding/collapsing sections of the HTML representation to avoid rendering all details at once for large datasets.\n- If the issue persists, profile the `_repr_html_` method to identify specific bottlenecks and optimize those parts of the code.\n\n### Code snippets to check\n\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray) \u2192 [core](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray/core)- [Lines 254 - 342](https://github.com/testbed/pydata__xarray__2022.03/blob//xarray/core/formatting_html.py#L254-L342)\n\n This snippet contains the implementation of the HTML representation for xarray objects, which is relevant to the performance issue with the HTML repr of multi-indexed data arrays.\n-  \u2192 [xarray](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray) \u2192 [core](https://github.com/testbed/pydata__xarray__2022.03/tree//xarray/core)- [Lines 626 - 877](https://github.com/testbed/pydata__xarray__2022.03/blob//xarray/core/formatting.py#L626-L877)\n\n This snippet includes the plain text representation functions for xarray objects, which might be relevant for comparison or as a fallback to the HTML repr, and could be useful for understanding the overall repr system."
    }
}