{
    "id": "scikit-learn__scikit-learn-13828",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
    "task_id": 2486735914373754341,
    "title": "sklearn.cluster.AffinityPropagation doesn't support sparse affinity matrix",
    "body": "<!--\r\nIf your issue is a usage question, submit it here instead:\r\n- StackOverflow with the scikit-learn tag: https://stackoverflow.com/questions/tagged/scikit-learn\r\n- Mailing List: https://mail.python.org/mailman/listinfo/scikit-learn\r\nFor more information, see User Questions: http://scikit-learn.org/stable/support.html#user-questions\r\n-->\r\n\r\n<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\r\n\r\n#### Description\r\nsklearn.cluster.AffinityPropagation doesn't support sparse affinity matrix.\r\n<!-- Example: Joblib Error thrown when calling fit on LatentDirichletAllocation with evaluate_every > 0-->\r\nA similar question is at #4051. It focuses on default affinity.\r\n#### Steps/Code to Reproduce\r\n```python\r\nfrom sklearn.cluster import AffinityPropagation\r\nfrom scipy.sparse import csr\r\naffinity_matrix = csr.csr_matrix((3,3))\r\nAffinityPropagation(affinity='precomputed').fit(affinity_matrix)\r\n```\r\n\r\n\r\n#### Expected Results\r\nno error raised since it works for dense matrix.\r\n\r\n#### Actual Results\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Miniconda\\lib\\site-packages\\sklearn\\cluster\\affinity_propagation_.py\", line 381, in fit\r\n    copy=self.copy, verbose=self.verbose, return_n_iter=True)\r\n  File \"D:\\Miniconda\\lib\\site-packages\\sklearn\\cluster\\affinity_propagation_.py\", line 115, in affinity_propagation\r\n    preference = np.median(S)\r\n  File \"D:\\Miniconda\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 3336, in median\r\n    overwrite_input=overwrite_input)\r\n  File \"D:\\Miniconda\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 3250, in _ureduce\r\n    r = func(a, **kwargs)\r\n  File \"D:\\Miniconda\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 3395, in _median\r\n    return mean(part[indexer], axis=axis, out=out)\r\n  File \"D:\\Miniconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 2920, in mean\r\n    out=out, **kwargs)\r\n  File \"D:\\Miniconda\\lib\\site-packages\\numpy\\core\\_methods.py\", line 85, in _mean\r\n    ret = ret.dtype.type(ret / rcount)\r\nValueError: setting an array element with a sequence.\r\n\r\n#### Versions\r\nSystem:\r\n    python: 3.6.7 |Anaconda, Inc.| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)]\r\nexecutable: D:\\Miniconda\\python.exe\r\n   machine: Windows-7-6.1.7601-SP1\r\n\r\nBLAS:\r\n    macros: SCIPY_MKL_H=None, HAVE_CBLAS=None\r\n  lib_dirs: D:/Miniconda\\Library\\lib\r\ncblas_libs: mkl_rt\r\n\r\nPython deps:\r\n       pip: 18.1\r\nsetuptools: 40.6.2\r\n   sklearn: 0.20.1\r\n     numpy: 1.15.4\r\n     scipy: 1.1.0\r\n    Cython: None\r\n    pandas: 0.23.4\r\n\r\n\r\n<!-- Thanks for contributing! -->\r\n\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.22.git",
    "requested_commit": "",
    "mayil_response": "- Ensure that `AffinityPropagation` can handle sparse matrices when `affinity='precomputed'`. Modify the `fit` method to accept sparse matrices.\n- Check if `affinity_matrix` is a sparse matrix using `scipy.sparse.issparse(affinity_matrix)` before computing the median.\n- If `affinity_matrix` is sparse, convert it to a dense array using `affinity_matrix.toarray()` before calculating the median with `np.median(S)`.\n- Alternatively, if the median calculation is not essential for sparse matrices, consider skipping it or finding an alternative that works with sparse data.\n- Add tests to verify that `AffinityPropagation` works correctly with both dense and sparse precomputed affinity matrices.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn) \u2192 [cluster](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn/cluster)- [Lines 1 - 33](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/cluster/_affinity_propagation.py#L1-L33)\n\n This snippet is from the file '_affinity_propagation.py' which is directly related to the AffinityPropagation class that the issue is about. It may contain the implementation details that need to be modified to support sparse affinity matrices.\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn/utils)- [Lines 534 - 581](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/validation.py#L534-L581)\n\n This snippet from 'validation.py' includes checks for sparse matrix handling and may be relevant for understanding how sparse matrices are currently validated and processed within scikit-learn, which is necessary for solving the issue. \n\n\n   - [Lines 1001 - 2214](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/validation.py#L1001-L2214)\n\n This snippet contains a function that checks for large sparse matrices and may be relevant to the issue if the problem is related to the handling of 64-bit indices in sparse matrices. \n\n\n   - [Lines 460 - 2272](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/validation.py#L460-L2272)\n\n This snippet defines a function that ensures the sparse format of matrices, which could be relevant to the issue if modifications are needed to support sparse affinity matrices in AffinityPropagation.",
    "ai_cost": {
        "search_embedding": 1.3e-07,
        "issue_classifier": 0.0005394999999999999,
        "snippet_processor": 0.08021,
        "issue_star_creation": 0.03338,
        "issue_star_solver": 0.08541,
        "bouncer": 0.023790000000000002
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711739736.9231381,
        "relevant_snippets": [
            {
                "code": "if accept_sparse is False:\n        raise TypeError(\n            \"A sparse matrix was passed, but dense \"\n            \"data is required. Use X.toarray() to \"\n            \"convert to a dense numpy array.\"\n        )\n    elif isinstance(accept_sparse, (list, tuple)):\n        if len(accept_sparse) == 0:\n            raise ValueError(\n                \"When providing 'accept_sparse' \"\n                \"as a tuple or list, it must contain at \"\n                \"least one string value.\"\n            )\n        # ensure correct sparse format\n        if spmatrix.format not in accept_sparse:\n            # create new with correct sparse\n            spmatrix = spmatrix.asformat(accept_sparse[0])\n            changed_format = True\n    elif accept_sparse is not True:\n        # any other type\n        raise ValueError(\n            \"Parameter 'accept_sparse' should be a string, \"\n            \"boolean or list of strings. You provided \"\n            \"'accept_sparse={}'.\".format(accept_sparse)\n        )\n\n    if dtype != spmatrix.dtype:\n        # convert dtype\n        spmatrix = spmatrix.astype(dtype)\n    elif copy and not changed_format:\n        # force copy\n        spmatrix = spmatrix.copy()\n\n    if force_all_finite:\n        if not hasattr(spmatrix, \"data\"):\n            warnings.warn(\n                \"Can't check %s sparse matrix for nan or inf.\" % spmatrix.format,\n                stacklevel=2,\n            )\n        else:\n            _assert_all_finite(\n                spmatrix.data,\n                allow_nan=force_all_finite == \"allow-nan\",\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n\n    return spmatrix",
                "filename": "sklearn/utils/validation.py",
                "start_index": 17856,
                "end_index": 19516,
                "start_line": 534,
                "end_line": 581,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "def check_array_api_input_and_values(\n    name,\n    estimator_orig,\n    array_namespace,\n    device=None,\n    dtype=\"float64\",\n):\n    return check_array_api_input(\n        name,\n        estimator_orig,\n        array_namespace=array_namespace,\n        device=device,\n        dtype=dtype,\n        check_values=True,\n    )\n\n\ndef check_estimator_sparse_data(name, estimator_orig):\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(40, 3))\n    X[X < 0.8] = 0\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    X_csr = sparse.csr_matrix(X)\n    y = (4 * rng.uniform(size=40)).astype(int)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n    tags = _safe_tags(estimator_orig)\n    for matrix_format, X in _generate_sparse_matrix(X_csr):\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n            if name in [\"Scaler\", \"StandardScaler\"]:\n                estimator.set_params(with_mean=False)\n        # fit and predict\n        if \"64\" in matrix_format:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to support {matrix_format} \"\n                \"matrix, and is not failing gracefully, e.g. by using \"\n                \"check_array(X, accept_large_sparse=False)\"\n            )\n        else:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to fail gracefully on sparse \"\n                \"data: error message should state explicitly that sparse \"\n                \"input is not supported if this is not the case.\"\n            )\n        with raises(\n            (TypeError, ValueError),\n            match=[\"sparse\", \"Sparse\"],\n            may_pass=True,\n            err_msg=err_msg,\n        ):\n            with ignore_warnings(category=FutureWarning):\n                estimator.fit(X, y)\n            if hasattr(estimator, \"predict\"):\n                pred = estimator.predict(X)\n                if tags[\"multioutput_only\"]:\n                    assert pred.shape == (X.shape[0], 1)\n                else:\n                    assert pred.shape == (X.shape[0],)\n            if hasattr(estimator, \"predict_proba\"):\n                probs = estimator.predict_proba(X)\n                if tags[\"binary_only\"]:\n                    expected_probs_shape = (X.shape[0], 2)\n                else:\n                    expected_probs_shape = (X.shape[0], 4)\n                assert probs.shape == expected_probs_shape",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 36016,
                "end_index": 38577,
                "start_line": 1025,
                "end_line": 1093,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "def _ensure_sparse_format(\n    spmatrix,\n    accept_sparse,\n    dtype,\n    copy,\n    force_all_finite,\n    accept_large_sparse,\n    estimator_name=None,\n    input_name=\"\",\n):",
                "filename": "sklearn/utils/validation.py",
                "start_index": 15534,
                "end_index": 15708,
                "start_line": 460,
                "end_line": 2272,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "assert array(\"i\").itemsize == 4, (\n            \"sizeof(int) != 4 on your platform; please report this at\"\n            \" https://github.com/scikit-learn/scikit-learn/issues and\"\n            \" include the output from platform.platform() in your bug report\"\n        )\n\n        dtype = self.dtype\n        if fitting:\n            feature_names = []\n            vocab = {}\n        else:\n            feature_names = self.feature_names_\n            vocab = self.vocabulary_\n\n        transforming = True\n\n        # Process everything as sparse regardless of setting\n        X = [X] if isinstance(X, Mapping) else X\n\n        indices = array(\"i\")\n        indptr = [0]\n        # XXX we could change values to an array.array as well, but it\n        # would require (heuristic) conversion of dtype to typecode...\n        values = []\n\n        # collect all the possible feature names and build sparse matrix at\n        # same time\n        for x in X:\n            for f, v in x.items():\n                if isinstance(v, str):\n                    feature_name = \"%s%s%s\" % (f, self.separator, v)\n                    v = 1\n                elif isinstance(v, Number) or (v is None):\n                    feature_name = f\n                elif not isinstance(v, Mapping) and isinstance(v, Iterable):\n                    feature_name = None\n                    self._add_iterable_element(\n                        f,\n                        v,\n                        feature_names,\n                        vocab,\n                        fitting=fitting,\n                        transforming=transforming,\n                        indices=indices,\n                        values=values,\n                    )\n                else:\n                    raise TypeError(\n                        f\"Unsupported value Type {type(v)} \"\n                        f\"for {f}: {v}.\\n\"\n                        f\"{type(v)} objects are not supported.\"\n                    )\n\n                if feature_name is not None:\n                    if fitting and feature_name not in vocab:\n                        vocab[feature_name] = len(feature_names)\n                        feature_names.append(feature_name)\n\n                    if feature_name in vocab:\n                        indices.append(vocab[feature_name])\n                        values.append(self.dtype(v))\n\n            indptr.append(len(indices))\n\n        if len(indptr) == 1:\n            raise ValueError(\"Sample sequence X is empty.\")\n\n        indices = np.frombuffer(indices, dtype=np.intc)\n        shape = (len(indptr) - 1, len(vocab))\n\n        result_matrix = sp.csr_matrix(\n            (values, indices, indptr), shape=shape, dtype=dtype\n        )\n\n        # Sort everything if asked",
                "filename": "sklearn/feature_extraction/_dict_vectorizer.py",
                "start_index": 6855,
                "end_index": 9563,
                "start_line": 195,
                "end_line": 269,
                "max_line": 444,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "# Authors: Manoj Kumar <manojkumarsivaraj334@gmail.com>\n#          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#          Joel Nothman <joel.nothman@gmail.com>\n# License: BSD 3 clause\n\nimport warnings\nfrom math import sqrt\nfrom numbers import Integral, Real\n\nimport numpy as np\nfrom scipy import sparse\n\nfrom .._config import config_context\nfrom ..base import (\n    BaseEstimator,\n    ClassNamePrefixFeaturesOutMixin,\n    ClusterMixin,\n    TransformerMixin,\n    _fit_context,\n)\nfrom ..exceptions import ConvergenceWarning\nfrom ..metrics import pairwise_distances_argmin\nfrom ..metrics.pairwise import euclidean_distances\nfrom ..utils._param_validation import Interval\nfrom ..utils.extmath import row_norms\nfrom ..utils.validation import check_is_fitted\nfrom . import AgglomerativeClustering\n\n\ndef _iterate_sparse_X(X):\n    \"\"\"This little hack returns a densified row when iterating over a sparse\n    matrix, instead of constructing a sparse matrix for every row that is\n    expensive.\n    \"\"\"\n    n_samples = X.shape[0]\n    X_indices = X.indices\n    X_data = X.data\n    X_indptr = X.indptr\n\n    for i in range(n_samples):\n        row = np.zeros(X.shape[1])\n        startptr, endptr = X_indptr[i], X_indptr[i + 1]\n        nonzero_indices = X_indices[startptr:endptr]\n        row[nonzero_indices] = X_data[startptr:endptr]\n        yield row",
                "filename": "sklearn/cluster/_birch.py",
                "start_index": 0,
                "end_index": 1355,
                "start_line": 1,
                "end_line": 45,
                "max_line": 741,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "@validate_params(\n    {\"affinity\": [\"array-like\", \"sparse matrix\"]},\n    prefer_skip_nested_validation=False,\n)",
                "filename": "sklearn/cluster/_spectral.py",
                "start_index": 6771,
                "end_index": 6882,
                "start_line": 192,
                "end_line": 780,
                "max_line": 786,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "def _check_large_sparse(X, accept_large_sparse=False):\n    \"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\n    if not accept_large_sparse:\n        supported_indices = [\"int32\"]\n        if X.getformat() == \"coo\":\n            index_keys = [\"col\", \"row\"]\n        elif X.getformat() in [\"csr\", \"csc\", \"bsr\"]:\n            index_keys = [\"indices\", \"indptr\"]\n        else:\n            return\n        for key in index_keys:\n            indices_datatype = getattr(X, key).dtype\n            if indices_datatype not in supported_indices:\n                raise ValueError(\n                    \"Only sparse matrices with 32-bit integer indices are accepted.\"\n                    f\" Got {indices_datatype} indices. Please do report a minimal\"\n                    \" reproducer on scikit-learn issue tracker so that support for\"\n                    \" your use-case can be studied by maintainers. See:\"\n                    \" https://scikit-learn.org/dev/developers/minimal_reproducer.html\"\n                )",
                "filename": "sklearn/utils/validation.py",
                "start_index": 35996,
                "end_index": 37016,
                "start_line": 1001,
                "end_line": 2214,
                "max_line": 2282,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "\"\"\"Affinity Propagation clustering algorithm.\"\"\"\n\n# Author: Alexandre Gramfort alexandre.gramfort@inria.fr\n#        Gael Varoquaux gael.varoquaux@normalesup.org\n\n# License: BSD 3 clause\n\nimport warnings\nfrom numbers import Integral, Real\n\nimport numpy as np\n\nfrom .._config import config_context\nfrom ..base import BaseEstimator, ClusterMixin, _fit_context\nfrom ..exceptions import ConvergenceWarning\nfrom ..metrics import euclidean_distances, pairwise_distances_argmin\nfrom ..utils import check_random_state\nfrom ..utils._param_validation import Interval, StrOptions, validate_params\nfrom ..utils.validation import check_is_fitted\n\n\ndef _equal_similarities_and_preferences(S, preference):\n    def all_equal_preferences():\n        return np.all(preference == preference.flat[0])\n\n    def all_equal_similarities():\n        # Create mask to ignore diagonal of S\n        mask = np.ones(S.shape, dtype=bool)\n        np.fill_diagonal(mask, 0)\n\n        return np.all(S[mask].flat == S[mask].flat[0])\n\n    return all_equal_preferences() and all_equal_similarities()",
                "filename": "sklearn/cluster/_affinity_propagation.py",
                "start_index": 0,
                "end_index": 1058,
                "start_line": 1,
                "end_line": 33,
                "max_line": 590,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "\"\"\"\n=================================================\nDemo of affinity propagation clustering algorithm\n=================================================\n\nReference:\nBrendan J. Frey and Delbert Dueck, \"Clustering by Passing Messages\nBetween Data Points\", Science Feb. 2007\n\n\"\"\"\nimport numpy as np\n\nfrom sklearn import metrics\nfrom sklearn.cluster import AffinityPropagation\nfrom sklearn.datasets import make_blobs\n\n# %%\n# Generate sample data\n# --------------------\ncenters = [[1, 1], [-1, -1], [1, -1]]\nX, labels_true = make_blobs(\n    n_samples=300, centers=centers, cluster_std=0.5, random_state=0\n)\n\n# %%\n# Compute Affinity Propagation\n# ----------------------------\naf = AffinityPropagation(preference=-50, random_state=0).fit(X)\ncluster_centers_indices = af.cluster_centers_indices_\nlabels = af.labels_\n\nn_clusters_ = len(cluster_centers_indices)\n\nprint(\"Estimated number of clusters: %d\" % n_clusters_)\nprint(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\nprint(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\nprint(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\nprint(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\nprint(\n    \"Adjusted Mutual Information: %0.3f\"\n    % metrics.adjusted_mutual_info_score(labels_true, labels)\n)\nprint(\n    \"Silhouette Coefficient: %0.3f\"\n    % metrics.silhouette_score(X, labels, metric=\"sqeuclidean\")\n)\n\n# %%\n# Plot result\n# -----------\nimport matplotlib.pyplot as plt\n\nplt.close(\"all\")\nplt.figure(1)\nplt.clf()\n\ncolors = plt.cycler(\"color\", plt.cm.viridis(np.linspace(0, 1, 4)))\n\nfor k, col in zip(range(n_clusters_), colors):\n    class_members = labels == k\n    cluster_center = X[cluster_centers_indices[k]]\n    plt.scatter(\n        X[class_members, 0], X[class_members, 1], color=col[\"color\"], marker=\".\"\n    )\n    plt.scatter(\n        cluster_center[0], cluster_center[1], s=14, color=col[\"color\"], marker=\"o\"\n    )\n    for x in X[class_members]:\n        plt.plot(\n            [cluster_center[0], x[0]], [cluster_center[1], x[1]], color=col[\"color\"]\n        )\n\nplt.title(\"Estimated number of clusters: %d\" % n_clusters_)\nplt.show()",
                "filename": "examples/cluster/plot_affinity_propagation.py",
                "start_index": 0,
                "end_index": 2179,
                "start_line": 1,
                "end_line": 74,
                "max_line": 74,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            },
            {
                "code": "\"\"\"\n==============================\nLasso on dense and sparse data\n==============================\n\nWe show that linear_model.Lasso provides the same results for dense and sparse\ndata and that in the case of sparse data the speed is improved.\n\n\"\"\"\n\nfrom time import time\n\nfrom scipy import linalg, sparse\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import Lasso\n\n# %%\n# Comparing the two Lasso implementations on Dense data\n# -----------------------------------------------------\n#\n# We create a linear regression problem that is suitable for the Lasso,\n# that is to say, with more features than samples. We then store the data\n# matrix in both dense (the usual) and sparse format, and train a Lasso on\n# each. We compute the runtime of both and check that they learned the\n# same model by computing the Euclidean norm of the difference between the\n# coefficients they learned. Because the data is dense, we expect better\n# runtime with a dense data format.\n\nX, y = make_regression(n_samples=200, n_features=5000, random_state=0)\n# create a copy of X in sparse format\nX_sp = sparse.coo_matrix(X)\n\nalpha = 1\nsparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)\ndense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)\n\nt0 = time()\nsparse_lasso.fit(X_sp, y)\nprint(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n\nt0 = time()\ndense_lasso.fit(X, y)\nprint(f\"Dense Lasso done in {(time() - t0):.3f}s\")\n\n# compare the regression coefficients\ncoeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\nprint(f\"Distance between coefficients : {coeff_diff:.2e}\")\n\n#\n# %%\n# Comparing the two Lasso implementations on Sparse data\n# ------------------------------------------------------\n#\n# We make the previous problem sparse by replacing all small values with 0\n# and run the same comparisons as above. Because the data is now sparse, we\n# expect the implementation that uses the sparse data format to be faster.\n\n# make a copy of the previous data\nXs = X.copy()\n# make Xs sparse by replacing the values lower than 2.5 with 0s\nXs[Xs < 2.5] = 0.0\n# create a copy of Xs in sparse format\nXs_sp = sparse.coo_matrix(Xs)\nXs_sp = Xs_sp.tocsc()\n\n# compute the proportion of non-zero coefficient in the data matrix\nprint(f\"Matrix density : {(Xs_sp.nnz / float(X.size) * 100):.3f}%\")\n\nalpha = 0.1\nsparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\ndense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n\nt0 = time()\nsparse_lasso.fit(Xs_sp, y)\nprint(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n\nt0 = time()\ndense_lasso.fit(Xs, y)\nprint(f\"Dense Lasso done in  {(time() - t0):.3f}s\")\n\n# compare the regression coefficients\ncoeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\nprint(f\"Distance between coefficients : {coeff_diff:.2e}\")\n\n# %%",
                "filename": "examples/linear_model/plot_lasso_dense_vs_sparse_data.py",
                "start_index": 0,
                "end_index": 2825,
                "start_line": 1,
                "end_line": 86,
                "max_line": 86,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                "sha": ""
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sklearn/cluster/_affinity_propagation.py": [
                {
                    "chunk": {
                        "code": "\"\"\"Affinity Propagation clustering algorithm.\"\"\"\n\n# Author: Alexandre Gramfort alexandre.gramfort@inria.fr\n#        Gael Varoquaux gael.varoquaux@normalesup.org\n\n# License: BSD 3 clause\n\nimport warnings\nfrom numbers import Integral, Real\n\nimport numpy as np\n\nfrom .._config import config_context\nfrom ..base import BaseEstimator, ClusterMixin, _fit_context\nfrom ..exceptions import ConvergenceWarning\nfrom ..metrics import euclidean_distances, pairwise_distances_argmin\nfrom ..utils import check_random_state\nfrom ..utils._param_validation import Interval, StrOptions, validate_params\nfrom ..utils.validation import check_is_fitted\n\n\ndef _equal_similarities_and_preferences(S, preference):\n    def all_equal_preferences():\n        return np.all(preference == preference.flat[0])\n\n    def all_equal_similarities():\n        # Create mask to ignore diagonal of S\n        mask = np.ones(S.shape, dtype=bool)\n        np.fill_diagonal(mask, 0)\n\n        return np.all(S[mask].flat == S[mask].flat[0])\n\n    return all_equal_preferences() and all_equal_similarities()",
                        "filename": "sklearn/cluster/_affinity_propagation.py",
                        "start_index": 0,
                        "end_index": 1058,
                        "start_line": 1,
                        "end_line": 33,
                        "max_line": 590,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet is from the file '_affinity_propagation.py' which is directly related to the AffinityPropagation class that the issue is about. It may contain the implementation details that need to be modified to support sparse affinity matrices."
                }
            ],
            "sklearn/utils/validation.py": [
                {
                    "chunk": {
                        "code": "if accept_sparse is False:\n        raise TypeError(\n            \"A sparse matrix was passed, but dense \"\n            \"data is required. Use X.toarray() to \"\n            \"convert to a dense numpy array.\"\n        )\n    elif isinstance(accept_sparse, (list, tuple)):\n        if len(accept_sparse) == 0:\n            raise ValueError(\n                \"When providing 'accept_sparse' \"\n                \"as a tuple or list, it must contain at \"\n                \"least one string value.\"\n            )\n        # ensure correct sparse format\n        if spmatrix.format not in accept_sparse:\n            # create new with correct sparse\n            spmatrix = spmatrix.asformat(accept_sparse[0])\n            changed_format = True\n    elif accept_sparse is not True:\n        # any other type\n        raise ValueError(\n            \"Parameter 'accept_sparse' should be a string, \"\n            \"boolean or list of strings. You provided \"\n            \"'accept_sparse={}'.\".format(accept_sparse)\n        )\n\n    if dtype != spmatrix.dtype:\n        # convert dtype\n        spmatrix = spmatrix.astype(dtype)\n    elif copy and not changed_format:\n        # force copy\n        spmatrix = spmatrix.copy()\n\n    if force_all_finite:\n        if not hasattr(spmatrix, \"data\"):\n            warnings.warn(\n                \"Can't check %s sparse matrix for nan or inf.\" % spmatrix.format,\n                stacklevel=2,\n            )\n        else:\n            _assert_all_finite(\n                spmatrix.data,\n                allow_nan=force_all_finite == \"allow-nan\",\n                estimator_name=estimator_name,\n                input_name=input_name,\n            )\n\n    return spmatrix",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 17856,
                        "end_index": 19516,
                        "start_line": 534,
                        "end_line": 581,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet from 'validation.py' includes checks for sparse matrix handling and may be relevant for understanding how sparse matrices are currently validated and processed within scikit-learn, which is necessary for solving the issue."
                },
                {
                    "chunk": {
                        "code": "def _check_large_sparse(X, accept_large_sparse=False):\n    \"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\n    if not accept_large_sparse:\n        supported_indices = [\"int32\"]\n        if X.getformat() == \"coo\":\n            index_keys = [\"col\", \"row\"]\n        elif X.getformat() in [\"csr\", \"csc\", \"bsr\"]:\n            index_keys = [\"indices\", \"indptr\"]\n        else:\n            return\n        for key in index_keys:\n            indices_datatype = getattr(X, key).dtype\n            if indices_datatype not in supported_indices:\n                raise ValueError(\n                    \"Only sparse matrices with 32-bit integer indices are accepted.\"\n                    f\" Got {indices_datatype} indices. Please do report a minimal\"\n                    \" reproducer on scikit-learn issue tracker so that support for\"\n                    \" your use-case can be studied by maintainers. See:\"\n                    \" https://scikit-learn.org/dev/developers/minimal_reproducer.html\"\n                )",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 35996,
                        "end_index": 37016,
                        "start_line": 1001,
                        "end_line": 2214,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet contains a function that checks for large sparse matrices and may be relevant to the issue if the problem is related to the handling of 64-bit indices in sparse matrices."
                },
                {
                    "chunk": {
                        "code": "def _ensure_sparse_format(\n    spmatrix,\n    accept_sparse,\n    dtype,\n    copy,\n    force_all_finite,\n    accept_large_sparse,\n    estimator_name=None,\n    input_name=\"\",\n):",
                        "filename": "sklearn/utils/validation.py",
                        "start_index": 15534,
                        "end_index": 15708,
                        "start_line": 460,
                        "end_line": 2272,
                        "max_line": 2282,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.22",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet defines a function that ensures the sparse format of matrices, which could be relevant to the issue if modifications are needed to support sparse affinity matrices in AffinityPropagation."
                }
            ]
        },
        "solution_task": "- Ensure that `AffinityPropagation` can handle sparse matrices when `affinity='precomputed'`. Modify the `fit` method to accept sparse matrices.\n- Check if `affinity_matrix` is a sparse matrix using `scipy.sparse.issparse(affinity_matrix)` before computing the median.\n- If `affinity_matrix` is sparse, convert it to a dense array using `affinity_matrix.toarray()` before calculating the median with `np.median(S)`.\n- Alternatively, if the median calculation is not essential for sparse matrices, consider skipping it or finding an alternative that works with sparse data.\n- Add tests to verify that `AffinityPropagation` works correctly with both dense and sparse precomputed affinity matrices.",
        "bouncer_response": {
            "score": 7,
            "criteria": "RESPONSES that are highly relevant, offering clear and comprehensive guidance or solutions for the described bug, should score between 7 and 9.",
            "supporting_evidence": "The RESPONSE provides a series of actionable steps to address the issue of sklearn.cluster.AffinityPropagation not supporting sparse affinity matrices. It suggests modifying the 'fit' method to accept sparse matrices, checking if the matrix is sparse, converting it to a dense array if necessary, and considering alternatives for median calculation with sparse data. Additionally, it recommends adding tests for both dense and sparse matrices. The RESPONSE also provides relevant code snippets from the scikit-learn repository that could contain the necessary implementation details to be modified. This guidance is directly related to the described bug and offers a clear path to potentially resolving it. However, it does not address the entire traceback or the specific error message, which is why it does not score a perfect 10.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711739891.5416992,
        "result": "- Ensure that `AffinityPropagation` can handle sparse matrices when `affinity='precomputed'`. Modify the `fit` method to accept sparse matrices.\n- Check if `affinity_matrix` is a sparse matrix using `scipy.sparse.issparse(affinity_matrix)` before computing the median.\n- If `affinity_matrix` is sparse, convert it to a dense array using `affinity_matrix.toarray()` before calculating the median with `np.median(S)`.\n- Alternatively, if the median calculation is not essential for sparse matrices, consider skipping it or finding an alternative that works with sparse data.\n- Add tests to verify that `AffinityPropagation` works correctly with both dense and sparse precomputed affinity matrices.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn) \u2192 [cluster](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn/cluster)- [Lines 1 - 33](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/cluster/_affinity_propagation.py#L1-L33)\n\n This snippet is from the file '_affinity_propagation.py' which is directly related to the AffinityPropagation class that the issue is about. It may contain the implementation details that need to be modified to support sparse affinity matrices.\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.22/tree//sklearn/utils)- [Lines 534 - 581](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/validation.py#L534-L581)\n\n This snippet from 'validation.py' includes checks for sparse matrix handling and may be relevant for understanding how sparse matrices are currently validated and processed within scikit-learn, which is necessary for solving the issue. \n\n\n   - [Lines 1001 - 2214](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/validation.py#L1001-L2214)\n\n This snippet contains a function that checks for large sparse matrices and may be relevant to the issue if the problem is related to the handling of 64-bit indices in sparse matrices. \n\n\n   - [Lines 460 - 2272](https://github.com/testbed/scikit-learn__scikit-learn__0.22/blob//sklearn/utils/validation.py#L460-L2272)\n\n This snippet defines a function that ensures the sparse format of matrices, which could be relevant to the issue if modifications are needed to support sparse affinity matrices in AffinityPropagation."
    }
}