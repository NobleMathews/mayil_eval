{
    "id": "scikit-learn__scikit-learn-12784",
    "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
    "task_id": 6713967858506602424,
    "title": "KNeighborsRegressor gives different results for different n_jobs values",
    "body": "<!--\r\nIf your issue is a usage question, submit it here instead:\r\n- StackOverflow with the scikit-learn tag: https://stackoverflow.com/questions/tagged/scikit-learn\r\n- Mailing List: https://mail.python.org/mailman/listinfo/scikit-learn\r\nFor more information, see User Questions: http://scikit-learn.org/stable/support.html#user-questions\r\n-->\r\n\r\n<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\r\n\r\n#### Description\r\n<!-- Example: Joblib Error thrown when calling fit on LatentDirichletAllocation with evaluate_every > 0-->\r\nWhen using 'seuclidean' distance metric, the algorithm produces different predictions for different values of the n_jobs parameter if no V is passed as additional metric_params. This implies that if configured with n_jobs=-1 two different machines show different results depending on the number of cores. The same happens for 'mahalanobis' distance metric if no V and VI are passed as metric_params.\r\n\r\n#### Steps/Code to Reproduce\r\n<!--\r\nExample:\r\n```python\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\nfrom sklearn.decomposition import LatentDirichletAllocation\r\n\r\ndocs = [\"Help I have a bug\" for i in range(1000)]\r\n\r\nvectorizer = CountVectorizer(input=docs, analyzer='word')\r\nlda_features = vectorizer.fit_transform(docs)\r\n\r\nlda_model = LatentDirichletAllocation(\r\n    n_topics=10,\r\n    learning_method='online',\r\n    evaluate_every=10,\r\n    n_jobs=4,\r\n)\r\nmodel = lda_model.fit(lda_features)\r\n```\r\nIf the code is too long, feel free to put it in a public gist and link\r\nit in the issue: https://gist.github.com\r\n-->\r\n```python\r\n# Import required packages\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom sklearn.datasets import load_boston\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.neighbors import KNeighborsRegressor\r\n\r\n# Prepare the dataset\r\ndataset = load_boston()\r\ntarget = dataset.target\r\ndata = pd.DataFrame(dataset.data, columns=dataset.feature_names)\r\n\r\n# Split the dataset\r\nnp.random.seed(42)\r\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\r\n\r\n# Create a regressor with seuclidean distance and passing V as additional argument\r\nmodel_n_jobs_1 = KNeighborsRegressor(n_jobs=1, algorithm='brute', metric='seuclidean')\r\nmodel_n_jobs_1.fit(X_train, y_train)\r\nnp.sum(model_n_jobs_1.predict(X_test)) # --> 2127.99999\r\n\r\n# Create a regressor with seuclidean distance and passing V as additional argument\r\nmodel_n_jobs_3 = KNeighborsRegressor(n_jobs=3, algorithm='brute', metric='seuclidean')\r\nmodel_n_jobs_3.fit(X_train, y_train)\r\nnp.sum(model_n_jobs_3.predict(X_test)) # --> 2129.38\r\n\r\n# Create a regressor with seuclidean distance and passing V as additional argument\r\nmodel_n_jobs_all = KNeighborsRegressor(n_jobs=-1, algorithm='brute', metric='seuclidean')\r\nmodel_n_jobs_all.fit(X_train, y_train)\r\nnp.sum(model_n_jobs_all.predict(X_test)) # --> 2125.29999\r\n```\r\n\r\n#### Expected Results\r\n<!-- Example: No error is thrown. Please paste or describe the expected results.-->\r\nThe prediction should be always the same and not depend on the value passed to the n_jobs parameter.\r\n\r\n#### Actual Results\r\n<!-- Please paste or specifically describe the actual output or traceback. -->\r\nThe prediction value changes depending on the value passed to n_jobs which, in case of n_jobs=-1, makes the prediction depend on the number of cores of the machine running the code.\r\n\r\n#### Versions\r\n<!--\r\nPlease run the following snippet and paste the output below.\r\nFor scikit-learn >= 0.20:\r\nimport sklearn; sklearn.show_versions()\r\nFor scikit-learn < 0.20:\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport numpy; print(\"NumPy\", numpy.__version__)\r\nimport scipy; print(\"SciPy\", scipy.__version__)\r\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\r\n-->\r\nSystem\r\n------\r\n    python: 3.6.6 (default, Jun 28 2018, 04:42:43)  [GCC 5.4.0 20160609]\r\n    executable: /home/mcorella/.local/share/virtualenvs/outlier_detection-8L4UL10d/bin/python3.6\r\n    machine: Linux-4.15.0-39-generic-x86_64-with-Ubuntu-16.04-xenial\r\n\r\nBLAS\r\n----\r\n    macros: NO_ATLAS_INFO=1, HAVE_CBLAS=None\r\n    lib_dirs: /usr/lib\r\n    cblas_libs: cblas\r\n\r\nPython deps\r\n-----------\r\n    pip: 18.1\r\n    setuptools: 40.5.0\r\n    sklearn: 0.20.0\r\n    numpy: 1.15.4\r\n    scipy: 1.1.0\r\n    Cython: None\r\n    pandas: 0.23.4\r\n\r\n<!-- Thanks for contributing! -->\r\n\nutils.validation.check_array throws bad TypeError pandas series is passed in\n#### Description\r\nvalidation.check_array throws bad TypeError pandas series is passed in. It cropped up when using the RandomizedSearchCV class.  Caused when line 480 is executed\r\n\r\n480 - if hasattr(array, \"dtypes\") and len(array.dtypes):\r\n\r\n#### Steps/Code to Reproduce\r\n\r\nvalidation.check_array(y, ensure_2d=False, dtype=None) where y is a pandas series\r\n\r\n#### Expected Results\r\nNo error (I'm not familiar with this code so not sure on the details)\r\n\r\n#### Actual Results\r\nTypeError: object of type 'DTYPE NAME OF THE SERIES' has no len()\r\n\r\n#### Versions\r\n0.20.1\n",
    "state": "closed",
    "repo_link": "https://github.com/testbed/scikit-learn__scikit-learn__0.20.git",
    "requested_commit": "",
    "mayil_response": "- Ensure that `metric_params` is properly set when using 'seuclidean' or 'mahalanobis' distance metrics with `KNeighborsRegressor`. For 'seuclidean', a value for `V` (variance vector) is required, and for 'mahalanobis', a value for `VI` (inverse of the covariance matrix) is needed. If these parameters are not set, calculate them from the training data and pass them to `metric_params`.\n- When using `RandomizedSearchCV` with `KNeighborsRegressor`, ensure that the `metric_params` is included in the parameter distribution to avoid inconsistent predictions when using different `n_jobs` values.\n- To address the `TypeError` raised by `utils.validation.check_array` when a pandas series is passed in, ensure that input data is converted to a NumPy array before being passed to `KNeighborsRegressor`. Use `np.asarray()` or `pd.Series.values` to convert a pandas series to a NumPy array.\n- If `ensure_2d=False` is causing issues, ensure that input data to `check_array` is two-dimensional. This can be done by reshaping the data if necessary using `np.reshape(-1, 1)` for a single feature or ensuring the input data is already in a 2D shape.\n- If `dtype=None` is causing issues in `check_array`, explicitly set the `dtype` to a numerical type like `np.float64` when calling `check_array` to ensure that the data is checked as a numeric array.\n- Since the issue is observed with scikit-learn version 0.20.0 and 0.20.1, consider upgrading to a newer version of scikit-learn if the issue is known and fixed in later versions.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/utils)- [Lines 181 - 3430](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/estimator_checks.py#L181-L3430)\n\n This snippet includes checks for regressors with non-array data types, which is relevant to the issue of KNeighborsRegressor giving different results for different n_jobs values when using 'seuclidean' distance without passing V as additional metric_params. \n\n\n   - [Lines 181 - 1181](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/estimator_checks.py#L181-L1181)\n\n This snippet checks that estimators accept a 'sample_weight' parameter of type pandas.Series, which is relevant because the issue mentions a problem with handling pandas series in the check_array function.",
    "ai_cost": {
        "search_embedding": 2.6e-07,
        "issue_classifier": 0.005174,
        "snippet_processor": 0.06475,
        "issue_star_creation": 0.04989,
        "issue_star_solver": 0.08403000000000001,
        "bouncer": 0.12060000000000001
    },
    "mayil_collected_data": {
        "status": "completed",
        "start_time": 1711741499.83286,
        "relevant_snippets": [
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_regressor_data_not_an_array(name, estimator_orig):\n    X, y = _regression_dataset()\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n    for obj_type in [\"NotAnArray\", \"PandasDataframe\"]:\n        check_estimators_data_not_an_array(name, estimator_orig, X, y, obj_type)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_estimators_data_not_an_array(name, estimator_orig, X, y, obj_type):\n    if name in CROSS_DECOMPOSITION:\n        raise SkipTest(\n            \"Skipping check_estimators_data_not_an_array \"\n            \"for cross decomposition module as estimators \"\n            \"are not deterministic.\"\n        )\n    # separate estimators to control random seeds\n    estimator_1 = clone(estimator_orig)\n    estimator_2 = clone(estimator_orig)\n    set_random_state(estimator_1)\n    set_random_state(estimator_2)\n\n    if obj_type not in [\"NotAnArray\", \"PandasDataframe\"]:\n        raise ValueError(\"Data type {0} not supported\".format(obj_type))\n\n    if obj_type == \"NotAnArray\":\n        y_ = _NotAnArray(np.asarray(y))\n        X_ = _NotAnArray(np.asarray(X))\n    else:\n        # Here pandas objects (Series and DataFrame) are tested explicitly\n        # because some estimators may handle them (especially their indexing)\n        # specially.\n        try:\n            import pandas as pd\n\n            y_ = np.asarray(y)\n            if y_.ndim == 1:\n                y_ = pd.Series(y_, copy=False)\n            else:\n                y_ = pd.DataFrame(y_, copy=False)\n            X_ = pd.DataFrame(np.asarray(X), copy=False)\n\n        except ImportError:\n            raise SkipTest(\n                \"pandas is not installed: not checking estimators for pandas objects.\"\n            )\n\n    # fit\n    estimator_1.fit(X_, y_)\n    pred1 = estimator_1.predict(X_)\n    estimator_2.fit(X, y)\n    pred2 = estimator_2.predict(X)\n    assert_allclose(pred1, pred2, atol=1e-2, err_msg=name)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 118586,
                "end_index": 120568,
                "start_line": 181,
                "end_line": 3430,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_sample_weights_pandas_series(name, estimator_orig):\n    # check that estimators will accept a 'sample_weight' parameter of\n    # type pandas.Series in the 'fit' function.\n    estimator = clone(estimator_orig)\n    try:\n        import pandas as pd\n\n        X = np.array(\n            [\n                [1, 1],\n                [1, 2],\n                [1, 3],\n                [1, 4],\n                [2, 1],\n                [2, 2],\n                [2, 3],\n                [2, 4],\n                [3, 1],\n                [3, 2],\n                [3, 3],\n                [3, 4],\n            ]\n        )\n        X = pd.DataFrame(_enforce_estimator_tags_X(estimator_orig, X), copy=False)\n        y = pd.Series([1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2])\n        weights = pd.Series([1] * 12)\n        if _safe_tags(estimator, key=\"multioutput_only\"):\n            y = pd.DataFrame(y, copy=False)\n        try:\n            estimator.fit(X, y, sample_weight=weights)\n        except ValueError:\n            raise ValueError(\n                \"Estimator {0} raises error if \"\n                \"'sample_weight' parameter is of \"\n                \"type pandas.Series\".format(name)\n            )\n    except ImportError:\n        raise SkipTest(\n            \"pandas is not installed: not testing for \"\n            \"input of type pandas.Series to class weight.\"\n        )\n\n\n@ignore_warnings(category=(FutureWarning))\ndef check_sample_weights_not_an_array(name, estimator_orig):\n    # check that estimators will accept a 'sample_weight' parameter of\n    # type _NotAnArray in the 'fit' function.\n    estimator = clone(estimator_orig)\n    X = np.array(\n        [\n            [1, 1],\n            [1, 2],\n            [1, 3],\n            [1, 4],\n            [2, 1],\n            [2, 2],\n            [2, 3],\n            [2, 4],\n            [3, 1],\n            [3, 2],\n            [3, 3],\n            [3, 4],\n        ]\n    )\n    X = _NotAnArray(_enforce_estimator_tags_X(estimator_orig, X))\n    y = _NotAnArray([1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2])\n    weights = _NotAnArray([1] * 12)\n    if _safe_tags(estimator, key=\"multioutput_only\"):\n        y = _NotAnArray(y.data.reshape(-1, 1))\n    estimator.fit(X, y, sample_weight=weights)\n\n\n@ignore_warnings(category=(FutureWarning))\ndef check_sample_weights_list(name, estimator_orig):\n    # check that estimators will accept a 'sample_weight' parameter of\n    # type list in the 'fit' function.\n    estimator = clone(estimator_orig)\n    rnd = np.random.RandomState(0)\n    n_samples = 30\n    X = _enforce_estimator_tags_X(estimator_orig, rnd.uniform(size=(n_samples, 3)))\n    y = np.arange(n_samples) % 3\n    y = _enforce_estimator_tags_y(estimator, y)\n    sample_weight = [3] * n_samples\n    # Test that estimators don't raise any exception\n    estimator.fit(X, y, sample_weight=sample_weight)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 38580,
                "end_index": 41430,
                "start_line": 181,
                "end_line": 1181,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "@ignore_warnings\ndef check_fit2d_1feature(name, estimator_orig):\n    # check fitting a 2d array with only 1 feature either works or returns\n    # informative message\n    rnd = np.random.RandomState(0)\n    X = 3 * rnd.uniform(size=(10, 1))\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = X[:, 0].astype(int)\n    estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    if hasattr(estimator, \"n_components\"):\n        estimator.n_components = 1\n    if hasattr(estimator, \"n_clusters\"):\n        estimator.n_clusters = 1\n    # ensure two labels in subsample for RandomizedLogisticRegression\n    if name == \"RandomizedLogisticRegression\":\n        estimator.sample_fraction = 1\n    # ensure non skipped trials for RANSACRegressor\n    if name == \"RANSACRegressor\":\n        estimator.residual_threshold = 0.5\n\n    y = _enforce_estimator_tags_y(estimator, y)\n    set_random_state(estimator, 1)\n\n    msgs = [r\"1 feature\\(s\\)\", \"n_features = 1\", \"n_features=1\"]\n\n    with raises(ValueError, match=msgs, may_pass=True):\n        estimator.fit(X, y)\n\n\n@ignore_warnings\ndef check_fit1d(name, estimator_orig):\n    # check fitting 1d X array raises a ValueError\n    rnd = np.random.RandomState(0)\n    X = 3 * rnd.uniform(size=(20))\n    y = X.astype(int)\n    estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    if hasattr(estimator, \"n_components\"):\n        estimator.n_components = 1\n    if hasattr(estimator, \"n_clusters\"):\n        estimator.n_clusters = 1\n\n    set_random_state(estimator, 1)\n    with raises(ValueError):\n        estimator.fit(X, y)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformer_general(name, transformer, readonly_memmap=False):\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer, X)\n\n    if readonly_memmap:\n        X, y = create_memmap_backed_data([X, y])\n\n    _check_transformer(name, transformer, X, y)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_transformer_data_not_an_array(name, transformer):\n    X, y = make_blobs(\n        n_samples=30,\n        centers=[[0, 0, 0], [1, 1, 1]],\n        random_state=0,\n        n_features=2,\n        cluster_std=0.1,\n    )\n    X = StandardScaler().fit_transform(X)\n    X = _enforce_estimator_tags_X(transformer, X)\n    this_X = _NotAnArray(X)\n    this_y = _NotAnArray(np.asarray(y))\n    _check_transformer(name, transformer, this_X, this_y)\n    # try the same with some list\n    _check_transformer(name, transformer, X.tolist(), y.tolist())",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 55999,
                "end_index": 58685,
                "start_line": 181,
                "end_line": 1729,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def check_classifiers_classes(name, classifier_orig):\n    X_multiclass, y_multiclass = make_blobs(\n        n_samples=30, random_state=0, cluster_std=0.1\n    )\n    X_multiclass, y_multiclass = shuffle(X_multiclass, y_multiclass, random_state=7)\n    X_multiclass = StandardScaler().fit_transform(X_multiclass)\n\n    X_binary = X_multiclass[y_multiclass != 2]\n    y_binary = y_multiclass[y_multiclass != 2]\n\n    X_multiclass = _enforce_estimator_tags_X(classifier_orig, X_multiclass)\n    X_binary = _enforce_estimator_tags_X(classifier_orig, X_binary)\n\n    labels_multiclass = [\"one\", \"two\", \"three\"]\n    labels_binary = [\"one\", \"two\"]\n\n    y_names_multiclass = np.take(labels_multiclass, y_multiclass)\n    y_names_binary = np.take(labels_binary, y_binary)\n\n    problems = [(X_binary, y_binary, y_names_binary)]\n    if not _safe_tags(classifier_orig, key=\"binary_only\"):\n        problems.append((X_multiclass, y_multiclass, y_names_multiclass))\n\n    for X, y, y_names in problems:\n        for y_names_i in [y_names, y_names.astype(\"O\")]:\n            y_ = _choose_check_classifiers_labels(name, y, y_names_i)\n            check_classifiers_predictions(X, y_, name, classifier_orig)\n\n    labels_binary = [-1, 1]\n    y_names_binary = np.take(labels_binary, y_binary)\n    y_binary = _choose_check_classifiers_labels(name, y_binary, y_names_binary)\n    check_classifiers_predictions(X_binary, y_binary, name, classifier_orig)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_regressors_int(name, regressor_orig):\n    X, _ = _regression_dataset()\n    X = _enforce_estimator_tags_X(regressor_orig, X[:50])\n    rnd = np.random.RandomState(0)\n    y = rnd.randint(3, size=X.shape[0])\n    y = _enforce_estimator_tags_y(regressor_orig, y)\n    rnd = np.random.RandomState(0)\n    # separate estimators to control random seeds\n    regressor_1 = clone(regressor_orig)\n    regressor_2 = clone(regressor_orig)\n    set_random_state(regressor_1)\n    set_random_state(regressor_2)\n\n    if name in CROSS_DECOMPOSITION:\n        y_ = np.vstack([y, 2 * y + rnd.randint(2, size=len(y))])\n        y_ = y_.T\n    else:\n        y_ = y\n\n    # fit\n    regressor_1.fit(X, y_)\n    pred1 = regressor_1.predict(X)\n    regressor_2.fit(X, y_.astype(float))\n    pred2 = regressor_2.predict(X)\n    assert_allclose(pred1, pred2, atol=1e-2, err_msg=name)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 105609,
                "end_index": 107920,
                "start_line": 3007,
                "end_line": 3430,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def _yield_classifier_checks(classifier):\n    tags = _safe_tags(classifier)\n\n    # test classifiers can handle non-array data and pandas objects\n    yield check_classifier_data_not_an_array\n    # test classifiers trained on a single label always return this label\n    yield check_classifiers_one_label\n    yield check_classifiers_one_label_sample_weights\n    yield check_classifiers_classes\n    yield check_estimators_partial_fit_n_features\n    if tags[\"multioutput\"]:\n        yield check_classifier_multioutput\n    # basic consistency testing\n    yield check_classifiers_train\n    yield partial(check_classifiers_train, readonly_memmap=True)\n    yield partial(check_classifiers_train, readonly_memmap=True, X_dtype=\"float32\")\n    yield check_classifiers_regression_target\n    if tags[\"multilabel\"]:\n        yield check_classifiers_multilabel_representation_invariance\n        yield check_classifiers_multilabel_output_format_predict\n        yield check_classifiers_multilabel_output_format_predict_proba\n        yield check_classifiers_multilabel_output_format_decision_function\n    if not tags[\"no_validation\"]:\n        yield check_supervised_y_no_nan\n        if not tags[\"multioutput_only\"]:\n            yield check_supervised_y_2d\n    if tags[\"requires_fit\"]:\n        yield check_estimators_unfitted\n    if \"class_weight\" in classifier.get_params().keys():\n        yield check_class_weight_classifiers\n\n    yield check_non_transformer_estimators_n_iter\n    # test if predict_proba is a monotonic transformation of decision_function\n    yield check_decision_proba_consistency\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_supervised_y_no_nan(name, estimator_orig):\n    # Checks that the Estimator targets are not NaN.\n    estimator = clone(estimator_orig)\n    rng = np.random.RandomState(888)\n    X = rng.standard_normal(size=(10, 5))\n\n    for value in [np.nan, np.inf]:\n        y = np.full(10, value)\n        y = _enforce_estimator_tags_y(estimator, y)\n\n        module_name = estimator.__module__\n        if module_name.startswith(\"sklearn.\") and not (\n            \"test_\" in module_name or module_name.endswith(\"_testing\")\n        ):\n            # In scikit-learn we want the error message to mention the input\n            # name and be specific about the kind of unexpected value.\n            if np.isinf(value):\n                match = (\n                    r\"Input (y|Y) contains infinity or a value too large for\"\n                    r\" dtype\\('float64'\\).\"\n                )\n            else:\n                match = r\"Input (y|Y) contains NaN.\"\n        else:\n            # Do not impose a particular error message to third-party libraries.\n            match = None\n        err_msg = (\n            f\"Estimator {name} should have raised error on fitting array y with inf\"\n            \" value.\"\n        )\n        with raises(ValueError, match=match, err_msg=err_msg):\n            estimator.fit(X, y)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 4352,
                "end_index": 7266,
                "start_line": 145,
                "end_line": 1355,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "@ignore_warnings(category=FutureWarning)\ndef check_classifiers_one_label(name, classifier_orig):\n    error_string_fit = \"Classifier can't train when only one class is present.\"\n    error_string_predict = \"Classifier can't predict when only one class is present.\"\n    rnd = np.random.RandomState(0)\n    X_train = rnd.uniform(size=(10, 3))\n    X_test = rnd.uniform(size=(10, 3))\n    y = np.ones(10)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        classifier = clone(classifier_orig)\n        with raises(\n            ValueError, match=\"class\", may_pass=True, err_msg=error_string_fit\n        ) as cm:\n            classifier.fit(X_train, y)\n\n        if cm.raised_and_matched:\n            # ValueError was raised with proper error message\n            return\n\n        assert_array_equal(classifier.predict(X_test), y, err_msg=error_string_predict)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_classifiers_one_label_sample_weights(name, classifier_orig):\n    \"\"\"Check that classifiers accepting sample_weight fit or throws a ValueError with\n    an explicit message if the problem is reduced to one class.\n    \"\"\"\n    error_fit = (\n        f\"{name} failed when fitted on one label after sample_weight trimming. Error \"\n        \"message is not explicit, it should have 'class'.\"\n    )\n    error_predict = f\"{name} prediction results should only output the remaining class.\"\n    rnd = np.random.RandomState(0)\n    # X should be square for test on SVC with precomputed kernel\n    X_train = rnd.uniform(size=(10, 10))\n    X_test = rnd.uniform(size=(10, 10))\n    y = np.arange(10) % 2\n    sample_weight = y.copy()  # select a single class\n    classifier = clone(classifier_orig)\n\n    if has_fit_parameter(classifier, \"sample_weight\"):\n        match = [r\"\\bclass(es)?\\b\", error_predict]\n        err_type, err_msg = (AssertionError, ValueError), error_fit\n    else:\n        match = r\"\\bsample_weight\\b\"\n        err_type, err_msg = (TypeError, ValueError), None\n\n    with raises(err_type, match=match, may_pass=True, err_msg=err_msg) as cm:\n        classifier.fit(X_train, y, sample_weight=sample_weight)\n        if cm.raised_and_matched:\n            # raise the proper error type with the proper error message\n            return\n        # for estimators that do not fail, they should be able to predict the only\n        # class remaining during fit\n        assert_array_equal(\n            classifier.predict(X_test), np.ones(10), err_msg=error_predict\n        )",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 79371,
                "end_index": 81868,
                "start_line": 181,
                "end_line": 4639,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def check_array_api_input_and_values(\n    name,\n    estimator_orig,\n    array_namespace,\n    device=None,\n    dtype=\"float64\",\n):\n    return check_array_api_input(\n        name,\n        estimator_orig,\n        array_namespace=array_namespace,\n        device=device,\n        dtype=dtype,\n        check_values=True,\n    )\n\n\ndef check_estimator_sparse_data(name, estimator_orig):\n    rng = np.random.RandomState(0)\n    X = rng.uniform(size=(40, 3))\n    X[X < 0.8] = 0\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    X_csr = sparse.csr_matrix(X)\n    y = (4 * rng.uniform(size=40)).astype(int)\n    # catch deprecation warnings\n    with ignore_warnings(category=FutureWarning):\n        estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n    tags = _safe_tags(estimator_orig)\n    for matrix_format, X in _generate_sparse_matrix(X_csr):\n        # catch deprecation warnings\n        with ignore_warnings(category=FutureWarning):\n            estimator = clone(estimator_orig)\n            if name in [\"Scaler\", \"StandardScaler\"]:\n                estimator.set_params(with_mean=False)\n        # fit and predict\n        if \"64\" in matrix_format:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to support {matrix_format} \"\n                \"matrix, and is not failing gracefully, e.g. by using \"\n                \"check_array(X, accept_large_sparse=False)\"\n            )\n        else:\n            err_msg = (\n                f\"Estimator {name} doesn't seem to fail gracefully on sparse \"\n                \"data: error message should state explicitly that sparse \"\n                \"input is not supported if this is not the case.\"\n            )\n        with raises(\n            (TypeError, ValueError),\n            match=[\"sparse\", \"Sparse\"],\n            may_pass=True,\n            err_msg=err_msg,\n        ):\n            with ignore_warnings(category=FutureWarning):\n                estimator.fit(X, y)\n            if hasattr(estimator, \"predict\"):\n                pred = estimator.predict(X)\n                if tags[\"multioutput_only\"]:\n                    assert pred.shape == (X.shape[0], 1)\n                else:\n                    assert pred.shape == (X.shape[0],)\n            if hasattr(estimator, \"predict_proba\"):\n                probs = estimator.predict_proba(X)\n                if tags[\"binary_only\"]:\n                    expected_probs_shape = (X.shape[0], 2)\n                else:\n                    expected_probs_shape = (X.shape[0], 4)\n                assert probs.shape == expected_probs_shape",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 36016,
                "end_index": 38577,
                "start_line": 1025,
                "end_line": 1093,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def check_sample_weights_not_overwritten(name, estimator_orig):\n    # check that estimators don't override the passed sample_weight parameter\n    estimator = clone(estimator_orig)\n    set_random_state(estimator, random_state=0)\n\n    X = np.array(\n        [\n            [1, 3],\n            [1, 3],\n            [1, 3],\n            [1, 3],\n            [2, 1],\n            [2, 1],\n            [2, 1],\n            [2, 1],\n            [3, 3],\n            [3, 3],\n            [3, 3],\n            [3, 3],\n            [4, 1],\n            [4, 1],\n            [4, 1],\n            [4, 1],\n        ],\n        dtype=np.float64,\n    )\n    y = np.array([1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2], dtype=int)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    sample_weight_original = np.ones(y.shape[0])\n    sample_weight_original[0] = 10.0\n\n    sample_weight_fit = sample_weight_original.copy()\n\n    estimator.fit(X, y, sample_weight=sample_weight_fit)\n\n    err_msg = f\"{name} overwrote the original `sample_weight` given during fit\"\n    assert_allclose(sample_weight_fit, sample_weight_original, err_msg=err_msg)\n\n\n@ignore_warnings(category=(FutureWarning, UserWarning))\ndef check_dtype_object(name, estimator_orig):\n    # check that estimators treat dtype object as numeric if possible\n    rng = np.random.RandomState(0)\n    X = _enforce_estimator_tags_X(estimator_orig, rng.uniform(size=(40, 10)))\n    X = X.astype(object)\n    tags = _safe_tags(estimator_orig)\n    y = (X[:, 0] * 4).astype(int)\n    estimator = clone(estimator_orig)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    estimator.fit(X, y)\n    if hasattr(estimator, \"predict\"):\n        estimator.predict(X)\n\n    if hasattr(estimator, \"transform\"):\n        estimator.transform(X)\n\n    with raises(Exception, match=\"Unknown label type\", may_pass=True):\n        estimator.fit(X, y.astype(object))\n\n    if \"string\" not in tags[\"X_types\"]:\n        X[0, 0] = {\"foo\": \"bar\"}\n        msg = \"argument must be a string.* number\"\n        with raises(TypeError, match=msg):\n            estimator.fit(X, y)\n    else:\n        # Estimators supporting string will not call np.asarray to convert the\n        # data to numeric and therefore, the error will not be raised.\n        # Checking for each element dtype in the input array will be costly.\n        # Refer to #11401 for full discussion.\n        estimator.fit(X, y)\n\n\ndef check_complex_data(name, estimator_orig):\n    rng = np.random.RandomState(42)\n    # check that estimators raise an exception on providing complex data\n    X = rng.uniform(size=10) + 1j * rng.uniform(size=10)\n    X = X.reshape(-1, 1)\n\n    # Something both valid for classification and regression\n    y = rng.randint(low=0, high=2, size=10) + 1j\n    estimator = clone(estimator_orig)\n    set_random_state(estimator, random_state=0)\n    with raises(ValueError, match=\"Complex data not supported\"):\n        estimator.fit(X, y)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 44629,
                "end_index": 47525,
                "start_line": 1290,
                "end_line": 4110,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def check_outliers_fit_predict(name, estimator_orig):\n    # Check fit_predict for outlier detectors.\n\n    n_samples = 300\n    X, _ = make_blobs(n_samples=n_samples, random_state=0)\n    X = shuffle(X, random_state=7)\n    n_samples, n_features = X.shape\n    estimator = clone(estimator_orig)\n\n    set_random_state(estimator)\n\n    y_pred = estimator.fit_predict(X)\n    assert y_pred.shape == (n_samples,)\n    assert y_pred.dtype.kind == \"i\"\n    assert_array_equal(np.unique(y_pred), np.array([-1, 1]))\n\n    # check fit_predict = fit.predict when the estimator has both a predict and\n    # a fit_predict method. recall that it is already assumed here that the\n    # estimator has a fit_predict method\n    if hasattr(estimator, \"predict\"):\n        y_pred_2 = estimator.fit(X).predict(X)\n        assert_array_equal(y_pred, y_pred_2)\n\n    if hasattr(estimator, \"contamination\"):\n        # proportion of outliers equal to contamination parameter when not\n        # set to 'auto'\n        expected_outliers = 30\n        contamination = float(expected_outliers) / n_samples\n        estimator.set_params(contamination=contamination)\n        y_pred = estimator.fit_predict(X)\n\n        num_outliers = np.sum(y_pred != 1)\n        # num_outliers should be equal to expected_outliers unless\n        # there are ties in the decision_function values. this can\n        # only be tested for estimators with a decision_function\n        # method\n        if num_outliers != expected_outliers and hasattr(\n            estimator, \"decision_function\"\n        ):\n            decision = estimator.decision_function(X)\n            check_outlier_corruption(num_outliers, expected_outliers, decision)\n\n\ndef check_fit_non_negative(name, estimator_orig):\n    # Check that proper warning is raised for non-negative X\n    # when tag requires_positive_X is present\n    X = np.array([[-1.0, 1], [-1.0, 1]])\n    y = np.array([1, 2])\n    estimator = clone(estimator_orig)\n    with raises(ValueError):\n        estimator.fit(X, y)",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 134030,
                "end_index": 136018,
                "start_line": 3781,
                "end_line": 4110,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            },
            {
                "code": "def check_fit_check_is_fitted(name, estimator_orig):\n    # Make sure that estimator doesn't pass check_is_fitted before calling fit\n    # and that passes check_is_fitted once it's fit.\n\n    rng = np.random.RandomState(42)\n\n    estimator = clone(estimator_orig)\n    set_random_state(estimator)\n    if \"warm_start\" in estimator.get_params():\n        estimator.set_params(warm_start=False)\n\n    n_samples = 100\n    X = rng.normal(loc=100, size=(n_samples, 2))\n    X = _enforce_estimator_tags_X(estimator, X)\n    if is_regressor(estimator_orig):\n        y = rng.normal(size=n_samples)\n    else:\n        y = rng.randint(low=0, high=2, size=n_samples)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    if not _safe_tags(estimator).get(\"stateless\", False):\n        # stateless estimators (such as FunctionTransformer) are always \"fit\"!\n        try:\n            check_is_fitted(estimator)\n            raise AssertionError(\n                f\"{estimator.__class__.__name__} passes check_is_fitted before being\"\n                \" fit!\"\n            )\n        except NotFittedError:\n            pass\n    estimator.fit(X, y)\n    try:\n        check_is_fitted(estimator)\n    except NotFittedError as e:\n        raise NotFittedError(\n            \"Estimator fails to pass `check_is_fitted` even though it has been fit.\"\n        ) from e\n\n\ndef check_n_features_in(name, estimator_orig):\n    # Make sure that n_features_in_ attribute doesn't exist until fit is\n    # called, and that its value is correct.\n\n    rng = np.random.RandomState(0)\n\n    estimator = clone(estimator_orig)\n    set_random_state(estimator)\n    if \"warm_start\" in estimator.get_params():\n        estimator.set_params(warm_start=False)\n\n    n_samples = 100\n    X = rng.normal(loc=100, size=(n_samples, 2))\n    X = _enforce_estimator_tags_X(estimator, X)\n    if is_regressor(estimator_orig):\n        y = rng.normal(size=n_samples)\n    else:\n        y = rng.randint(low=0, high=2, size=n_samples)\n    y = _enforce_estimator_tags_y(estimator, y)\n\n    assert not hasattr(estimator, \"n_features_in_\")\n    estimator.fit(X, y)\n    assert hasattr(estimator, \"n_features_in_\")\n    assert estimator.n_features_in_ == X.shape[1]\n\n\ndef check_requires_y_none(name, estimator_orig):\n    # Make sure that an estimator with requires_y=True fails gracefully when\n    # given y=None\n\n    rng = np.random.RandomState(0)\n\n    estimator = clone(estimator_orig)\n    set_random_state(estimator)\n\n    n_samples = 100\n    X = rng.normal(loc=100, size=(n_samples, 2))\n    X = _enforce_estimator_tags_X(estimator, X)\n\n    expected_err_msgs = (\n        \"requires y to be passed, but the target y is None\",\n        \"Expected array-like (array or non-string sequence), got None\",\n        \"y should be a 1d array\",\n    )\n\n    try:\n        estimator.fit(X, None)\n    except ValueError as ve:\n        if not any(msg in str(ve) for msg in expected_err_msgs):\n            raise ve",
                "filename": "sklearn/utils/estimator_checks.py",
                "start_index": 138164,
                "end_index": 141063,
                "start_line": 3892,
                "end_line": 3980,
                "max_line": 4639,
                "git_instance": "github",
                "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                "sha": ""
            }
        ],
        "classification": "bug",
        "snippet_processor_task": {
            "sklearn/utils/estimator_checks.py": [
                {
                    "chunk": {
                        "code": "@ignore_warnings(category=FutureWarning)\ndef check_regressor_data_not_an_array(name, estimator_orig):\n    X, y = _regression_dataset()\n    X = _enforce_estimator_tags_X(estimator_orig, X)\n    y = _enforce_estimator_tags_y(estimator_orig, y)\n    for obj_type in [\"NotAnArray\", \"PandasDataframe\"]:\n        check_estimators_data_not_an_array(name, estimator_orig, X, y, obj_type)\n\n\n@ignore_warnings(category=FutureWarning)\ndef check_estimators_data_not_an_array(name, estimator_orig, X, y, obj_type):\n    if name in CROSS_DECOMPOSITION:\n        raise SkipTest(\n            \"Skipping check_estimators_data_not_an_array \"\n            \"for cross decomposition module as estimators \"\n            \"are not deterministic.\"\n        )\n    # separate estimators to control random seeds\n    estimator_1 = clone(estimator_orig)\n    estimator_2 = clone(estimator_orig)\n    set_random_state(estimator_1)\n    set_random_state(estimator_2)\n\n    if obj_type not in [\"NotAnArray\", \"PandasDataframe\"]:\n        raise ValueError(\"Data type {0} not supported\".format(obj_type))\n\n    if obj_type == \"NotAnArray\":\n        y_ = _NotAnArray(np.asarray(y))\n        X_ = _NotAnArray(np.asarray(X))\n    else:\n        # Here pandas objects (Series and DataFrame) are tested explicitly\n        # because some estimators may handle them (especially their indexing)\n        # specially.\n        try:\n            import pandas as pd\n\n            y_ = np.asarray(y)\n            if y_.ndim == 1:\n                y_ = pd.Series(y_, copy=False)\n            else:\n                y_ = pd.DataFrame(y_, copy=False)\n            X_ = pd.DataFrame(np.asarray(X), copy=False)\n\n        except ImportError:\n            raise SkipTest(\n                \"pandas is not installed: not checking estimators for pandas objects.\"\n            )\n\n    # fit\n    estimator_1.fit(X_, y_)\n    pred1 = estimator_1.predict(X_)\n    estimator_2.fit(X, y)\n    pred2 = estimator_2.predict(X)\n    assert_allclose(pred1, pred2, atol=1e-2, err_msg=name)",
                        "filename": "sklearn/utils/estimator_checks.py",
                        "start_index": 118586,
                        "end_index": 120568,
                        "start_line": 181,
                        "end_line": 3430,
                        "max_line": 4639,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet includes checks for regressors with non-array data types, which is relevant to the issue of KNeighborsRegressor giving different results for different n_jobs values when using 'seuclidean' distance without passing V as additional metric_params."
                },
                {
                    "chunk": {
                        "code": "@ignore_warnings(category=FutureWarning)\ndef check_sample_weights_pandas_series(name, estimator_orig):\n    # check that estimators will accept a 'sample_weight' parameter of\n    # type pandas.Series in the 'fit' function.\n    estimator = clone(estimator_orig)\n    try:\n        import pandas as pd\n\n        X = np.array(\n            [\n                [1, 1],\n                [1, 2],\n                [1, 3],\n                [1, 4],\n                [2, 1],\n                [2, 2],\n                [2, 3],\n                [2, 4],\n                [3, 1],\n                [3, 2],\n                [3, 3],\n                [3, 4],\n            ]\n        )\n        X = pd.DataFrame(_enforce_estimator_tags_X(estimator_orig, X), copy=False)\n        y = pd.Series([1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2])\n        weights = pd.Series([1] * 12)\n        if _safe_tags(estimator, key=\"multioutput_only\"):\n            y = pd.DataFrame(y, copy=False)\n        try:\n            estimator.fit(X, y, sample_weight=weights)\n        except ValueError:\n            raise ValueError(\n                \"Estimator {0} raises error if \"\n                \"'sample_weight' parameter is of \"\n                \"type pandas.Series\".format(name)\n            )\n    except ImportError:\n        raise SkipTest(\n            \"pandas is not installed: not testing for \"\n            \"input of type pandas.Series to class weight.\"\n        )\n\n\n@ignore_warnings(category=(FutureWarning))\ndef check_sample_weights_not_an_array(name, estimator_orig):\n    # check that estimators will accept a 'sample_weight' parameter of\n    # type _NotAnArray in the 'fit' function.\n    estimator = clone(estimator_orig)\n    X = np.array(\n        [\n            [1, 1],\n            [1, 2],\n            [1, 3],\n            [1, 4],\n            [2, 1],\n            [2, 2],\n            [2, 3],\n            [2, 4],\n            [3, 1],\n            [3, 2],\n            [3, 3],\n            [3, 4],\n        ]\n    )\n    X = _NotAnArray(_enforce_estimator_tags_X(estimator_orig, X))\n    y = _NotAnArray([1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2])\n    weights = _NotAnArray([1] * 12)\n    if _safe_tags(estimator, key=\"multioutput_only\"):\n        y = _NotAnArray(y.data.reshape(-1, 1))\n    estimator.fit(X, y, sample_weight=weights)\n\n\n@ignore_warnings(category=(FutureWarning))\ndef check_sample_weights_list(name, estimator_orig):\n    # check that estimators will accept a 'sample_weight' parameter of\n    # type list in the 'fit' function.\n    estimator = clone(estimator_orig)\n    rnd = np.random.RandomState(0)\n    n_samples = 30\n    X = _enforce_estimator_tags_X(estimator_orig, rnd.uniform(size=(n_samples, 3)))\n    y = np.arange(n_samples) % 3\n    y = _enforce_estimator_tags_y(estimator, y)\n    sample_weight = [3] * n_samples\n    # Test that estimators don't raise any exception\n    estimator.fit(X, y, sample_weight=sample_weight)",
                        "filename": "sklearn/utils/estimator_checks.py",
                        "start_index": 38580,
                        "end_index": 41430,
                        "start_line": 181,
                        "end_line": 1181,
                        "max_line": 4639,
                        "git_instance": "github",
                        "repo_name": "testbed/scikit-learn__scikit-learn__0.20",
                        "sha": ""
                    },
                    "reason_for_relevance": "This snippet checks that estimators accept a 'sample_weight' parameter of type pandas.Series, which is relevant because the issue mentions a problem with handling pandas series in the check_array function."
                }
            ]
        },
        "solution_task": "- Ensure that `metric_params` is properly set when using 'seuclidean' or 'mahalanobis' distance metrics with `KNeighborsRegressor`. For 'seuclidean', a value for `V` (variance vector) is required, and for 'mahalanobis', a value for `VI` (inverse of the covariance matrix) is needed. If these parameters are not set, calculate them from the training data and pass them to `metric_params`.\n- When using `RandomizedSearchCV` with `KNeighborsRegressor`, ensure that the `metric_params` is included in the parameter distribution to avoid inconsistent predictions when using different `n_jobs` values.\n- To address the `TypeError` raised by `utils.validation.check_array` when a pandas series is passed in, ensure that input data is converted to a NumPy array before being passed to `KNeighborsRegressor`. Use `np.asarray()` or `pd.Series.values` to convert a pandas series to a NumPy array.\n- If `ensure_2d=False` is causing issues, ensure that input data to `check_array` is two-dimensional. This can be done by reshaping the data if necessary using `np.reshape(-1, 1)` for a single feature or ensuring the input data is already in a 2D shape.\n- If `dtype=None` is causing issues in `check_array`, explicitly set the `dtype` to a numerical type like `np.float64` when calling `check_array` to ensure that the data is checked as a numeric array.\n- Since the issue is observed with scikit-learn version 0.20.0 and 0.20.1, consider upgrading to a newer version of scikit-learn if the issue is known and fixed in later versions.",
        "bouncer_response": {
            "score": 7,
            "criteria": "The RESPONSE must provide actionable, relevant guidance to more parts of the PROMPT's described issue to score higher.",
            "supporting_evidence": "The RESPONSE provides a comprehensive set of actionable steps to address the issues described in the PROMPT. It correctly identifies the need to set `metric_params` when using 'seuclidean' or 'mahalanobis' distance metrics in `KNeighborsRegressor`. It also suggests ensuring that `metric_params` is included in the parameter distribution for `RandomizedSearchCV` and recommends converting pandas series to NumPy arrays before passing them to `KNeighborsRegressor`. Additionally, the RESPONSE provides guidance on handling potential issues with `ensure_2d=False` and `dtype=None` in `check_array`. The RESPONSE also suggests upgrading to a newer version of scikit-learn if the issue is known and fixed in later versions. However, the RESPONSE includes a section with code snippets to check, which is not directly actionable and seems to be more of a reference than a solution. This part does not directly contribute to resolving the bug but provides context, which is why the RESPONSE does not score a perfect 10.",
            "clarification_questions": "NONE"
        },
        "end_time": 1711742257.187107,
        "result": "- Ensure that `metric_params` is properly set when using 'seuclidean' or 'mahalanobis' distance metrics with `KNeighborsRegressor`. For 'seuclidean', a value for `V` (variance vector) is required, and for 'mahalanobis', a value for `VI` (inverse of the covariance matrix) is needed. If these parameters are not set, calculate them from the training data and pass them to `metric_params`.\n- When using `RandomizedSearchCV` with `KNeighborsRegressor`, ensure that the `metric_params` is included in the parameter distribution to avoid inconsistent predictions when using different `n_jobs` values.\n- To address the `TypeError` raised by `utils.validation.check_array` when a pandas series is passed in, ensure that input data is converted to a NumPy array before being passed to `KNeighborsRegressor`. Use `np.asarray()` or `pd.Series.values` to convert a pandas series to a NumPy array.\n- If `ensure_2d=False` is causing issues, ensure that input data to `check_array` is two-dimensional. This can be done by reshaping the data if necessary using `np.reshape(-1, 1)` for a single feature or ensuring the input data is already in a 2D shape.\n- If `dtype=None` is causing issues in `check_array`, explicitly set the `dtype` to a numerical type like `np.float64` when calling `check_array` to ensure that the data is checked as a numeric array.\n- Since the issue is observed with scikit-learn version 0.20.0 and 0.20.1, consider upgrading to a newer version of scikit-learn if the issue is known and fixed in later versions.\n\n### Code snippets to check\n\n-  \u2192 [sklearn](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn) \u2192 [utils](https://github.com/testbed/scikit-learn__scikit-learn__0.20/tree//sklearn/utils)- [Lines 181 - 3430](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/estimator_checks.py#L181-L3430)\n\n This snippet includes checks for regressors with non-array data types, which is relevant to the issue of KNeighborsRegressor giving different results for different n_jobs values when using 'seuclidean' distance without passing V as additional metric_params. \n\n\n   - [Lines 181 - 1181](https://github.com/testbed/scikit-learn__scikit-learn__0.20/blob//sklearn/utils/estimator_checks.py#L181-L1181)\n\n This snippet checks that estimators accept a 'sample_weight' parameter of type pandas.Series, which is relevant because the issue mentions a problem with handling pandas series in the check_array function."
    }
}